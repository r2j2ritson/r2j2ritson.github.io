[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Years of Experience\n8+\n\n5+ w/ state agencies and univeristies\n\n\n\n3 w/ federal agencies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYears of Education\n6\n\n\n\n\n\n\n\n\n\n\n\n\n\n M.S. Biology, University of Nebraska-Kearney (2019)\n B.S. Wildlife and Fisheries Sciences, The Pennsylvania State University (2014)\n\n\n\nAssociate Wildlife Biologist®, The Wildlife Society\n\n\n\n Associate Research Scientist, University of Wyoming and Idaho Department of Fish and Game, February 2022 - present.\n Research Associate - Vegetation Modeling, Wildlife Management Institute and Idaho Department of Fish and Game, March 2021 - January 2022.\n Wildlife Technician, Idaho Department of Fish and Game, November 2019 - June 2020; November 2020 - March 2021.\n Habitat Biologist Technician, Wyoming Game and Fish Department, May - October 2019.\n Biological Science Technician (GS-05), USFS Rocky Mountain Research Station, June - September 2016; June - August 2017.\n Wild Turkey Technician, West Virginia University, April - June 2017.\n Lead Wildlife Research Technician, Idaho Department of Fish and Game, March - May 2016.\n Research Associate, Montana State University, June - October 2015.\n Sage-grouse Technician, University of Wyoming, March - June 2015.\n Snowshoe Hare Technician, Pennsylvania Cooperative Fish and Wildlife Research Unit, January - March 2015.\n Biological Science Aid (GS-03), Wind Cave National Park, June - August 2014.\n\n\n\n Mule deer seasonal range analysis. February 2022 – present. Collaborators: Scott Bergen, Matt Mumma, Shane Roberts, Mark Hurley. Idaho Department of Fish and Game. Pocatello, ID.\n Fine-scale vegetation model. March 2021 – present. Collaborators: Erin Roche, Sara Thompson, Scott Bergen, Matt Mumma, Shane Roberts, Mark Hurley. Idaho Department of Fish and Game. Boise, ID.\n Thesis: Spatial Ecology of Bison in the American West. August 2017 - May 2019 Collaborators: Nate Bickford, Melissa Wuellner, Angela Hollman, and Dustin H. Ranglack. University of Nebraska-Kearney. Kearney, NE.\n Effects of 2017 solar eclipse on animal behavior. August 2017 - May 2019. Collaborators: Nate Bickford, Melissa Wuellner, Dustin H. Ranglack, et al. University of Nebraska-Kearney. Kearney, NE.\n Ecological Correlates of Game Bird Distribution in Northern Tanzania. February – May 2013. Advisor: John Kioko. The School for Field Studies Center for Wildlife Management Studies. Karatu, TZ.\n\n\n\n Ritson R, Ranglack DH, Bickford N. 2019. Comparing Social Media Observations of Animals During a Solar Eclipse to Published Research. Animals 9(59):1-12. doi:10.3390/ani9020059\n\n Ritson R, Barg A, Shannon J, Hershey K, Shoenecker KA, Beard D, Kunkel K, Kinka D, Ranglack DH. Seasonal space use patterns of American bison across multiple management regimes. Prepared for Journal of Wildlife Management.\n\n\n Ritson R, Bickford N, Wuellner M, Fuda RK, Miller TA, Boulanger JR, Beasley JC, Brzorad JN, Fisher R, Orben RA, Barber M, Kays R, Watson JL, Ranglack DH. Obscured Sun, Obscure Behavior: Exploring the Effects of a Solar Eclipse on Animal Movement. Prepared for Movement Ecology.\n\n\n\n\n Ritson R, Bergen S, Mumma M. Influences of interannual snow conditions on the dynamics of mule deer winter range habitat selection. Idaho Chapter of The Wildlife Society Annual Meeting. Boise, ID. Feb 2023. Oral presentation.\n Ritson R, Mumma M, Roche E, Bergen S, Roberts S, Hurley M. Towards a fine scale vegetation model. Idaho Chapter of The Wildlife Society Annual Meeting. Virtual. Feb 2022. Oral presentation.\n Bergen S, Ritson R, Hurley M, Roberts S. Mule deer population classification using meteorological, phenological and movement data. Idaho Chapter of The Wildlife Society Annual Meeting. Virtual. Feb 2022. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Variations in American bison resource selection across their former range. 6th Triennial Conference of the American Bison Society. Santa Fe, NM. Oct 2019. Poster.\n Ranglack DH, Ritson R, Bickford N. Variations in American bison resource selection across their former range. Joint Annual Conference of the American Fisheries Society and The Wildlife Society. Reno, NV. Sep 2019. Oral presentation.\n Ritson R. Spatial ecology of bison in the American West. Thesis defense. University of Nebraska-Kearney. Apr 2019. Oral presentation.\n Ritson R. Movement Ecology: Using Animal Locations for Fish and Wildlife Research. Guest Lecture for Quantitative Fish and Wildlife Analysis (BIOL 830P). University of Nebraska-Kearney. Mar 2019. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Seasonal space use patterns of Plains bison (Bison bison) across multiple ecological gradients and management regimes in the American West. Nebraska Chapter of The Wildlife Society Annual Meeting. York, NE. Feb 2019. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Spatial Requirements of Plains Bison (Bison bison) in the American West. The Wildlife Society 25th Annual Conference. Cleveland, OH. Oct 2018. Oral presentation.\n Bickford N, Ritson R, Ranglack DH. Wildlife Behavior Changes During a Solar Eclipse. The Wildlife Society 25th Annual Conference. Cleveland, OH. Oct 2018. Poster.\n Ritson R, Bickford N, Smith L, Bickford S, Bice MR, Ranglack DH. Evaluating the role of CSR and SLO in Ecotourism. Plains Safaris: A conference on tourism and conservation in the Great Plains. Kearney, NE. April 2018. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Does Wildlife Behavior Change in Response to a Solar Eclipse? The Nebraska Academy of Sciences Annual Meeting. Lincoln, NE. April 2018. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Spatial Requirements of Plains Bison (Bison bison) in the American West. Central Mountains and Plains Section of the Wildlife Society Annual Meeting. Kearney, NE. March 2018. Poster.\n\n\n\n Animal movement analyses: A to Z, with lots of R. June 2018. British Ecological Society, Movement Ecology Special Interest Group. Vancouver, BC. Speakers: Marie Auger-Methe, Luca Borger, Garrett Street. Workshop\n Do the Genetics 101: Matching Techniques and Technologies to Research Questions in Wildlife and Fisheries Genetics. February 2022. Idaho Chapter of The Wildlife Society. The Molecular Ecology Working Group. Virtual.\n\n\n\n\n\n Data Carpentry Introduction to R. February 2023. Idaho Chapter of The Wildlife Society. Boise, ID.\n Mini animal movement analyses with R. October 2018. University of Nebraska at Kearney. Kearney, NE.\n\n\n\n Secretary, Executive Board\n Co-chair, Sponsorship Committee\n Membership Committee\n\n\n\n Bylaws and Operations Manual Committee\n\n\n\n\n Most Outstanding Thesis Award, University of Nebraska-Kearney (2020)\n Shikar-Safari Club Scholarship (2014)\n Four Year Conservation Scholarship, Safari Club International Foundation (2014)\n Eagle Scout, Boy Scouts of America (2009)"
  },
  {
    "objectID": "cameras.html",
    "href": "cameras.html",
    "title": "Cameras",
    "section": "",
    "text": "During my experience as an IDFG wildlife technician, I participated in image processing using Timelapse2 software as well as camera placement and programming. In addition to my familiarity with IDFG’s camera survey protocols, I am also familiar with camera inventory and logistics challenges. I have also worked on developing an R-wrapper for Microsoft’s MegaDetector AI model which can be run locally for filtering images containing animals."
  },
  {
    "objectID": "cameras.html#fa-camera-r-code",
    "href": "cameras.html#fa-camera-r-code",
    "title": "Cameras",
    "section": " R code",
    "text": "R code\nIncluded here is the first version of the R-wrapper I created. Microsoft has since changed the format of their model slightly, but this still works with the old version. The R code could process ~ 1 image per second, which is reasonable, but a little slow for IDFG’s needs (at least on a statewide scale), running the original Python code from Microsoft on a GPU is still much faster. The new version of the model uses PyTorch instead of TensorFlow which may result in speed improvements within an R environment.\n Batch execute ‘MegaDetector’ in R\n\npy_batch_megadetector <- function(\n  image_path = \"C:/MegaDetector/test_images/\",\n  out_file = \"C:/MegaDetector/results/results.json\",\n  detector_model = \"default\",\n  threshold = 0.1,\n  ncores = 0,\n  cp_freq = -1,\n  recursive = TRUE,\n  resume = FALSE){\n\n  if(detector_model == \"default\"){\n    detector_model <- paste(system.file(\"models\", package = \"ctww\", mustWork = T), \"md_v4.1.0.pb\", sep = \"/\")\n  }else if(stringr::str_detect(detector_model,pattern=\".pb\") == F){\n    stop(\"Error: Invalid detector model, must be a *.pb file!\")\n  }\n  if(length(dir(image_path)) < 1){stop(\"Error: No images in file path\")}\n\n  print(\"Initializing Python...\")\n  if(reticulate::py_version() == \"3.7\"){\n    reticulate::py_available(initialize = T)\n  }else{\n    pyversions <- reticulate::py_versions_windows()\n    if(\"3.7\" %in% pyversions$version){\n      reticulate::use_python(python = pyversions[pyversions[\"version\"]==\"3.7\",][[\"executable_path\"]][[1]])\n      reticulate::py_available(initialize = T)\n    }else{stop(\"Python 3.7 not detected: Please install in Terminal with 'conda install python=3.7'\")}\n  }\n\n  print(\"Loading Batch MegaDetector...\")\n  reticulate::source_python(paste(system.file(\"python\", package = \"ctww\", mustWork = T), \"run_batch_megadetector.py\", sep = \"/\"))\n\n  print(\"Reticulating MegaDetector on Images...\")\n  run_megadetector_batch(detector_file = detector_model,\n                         image_file = image_path,\n                         output_file = out_file,\n                         confidence_threshold = threshold,\n                         checkpoint_frequency = cp_freq,\n                         n_cores = as.integer(ncores),\n                         recurse = recursive,\n                         relative = TRUE,\n                         resume_from_checkpoint = resume)\n  print(\"Done\")\n}\n\n“run_batch_megadetector.py” was modified from Microsoft’s AI for Earth open-source code. This file is modified to ensure all of the proper environmental components and constants are imported together. I also modified the code to run as a function rather than command line, which enables it to be called into via ‘reticulate’ (see above).\n\n#----------------------------------------#\n#--- Essential MegaDetector Utilities ---#\n#----------------------------------------#\n#%% Constants, imports, environment\nimport argparse\nimport glob\nimport os\nimport statistics\nimport sys\nimport time\nimport warnings\nimport humanfriendly\nimport numpy as np\nfrom tqdm import tqdm\nfrom multiprocessing import Pool as workerpool\nfrom datetime import datetime\nfrom functools import partial\nimport itertools\nimport copy\nimport json\nimport inspect\nimport math\nimport jsonpickle\nfrom io import BytesIO\nfrom typing import Union\nimport matplotlib.pyplot as plt\nimport requests\nfrom PIL import Image, ImageFile, ImageFont, ImageDraw\n\n#%% Set Environment\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" #Turn off any GPUs\nos.environ.pop('TF_CONFIG',None) #Reset TensoerFlow Configuration\n\n#% Import and configure TensorFlow\nimport tensorflow as tf\nprint('TensorFlow version:', tf.__version__)\ntf.enable_eager_execution()\nprint('TensorFlow Executing Eagerly:',tf.executing_eagerly())\nconfig = tf.ConfigProto(intra_op_parallelism_threads=os.cpu_count(),\n                        inter_op_parallelism_threads=2,\n                        allow_soft_placement=True,\n                        device_count= {'CPU': os.cpu_count()})\nprint('TensorFlow Device Count:', config.device_count)\nprint('TensorFlow Inter Op Parallelism Threads:', config.inter_op_parallelism_threads)\nprint('TensorFlow Intra Op Parallelism Threads:', config.intra_op_parallelism_threads)\n\n#%% CT Utilities %%#\ndef truncate_float_array(xs, precision=3):\n    \"\"\"\n    Vectorized version of truncate_float(...)\n\n    Args:\n    x         (list of float) List of floats to truncate\n    precision (int)           The number of significant digits to preserve, should be\n                              greater or equal 1\n    \"\"\"\n\n    return [truncate_float(x, precision=precision) for x in xs]\n\n\ndef truncate_float(x, precision=3):\n    \"\"\"\n    Function for truncating a float scalar to the defined precision.\n    For example: truncate_float(0.0003214884) --> 0.000321\n    This function is primarily used to achieve a certain float representation\n    before exporting to JSON\n\n    Args:\n    x         (float) Scalar to truncate\n    precision (int)   The number of significant digits to preserve, should be\n                      greater or equal 1\n    \"\"\"\n\n    assert precision > 0\n\n    if np.isclose(x, 0):\n        return 0\n    else:\n        # Determine the factor, which shifts the decimal point of x\n        # just behind the last significant digit\n        factor = math.pow(10, precision - 1 - math.floor(math.log10(abs(x))))\n        # Shift decimal point by multiplicatipon with factor, flooring, and\n        # division by factor\n        return math.floor(x * factor)/factor\n      \n\ndef write_json(path, content, indent=1):\n    with open(path, 'w') as f:\n        json.dump(content, f, indent=indent)\n\n\nimage_extensions = ['.jpg', '.jpeg', '.gif', '.png']\n\n\ndef is_image_file(s):\n    \"\"\"\n    Check a file's extension against a hard-coded set of image file extensions\n    \"\"\"\n\n    ext = os.path.splitext(s)[1]\n    return ext.lower() in image_extensions\n\n\ndef convert_xywh_to_tf(api_box):\n    \"\"\"\n    Converts an xywh bounding box to an [y_min, x_min, y_max, x_max] box that the TensorFlow\n    Object Detection API uses\n\n    Args:\n        api_box: bbox output by the batch processing API [x_min, y_min, width_of_box, height_of_box]\n\n    Returns:\n        bbox with coordinates represented as [y_min, x_min, y_max, x_max]\n    \"\"\"\n    x_min, y_min, width_of_box, height_of_box = api_box\n    x_max = x_min + width_of_box\n    y_max = y_min + height_of_box\n    return [y_min, x_min, y_max, x_max]\n\n\ndef convert_xywh_to_xyxy(api_bbox):\n    \"\"\"\n    Converts an xywh bounding box to an xyxy bounding box.\n\n    Note that this is also different from the TensorFlow Object Detection API coords format.\n    Args:\n        api_bbox: bbox output by the batch processing API [x_min, y_min, width_of_box, height_of_box]\n\n    Returns:\n        bbox with coordinates represented as [x_min, y_min, x_max, y_max]\n    \"\"\"\n\n    x_min, y_min, width_of_box, height_of_box = api_bbox\n    x_max, y_max = x_min + width_of_box, y_min + height_of_box\n    return [x_min, y_min, x_max, y_max]\n\n\ndef get_iou(bb1, bb2):\n    \"\"\"\n    Calculate the Intersection over Union (IoU) of two bounding boxes.\n\n    Adapted from: https://stackoverflow.com/questions/25349178/calculating-percentage-of-bounding-box-overlap-for-image-detector-evaluation\n\n    Args:\n        bb1: [x_min, y_min, width_of_box, height_of_box]\n        bb2: [x_min, y_min, width_of_box, height_of_box]\n\n    These will be converted to\n\n    bb1: [x1,y1,x2,y2]\n    bb2: [x1,y1,x2,y2]\n\n    The (x1, y1) position is at the top left corner (or the bottom right - either way works).\n    The (x2, y2) position is at the bottom right corner (or the top left).\n\n    Returns:\n        intersection_over_union, a float in [0, 1]\n    \"\"\"\n\n    bb1 = convert_xywh_to_xyxy(bb1)\n    bb2 = convert_xywh_to_xyxy(bb2)\n\n    assert bb1[0] < bb1[2], 'Malformed bounding box (x2 >= x1)'\n    assert bb1[1] < bb1[3], 'Malformed bounding box (y2 >= y1)'\n\n    assert bb2[0] < bb2[2], 'Malformed bounding box (x2 >= x1)'\n    assert bb2[1] < bb2[3], 'Malformed bounding box (y2 >= y1)'\n\n    # Determine the coordinates of the intersection rectangle\n    x_left = max(bb1[0], bb2[0])\n    y_top = max(bb1[1], bb2[1])\n    x_right = min(bb1[2], bb2[2])\n    y_bottom = min(bb1[3], bb2[3])\n\n    if x_right < x_left or y_bottom < y_top:\n        return 0.0\n\n    # The intersection of two axis-aligned bounding boxes is always an\n    # axis-aligned bounding box\n    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n\n    # Compute the area of both AABBs\n    bb1_area = (bb1[2] - bb1[0]) * (bb1[3] - bb1[1])\n    bb2_area = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])\n\n    # Compute the intersection over union by taking the intersection\n    # area and dividing it by the sum of prediction + ground-truth\n    # areas - the intersection area.\n    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n    assert iou >= 0.0, 'Illegal IOU < 0'\n    assert iou <= 1.0, 'Illegal IOU > 1'\n    return iou\n\n\n\n\n#%% Annotation Constants %%#\nNUM_DETECTOR_CATEGORIES = 3  # this is for choosing colors, so ignoring the \"empty\" class\n\n# This is the label mapping used for our incoming iMerit annotations\n# Only used to parse the incoming annotations. In our database, the string name is used to avoid confusion\nannotation_bbox_categories = [\n    {'id': 0, 'name': 'empty'},\n    {'id': 1, 'name': 'animal'},\n    {'id': 2, 'name': 'person'},\n    {'id': 3, 'name': 'group'},  # group of animals\n    {'id': 4, 'name': 'vehicle'}\n]\n\nannotation_bbox_category_id_to_name = {}\nannotation_bbox_category_name_to_id = {}\n\nfor cat in annotation_bbox_categories:\n    annotation_bbox_category_id_to_name[cat['id']] = cat['name']\n    annotation_bbox_category_name_to_id[cat['name']] = cat['id']\n\n# MegaDetector outputs\ndetector_bbox_categories = [\n    {'id': 0, 'name': 'empty'},\n    {'id': 1, 'name': 'animal'},\n    {'id': 2, 'name': 'person'},\n    {'id': 3, 'name': 'vehicle'}\n]\n\ndetector_bbox_category_id_to_name = {}\ndetector_bbox_category_name_to_id = {}\n\nfor cat in detector_bbox_categories:\n    detector_bbox_category_id_to_name[cat['id']] = cat['name']\n    detector_bbox_category_name_to_id[cat['name']] = cat['id']\n\n\n#%% Visualization Utilities %%#\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nIMAGE_ROTATIONS = {\n    3: 180,\n    6: 270,\n    8: 90\n}\n\n# convert category ID from int to str\nDEFAULT_DETECTOR_LABEL_MAP = {\n    str(k): v for k, v in detector_bbox_category_id_to_name.items()\n}\n\n# Retry on blob storage read failures\nn_retries = 10\nretry_sleep_time = 0.01\nerror_names_for_retry = ['ConnectionError']\n\ndef open_image(input_file: Union[str, BytesIO]) -> Image:\n    \"\"\"\n    Opens an image in binary format using PIL.Image and converts to RGB mode.\n\n    This operation is lazy; image will not be actually loaded until the first\n    operation that needs to load it (for example, resizing), so file opening\n    errors can show up later.\n\n    Args:\n        input_file: str or BytesIO, either a path to an image file (anything\n            that PIL can open), or an image as a stream of bytes\n\n    Returns:\n        an PIL image object in RGB mode\n    \"\"\"\n    if (isinstance(input_file, str)\n            and input_file.startswith(('http://', 'https://'))):\n        try:\n            response = requests.get(input_file)\n        except Exception as e:\n            print(f'Error retrieving image {input_file}: {e}')\n            success = False\n            if e.__class__.__name__ in error_names_for_retry:\n                for i_retry in range(0,n_retries):\n                    try:\n                        time.sleep(retry_sleep_time)\n                        response = requests.get(input_file)        \n                    except Exception as e:\n                        print(f'Error retrieving image {input_file} on retry {i_retry}: {e}')\n                        continue\n                    print('Succeeded on retry {}'.format(i_retry))\n                    success = True\n                    break\n            if not success:\n                raise\n        try:\n            image = Image.open(BytesIO(response.content))\n        except Exception as e:\n            print(f'Error opening image {input_file}: {e}')\n            raise\n\n    else:\n        image = Image.open(input_file)\n    if image.mode not in ('RGBA', 'RGB', 'L', 'I;16'):\n        raise AttributeError(\n            f'Image {input_file} uses unsupported mode {image.mode}')\n    if image.mode == 'RGBA' or image.mode == 'L':\n        # PIL.Image.convert() returns a converted copy of this image\n        image = image.convert(mode='RGB')\n\n    # Alter orientation as needed according to EXIF tag 0x112 (274) for Orientation\n    #\n    # https://gist.github.com/dangtrinhnt/a577ece4cbe5364aad28\n    # https://www.media.mit.edu/pia/Research/deepview/exif.html\n    #\n    try:\n        exif = image._getexif()\n        orientation: int = exif.get(274, None)  # 274 is the key for the Orientation field\n        if orientation is not None and orientation in IMAGE_ROTATIONS:\n            image = image.rotate(IMAGE_ROTATIONS[orientation], expand=True)  # returns a rotated copy\n    except Exception:\n        pass\n\n    return image\n\ndef load_image(input_file: Union[str, BytesIO]) -> Image:\n    \"\"\"\n    Loads the image at input_file as a PIL Image into memory.\n\n    Image.open() used in open_image() is lazy and errors will occur downstream\n    if not explicitly loaded.\n\n    Args:\n        input_file: str or BytesIO, either a path to an image file (anything\n            that PIL can open), or an image as a stream of bytes\n\n    Returns: PIL.Image.Image, in RGB mode\n    \"\"\"\n    image = open_image(input_file)\n    image.load()\n    return image\n\n\ndef resize_image(image, target_width, target_height=-1):\n    \"\"\"\n    Resizes a PIL image object to the specified width and height; does not resize\n    in place. If either width or height are -1, resizes with aspect ratio preservation.\n    If both are -1, returns the original image (does not copy in this case).\n    \"\"\"\n\n    # Null operation\n    if target_width == -1 and target_height == -1:\n        return image\n\n    elif target_width == -1 or target_height == -1:\n\n        # Aspect ratio as width over height\n        # ar = w / h\n        aspect_ratio = image.size[0] / image.size[1]\n\n        if target_width != -1:\n            # h = w / ar\n            target_height = int(target_width / aspect_ratio)\n        else:\n            # w = ar * h\n            target_width = int(aspect_ratio * target_height)\n\n    resized_image = image.resize((target_width, target_height), Image.ANTIALIAS)\n    return resized_image\n\n\ndef show_images_in_a_row(images):\n\n    num = len(images)\n    assert num > 0\n\n    if isinstance(images[0], str):\n        images = [Image.open(img) for img in images]\n\n    fig, axarr = plt.subplots(1, num, squeeze=False)  # number of rows, number of columns\n    fig.set_size_inches((num * 5, 25))  # each image is 2 inches wide\n    for i, img in enumerate(images):\n        axarr[0, i].set_axis_off()\n        axarr[0, i].imshow(img)\n    return fig\n\n\n# The following three functions are modified versions of those at:\n# https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py\n\nCOLORS = [\n    'AliceBlue', 'Red', 'RoyalBlue', 'Gold', 'Chartreuse', 'Aqua', 'Azure',\n    'Beige', 'Bisque', 'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue',\n    'AntiqueWhite', 'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson',\n    'Cyan', 'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'GoldenRod',\n    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n    'RosyBrown', 'Aquamarine', 'SaddleBrown', 'Green', 'SandyBrown',\n    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n    'WhiteSmoke', 'Yellow', 'YellowGreen'\n]\n\n\ndef crop_image(detections, image, confidence_threshold=0.8, expansion=0):\n    \"\"\"\n    Crops detections above *confidence_threshold* from the PIL image *image*,\n    returning a list of PIL images.\n\n    *detections* should be a list of dictionaries with keys 'conf' and 'bbox';\n    see bbox format description below.  Normalized, [x,y,w,h], upper-left-origin.\n\n    *expansion* specifies a number of pixels to include on each side of the box.\n    \"\"\"\n\n    ret_images = []\n\n    for detection in detections:\n\n        score = float(detection['conf'])\n\n        if score >= confidence_threshold:\n\n            x1, y1, w_box, h_box = detection['bbox']\n            ymin,xmin,ymax,xmax = y1, x1, y1 + h_box, x1 + w_box\n\n            # Convert to pixels so we can use the PIL crop() function\n            im_width, im_height = image.size\n            (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                          ymin * im_height, ymax * im_height)\n\n            if expansion > 0:\n                left -= expansion\n                right += expansion\n                top -= expansion\n                bottom += expansion\n\n            # PIL's crop() does surprising things if you provide values outside of\n            # the image, clip inputs\n            left = max(left,0); right = max(right,0)\n            top = max(top,0); bottom = max(bottom,0)\n\n            left = min(left,im_width-1); right = min(right,im_width-1)\n            top = min(top,im_height-1); bottom = min(bottom,im_height-1)\n\n            ret_images.append(image.crop((left, top, right, bottom)))\n\n        # ...if this detection is above threshold\n\n    # ...for each detection\n\n    return ret_images\n\n\ndef render_detection_bounding_boxes(detections, image,\n                                    label_map={},\n                                    classification_label_map={},\n                                    confidence_threshold=0.8, thickness=4, expansion=0,\n                                    classification_confidence_threshold=0.3,\n                                    max_classifications=3):\n    \"\"\"\n    Renders bounding boxes, label, and confidence on an image if confidence is above the threshold.\n\n    This works with the output of the batch processing API.\n\n    Supports classification, if the detection contains classification results according to the\n    API output version 1.0.\n\n    Args:\n\n        detections: detections on the image, example content:\n            [\n                {\n                    \"category\": \"2\",\n                    \"conf\": 0.996,\n                    \"bbox\": [\n                        0.0,\n                        0.2762,\n                        0.1234,\n                        0.2458\n                    ]\n                }\n            ]\n\n            ...where the bbox coordinates are [x, y, box_width, box_height].\n\n            (0, 0) is the upper-left.  Coordinates are normalized.\n\n            Supports classification results, if *detections* have the format\n            [\n                {\n                    \"category\": \"2\",\n                    \"conf\": 0.996,\n                    \"bbox\": [\n                        0.0,\n                        0.2762,\n                        0.1234,\n                        0.2458\n                    ]\n                    \"classifications\": [\n                        [\"3\", 0.901],\n                        [\"1\", 0.071],\n                        [\"4\", 0.025]\n                    ]\n                }\n            ]\n\n        image: PIL.Image object, output of generate_detections.\n\n        label_map: optional, mapping the numerical label to a string name. The type of the numerical label\n            (default string) needs to be consistent with the keys in label_map; no casting is carried out.\n\n        classification_label_map: optional, mapping of the string class labels to the actual class names.\n            The type of the numerical label (default string) needs to be consistent with the keys in\n            label_map; no casting is carried out.\n\n        confidence_threshold: optional, threshold above which the bounding box is rendered.\n        thickness: line thickness in pixels. Default value is 4.\n        expansion: number of pixels to expand bounding boxes on each side.  Default is 0.\n        classification_confidence_threshold: confidence above which classification result is retained.\n        max_classifications: maximum number of classification results retained for one image.\n\n    image is modified in place.\n    \"\"\"\n\n    display_boxes = []\n    display_strs = []  # list of lists, one list of strings for each bounding box (to accommodate multiple labels)\n    classes = []  # for color selection\n\n    for detection in detections:\n\n        score = detection['conf']\n        if score >= confidence_threshold:\n\n            x1, y1, w_box, h_box = detection['bbox']\n            display_boxes.append([y1, x1, y1 + h_box, x1 + w_box])\n            clss = detection['category']\n            label = label_map[clss] if clss in label_map else clss\n            displayed_label = ['{}: {}%'.format(label, round(100 * score))]\n\n            if 'classifications' in detection:\n\n                # To avoid duplicate colors with detection-only visualization, offset\n                # the classification class index by the number of detection classes\n                clss = NUM_DETECTOR_CATEGORIES + int(detection['classifications'][0][0])\n                classifications = detection['classifications']\n                if len(classifications) > max_classifications:\n                    classifications = classifications[0:max_classifications]\n                for classification in classifications:\n                    p = classification[1]\n                    if p < classification_confidence_threshold:\n                        continue\n                    class_key = classification[0]\n                    if class_key in classification_label_map:\n                        class_name = classification_label_map[class_key]\n                    else:\n                        class_name = class_key\n                    displayed_label += ['{}: {:5.1%}'.format(class_name.lower(), classification[1])]\n\n            # ...if we have detection results\n            display_strs.append(displayed_label)\n            classes.append(clss)\n\n        # ...if the confidence of this detection is above threshold\n\n    # ...for each detection\n    display_boxes = np.array(display_boxes)\n\n    draw_bounding_boxes_on_image(image, display_boxes, classes,\n                                 display_strs=display_strs, thickness=thickness, expansion=expansion)\n\n\ndef draw_bounding_boxes_on_image(image,\n                                 boxes,\n                                 classes,\n                                 thickness=4,\n                                 expansion=0,\n                                 display_strs=()):\n    \"\"\"\n    Draws bounding boxes on an image.\n\n    Args:\n      image: a PIL.Image object.\n      boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n             The coordinates are in normalized format between [0, 1].\n      classes: a list of ints or strings (that can be cast to ints) corresponding to the class labels of the boxes.\n             This is only used for selecting the color to render the bounding box in.\n      thickness: line thickness in pixels. Default value is 4.\n      expansion: number of pixels to expand bounding boxes on each side.  Default is 0.\n      display_strs: list of list of strings.\n                             a list of strings for each bounding box.\n                             The reason to pass a list of strings for a\n                             bounding box is that it might contain\n                             multiple labels.\n    \"\"\"\n\n    boxes_shape = boxes.shape\n    if not boxes_shape:\n        return\n    if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n        # print('Input must be of size [N, 4], but is ' + str(boxes_shape))\n        return  # no object detection on this image, return\n    for i in range(boxes_shape[0]):\n        if display_strs:\n            display_str_list = display_strs[i]\n            draw_bounding_box_on_image(image,\n                                       boxes[i, 0], boxes[i, 1], boxes[i, 2], boxes[i, 3],\n                                       classes[i],\n                                       thickness=thickness, expansion=expansion,\n                                       display_str_list=display_str_list)\n\n\ndef draw_bounding_box_on_image(image,\n                               ymin,\n                               xmin,\n                               ymax,\n                               xmax,\n                               clss=None,\n                               thickness=4,\n                               expansion=0,\n                               display_str_list=(),\n                               use_normalized_coordinates=True,\n                               label_font_size=16):\n    \"\"\"\n    Adds a bounding box to an image.\n\n    Bounding box coordinates can be specified in either absolute (pixel) or\n    normalized coordinates by setting the use_normalized_coordinates argument.\n\n    Each string in display_str_list is displayed on a separate line above the\n    bounding box in black text on a rectangle filled with the input 'color'.\n    If the top of the bounding box extends to the edge of the image, the strings\n    are displayed below the bounding box.\n\n    Args:\n    image: a PIL.Image object.\n    ymin: ymin of bounding box - upper left.\n    xmin: xmin of bounding box.\n    ymax: ymax of bounding box.\n    xmax: xmax of bounding box.\n    clss: str, the class of the object in this bounding box - will be cast to an int.\n    thickness: line thickness. Default value is 4.\n    expansion: number of pixels to expand bounding boxes on each side.  Default is 0.\n    display_str_list: list of strings to display in box\n        (each to be shown on its own line).\n        use_normalized_coordinates: If True (default), treat coordinates\n        ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n        coordinates as absolute.\n    label_font_size: font size to attempt to load arial.ttf with\n    \"\"\"\n    if clss is None:\n        color = COLORS[1]\n    else:\n        color = COLORS[int(clss) % len(COLORS)]\n\n    draw = ImageDraw.Draw(image)\n    im_width, im_height = image.size\n    if use_normalized_coordinates:\n        (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                      ymin * im_height, ymax * im_height)\n    else:\n        (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n\n    if expansion > 0:\n        left -= expansion\n        right += expansion\n        top -= expansion\n        bottom += expansion\n\n        # Deliberately trimming to the width of the image only in the case where\n        # box expansion is turned on.  There's not an obvious correct behavior here,\n        # but the thinking is that if the caller provided an out-of-range bounding\n        # box, they meant to do that, but at least in the eyes of the person writing\n        # this comment, if you expand a box for visualization reasons, you don't want\n        # to end up with part of a box.\n        #\n        # A slightly more sophisticated might check whether it was in fact the expansion\n        # that made this box larger than the image, but this is the case 99.999% of the time\n        # here, so that doesn't seem necessary.\n        left = max(left,0); right = max(right,0)\n        top = max(top,0); bottom = max(bottom,0)\n\n        left = min(left,im_width-1); right = min(right,im_width-1)\n        top = min(top,im_height-1); bottom = min(bottom,im_height-1)\n\n    draw.line([(left, top), (left, bottom), (right, bottom),\n               (right, top), (left, top)], width=thickness, fill=color)\n\n    try:\n        font = ImageFont.truetype('arial.ttf', label_font_size)\n    except IOError:\n        font = ImageFont.load_default()\n\n    # If the total height of the display strings added to the top of the bounding\n    # box exceeds the top of the image, stack the strings below the bounding box\n    # instead of above.\n    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n\n    # Each display_str has a top and bottom margin of 0.05x.\n    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n\n    if top > total_display_str_height:\n        text_bottom = top\n    else:\n        text_bottom = bottom + total_display_str_height\n\n    # Reverse list and print from bottom to top.\n    for display_str in display_str_list[::-1]:\n        text_width, text_height = font.getsize(display_str)\n        margin = np.ceil(0.05 * text_height)\n\n        draw.rectangle(\n            [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n                                                              text_bottom)],\n            fill=color)\n\n        draw.text(\n            (left + margin, text_bottom - text_height - margin),\n            display_str,\n            fill='black',\n            font=font)\n\n        text_bottom -= (text_height + 2 * margin)\n\n\ndef render_iMerit_boxes(boxes, classes, image,\n                        label_map=annotation_bbox_category_id_to_name):\n    \"\"\"\n    Renders bounding boxes and their category labels on a PIL image.\n\n    Args:\n        boxes: bounding box annotations from iMerit, format is [x_rel, y_rel, w_rel, h_rel] (rel = relative coords)\n        classes: the class IDs of the predicted class of each box/object\n        image: PIL.Image object to annotate on\n        label_map: optional dict mapping classes to a string for display\n\n    Returns:\n        image will be altered in place\n    \"\"\"\n\n    display_boxes = []\n    display_strs = []  # list of list, one list of strings for each bounding box (to accommodate multiple labels)\n    for box, clss in zip(boxes, classes):\n        if len(box) == 0:\n            assert clss == 5\n            continue\n        x_rel, y_rel, w_rel, h_rel = box\n        ymin, xmin = y_rel, x_rel\n        ymax = ymin + h_rel\n        xmax = xmin + w_rel\n\n        display_boxes.append([ymin, xmin, ymax, xmax])\n\n        if label_map:\n            clss = label_map[int(clss)]\n        display_strs.append([clss])\n\n    display_boxes = np.array(display_boxes)\n    draw_bounding_boxes_on_image(image, display_boxes, classes, display_strs=display_strs)\n\n\ndef render_megadb_bounding_boxes(boxes_info, image):\n    \"\"\"\n    Args:\n        boxes_info: list of dict, each dict represents a single detection\n            {\n                \"category\": \"animal\",\n                \"bbox\": [\n                    0.739,\n                    0.448,\n                    0.187,\n                    0.198\n                ]\n            }\n            where bbox coordinates are normalized [x_min, y_min, width, height]\n        image: PIL.Image.Image, opened image\n    \"\"\"\n    display_boxes = []\n    display_strs = []\n    classes = []  # ints, for selecting colors\n\n    for b in boxes_info:\n        x_min, y_min, w_rel, h_rel = b['bbox']\n        y_max = y_min + h_rel\n        x_max = x_min + w_rel\n        display_boxes.append([y_min, x_min, y_max, x_max])\n        display_strs.append([b['category']])\n        classes.append(detector_bbox_category_name_to_id[b['category']])\n\n    display_boxes = np.array(display_boxes)\n    draw_bounding_boxes_on_image(image, display_boxes, classes, display_strs=display_strs)\n\n\ndef render_db_bounding_boxes(boxes, classes, image, original_size=None,\n                             label_map=None, thickness=4, expansion=0):\n    \"\"\"\n    Render bounding boxes (with class labels) on [image].  This is a wrapper for\n    draw_bounding_boxes_on_image, allowing the caller to operate on a resized image\n    by providing the original size of the image; bboxes will be scaled accordingly.\n    \"\"\"\n\n    display_boxes = []\n    display_strs = []\n\n    if original_size is not None:\n        image_size = original_size\n    else:\n        image_size = image.size\n\n    img_width, img_height = image_size\n\n    for box, clss in zip(boxes, classes):\n\n        x_min_abs, y_min_abs, width_abs, height_abs = box\n\n        ymin = y_min_abs / img_height\n        ymax = ymin + height_abs / img_height\n\n        xmin = x_min_abs / img_width\n        xmax = xmin + width_abs / img_width\n\n        display_boxes.append([ymin, xmin, ymax, xmax])\n\n        if label_map:\n            clss = label_map[int(clss)]\n        display_strs.append([str(clss)])  # need to be a string here because PIL needs to iterate through chars\n\n    display_boxes = np.array(display_boxes)\n    draw_bounding_boxes_on_image(image, display_boxes, classes, display_strs=display_strs,\n                                 thickness=thickness, expansion=expansion)\n\n\ndef draw_bounding_boxes_on_file(input_file, output_file, detections, confidence_threshold=0.0,\n                                detector_label_map=DEFAULT_DETECTOR_LABEL_MAP):\n    \"\"\"\n    Render detection bounding boxes on an image loaded from file, writing the results to a\n    new images file.  \"detections\" is in the API results format.\n    \"\"\"\n    \n    image = open_image(input_file)\n\n    render_detection_bounding_boxes(\n            detections, image, label_map=detector_label_map,\n            confidence_threshold=confidence_threshold)\n\n    image.save(output_file)\n\n\n#%% Classes %%#\nclass ImagePathUtils:\n    \"\"\"A collection of utility functions supporting this stand-alone script\"\"\"\n\n    # Stick this into filenames before the extension for the rendered result\n    DETECTION_FILENAME_INSERT = '_detections'\n\n    image_extensions = ['.jpg', '.jpeg', '.gif', '.png']\n\n    @staticmethod\n    def is_image_file(s):\n        \"\"\"\n        Check a file's extension against a hard-coded set of image file extensions\n        \"\"\"\n        ext = os.path.splitext(s)[1]\n        return ext.lower() in ImagePathUtils.image_extensions\n\n    @staticmethod\n    def find_image_files(strings):\n        \"\"\"\n        Given a list of strings that are potentially image file names, look for strings\n        that actually look like image file names (based on extension).\n        \"\"\"\n        return [s for s in strings if ImagePathUtils.is_image_file(s)]\n\n    @staticmethod\n    def find_images(dir_name, recursive=False):\n        \"\"\"\n        Find all files in a directory that look like image file names\n        \"\"\"\n        if recursive:\n            strings = glob.glob(os.path.join(dir_name, '**', '*.*'), recursive=True)\n        else:\n            strings = glob.glob(os.path.join(dir_name, '*.*'))\n\n        image_strings = ImagePathUtils.find_image_files(strings)\n\n        return image_strings\n\nclass TFDetector:\n    \"\"\"\n    A detector model loaded at the time of initialization. It is intended to be used with\n    the MegaDetector (TF). The inference batch size is set to 1; code needs to be modified\n    to support larger batch sizes, including resizing appropriately.\n    \"\"\"\n\n    # Number of decimal places to round to for confidence and bbox coordinates\n    CONF_DIGITS = 3\n    COORD_DIGITS = 4\n\n    # MegaDetector was trained with batch size of 1, and the resizing function is a part\n    # of the inference graph\n    BATCH_SIZE = 1\n\n    # An enumeration of failure reasons\n    FAILURE_TF_INFER = 'Failure TF inference'\n    FAILURE_IMAGE_OPEN = 'Failure image access'\n\n    DEFAULT_RENDERING_CONFIDENCE_THRESHOLD = 0.85  # to render bounding boxes\n    DEFAULT_OUTPUT_CONFIDENCE_THRESHOLD = 0.1  # to include in the output json file\n\n    DEFAULT_DETECTOR_LABEL_MAP = {\n        '1': 'animal',\n        '2': 'person',\n        '3': 'vehicle'  # available in megadetector v4+\n    }\n\n    NUM_DETECTOR_CATEGORIES = 4  # animal, person, group, vehicle - for color assignment\n\n    def __init__(self, model_path):\n        \"\"\"Loads model from model_path and starts a tf.Session with this graph. Obtains\n        input and output tensor handles.\"\"\"\n        detection_graph = TFDetector.__load_model(model_path)\n        self.tf_session = tf.Session(config=config,graph=detection_graph) #add configuration and graph\n        self.image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n        self.box_tensor = detection_graph.get_tensor_by_name('detection_boxes:0')\n        self.score_tensor = detection_graph.get_tensor_by_name('detection_scores:0')\n        self.class_tensor = detection_graph.get_tensor_by_name('detection_classes:0')\n\n    @staticmethod\n    def round_and_make_float(d, precision=4):\n        return truncate_float(float(d), precision=precision)\n\n    @staticmethod\n    def __convert_coords(tf_coords):\n        \"\"\"Converts coordinates from the model's output format [y1, x1, y2, x2] to the\n        format used by our API and MegaDB: [x1, y1, width, height]. All coordinates\n        (including model outputs) are normalized in the range [0, 1].\n\n        Args:\n            tf_coords: np.array of predicted bounding box coordinates from the TF detector,\n                has format [y1, x1, y2, x2]\n\n        Returns: list of Python float, predicted bounding box coordinates [x1, y1, width, height]\n        \"\"\"\n        # change from [y1, x1, y2, x2] to [x1, y1, width, height]\n        width = tf_coords[3] - tf_coords[1]\n        height = tf_coords[2] - tf_coords[0]\n\n        new = [tf_coords[1], tf_coords[0], width, height]  # must be a list instead of np.array\n\n        # convert numpy floats to Python floats\n        for i, d in enumerate(new):\n            new[i] = TFDetector.round_and_make_float(d, precision=TFDetector.COORD_DIGITS)\n        return new\n\n    @staticmethod\n    def convert_to_tf_coords(array):\n        \"\"\"From [x1, y1, width, height] to [y1, x1, y2, x2], where x1 is x_min, x2 is x_max\n\n        This is an extraneous step as the model outputs [y1, x1, y2, x2] but were converted to the API\n        output format - only to keep the interface of the sync API.\n        \"\"\"\n        x1 = array[0]\n        y1 = array[1]\n        width = array[2]\n        height = array[3]\n        x2 = x1 + width\n        y2 = y1 + height\n        return [y1, x1, y2, x2]\n\n    @staticmethod\n    def __load_model(model_path):\n        \"\"\"Loads a detection model (i.e., create a graph) from a .pb file.\n\n        Args:\n            model_path: .pb file of the model.\n\n        Returns: the loaded graph.\n        \"\"\"\n        print('TFDetector: Loading graph...')\n        detection_graph = tf.Graph()\n        with detection_graph.as_default():\n            od_graph_def = tf.GraphDef()\n            with tf.gfile.GFile(model_path, 'rb') as fid:\n                serialized_graph = fid.read()\n                od_graph_def.ParseFromString(serialized_graph)\n                tf.import_graph_def(od_graph_def, name='')\n        print('TFDetector: Detection graph loaded.')\n\n        return detection_graph\n\n    def _generate_detections_one_image(self, image):\n        np_im = np.asarray(image, np.uint8)\n        im_w_batch_dim = np.expand_dims(np_im, axis=0)\n\n        # need to change the above line to the following if supporting a batch size > 1 and resizing to the same size\n        # np_images = [np.asarray(image, np.uint8) for image in images]\n        # images_stacked = np.stack(np_images, axis=0) if len(images) > 1 else np.expand_dims(np_images[0], axis=0)\n\n        # performs inference\n        (box_tensor_out, score_tensor_out, class_tensor_out) = self.tf_session.run(\n            [self.box_tensor, self.score_tensor, self.class_tensor],\n            feed_dict={self.image_tensor: im_w_batch_dim})\n\n        return box_tensor_out, score_tensor_out, class_tensor_out\n\n    def generate_detections_one_image(self, image, image_id,\n                                      detection_threshold=DEFAULT_OUTPUT_CONFIDENCE_THRESHOLD):\n        \"\"\"Apply the detector to an image.\n\n        Args:\n            image: the PIL Image object\n            image_id: a path to identify the image; will be in the \"file\" field of the output object\n            detection_threshold: confidence above which to include the detection proposal\n\n        Returns:\n        A dict with the following fields, see the 'images' key in https://github.com/microsoft/CameraTraps/tree/master/api/batch_processing#batch-processing-api-output-format\n            - 'file' (always present)\n            - 'max_detection_conf'\n            - 'detections', which is a list of detection objects containing keys 'category', 'conf' and 'bbox'\n            - 'failure'\n        \"\"\"\n        result = {\n            'file': image_id\n        }\n        try:\n            b_box, b_score, b_class = self._generate_detections_one_image(image)\n\n            # our batch size is 1; need to loop the batch dim if supporting batch size > 1\n            boxes, scores, classes == b_box[0], b_score[0], b_class[0]\n\n            detections_cur_image = []  # will be empty for an image with no confident detections\n            max_detection_conf = 0.0\n            for b, s, c in zip(boxes, scores, classes):\n                if s > detection_threshold:\n                    detection_entry = {\n                        'category': str(int(c)),  # use string type for the numerical class label, not int\n                        'conf': truncate_float(float(s),  # cast to float for json serialization\n                                               precision=TFDetector.CONF_DIGITS),\n                        'bbox': TFDetector.__convert_coords(b)\n                    }\n                    detections_cur_image.append(detection_entry)\n                    if s > max_detection_conf:\n                        max_detection_conf = s\n\n            result['max_detection_conf'] = truncate_float(float(max_detection_conf),\n                                                          precision=TFDetector.CONF_DIGITS)\n            result['detections'] = detections_cur_image\n\n        except Exception as e:\n            result['failure'] = TFDetector.FAILURE_TF_INFER\n            print('TFDetector: image {} failed during inference: {}'.format(image_id, str(e)))\n\n        return result\n\n\n#%% Support functions for multiprocessing %%#\ndef process_images(im_files, tf_detector, confidence_threshold):\n    \"\"\"Runs the MegaDetector over a list of image files.\n\n    Args\n    - im_files: list of str, paths to image files\n    - tf_detector: TFDetector (loaded model) or str (path to .pb model file)\n    - confidence_threshold: float, only detections above this threshold are returned\n\n    Returns\n    - results: list of dict, each dict represents detections on one image\n        see the 'images' key in https://github.com/microsoft/CameraTraps/tree/master/api/batch_processing#batch-processing-api-output-format\n    \"\"\"\n    if isinstance(tf_detector, str):\n        start_time = time.time()\n        tf_detector = TFDetector(tf_detector)\n        elapsed = time.time() - start_time\n        #print('Loaded model (batch level) in {}'.format(humanfriendly.format_timespan(elapsed)))\n\n    results = []\n    for im_file in im_files:\n        results.append(process_image(im_file, tf_detector, confidence_threshold))\n    return results\n\n\ndef process_image(im_file, tf_detector, confidence_threshold):\n    \"\"\"Runs the MegaDetector over a single image file. Modified for multiprocessing...\n\n    Args\n    - im_file: str, path to image file\n    - tf_detector: TFDetector, loaded model\n    - confidence_threshold: float, only detections above this threshold are returned\n\n    Returns:\n    - result: dict representing detections on one image\n        see the 'images' key in https://github.com/microsoft/CameraTraps/tree/master/api/batch_processing#batch-processing-api-output-format\n    \"\"\"\n    print('Processing image {}'.format(im_file))\n    try:\n        tf_detector = TFDetector(tf_detector)      \n        image = load_image(im_file)\n    except Exception as e:\n        print('Image {} cannot be loaded. Exception: {}'.format(im_file, e))\n        result = {\n            'file': im_file,\n            'failure': TFDetector.FAILURE_IMAGE_OPEN\n        }\n        return result\n\n    try:\n        result = tf_detector.generate_detections_one_image(\n            image, im_file, detection_threshold=confidence_threshold)\n    except Exception as e:\n        print('Image {} cannot be processed. Exception: {}'.format(im_file, e))\n        result = {\n            'file': im_file,\n            'failure': TFDetector.FAILURE_TF_INFER\n        }\n        return result\n\n    return result\n\n\ndef chunks_by_number_of_chunks(ls, n):\n    \"\"\"Splits a list into n even chunks.\n\n    Args\n    - ls: list\n    - n: int, # of chunks\n    \"\"\"\n    for i in range(0, n):\n        yield ls[i::n]\n\n#%% Load and Run Detector \ndef load_and_run_detector_batch(model_file, image_file_names, checkpoint_path=None,\n                                confidence_threshold=0, checkpoint_frequency=-1,\n                                results=None, n_cores=0):\n    \"\"\"\n    Args\n    - model_file: str, path to .pb model file\n    - image_file_names: list of str, paths to image files\n    - checkpoint_path: str, path to JSON checkpoint file\n    - confidence_threshold: float, only detections above this threshold are returned\n    - checkpoint_frequency: int, write results to JSON checkpoint file every N images\n    - results: list of dict, existing results loaded from checkpoint\n    - n_cores: int, # of CPU cores to use\n\n    Returns\n    - results: list of dict, each dict represents detections on one image\n    \"\"\"\n    n_cores = int(round(n_cores))\n    if results is None:\n        results = []\n        \n    if n_cores <= 1:\n      # Load the detector\n        start_time = time.time()\n        tf_detector = TFDetector(model_file)\n        elapsed = time.time() - start_time\n        print('Loaded model in {}'.format(humanfriendly.format_timespan(elapsed)))\n        \n        for im_file in tqdm(image_file_names):\n          result = process_image(im_file, tf_detector, confidence_threshold)\n          results.append(result)\n            \n    else:\n      tf_detector = model_file\n      \n      print('Creating pool with {} cores'.format(n_cores))\n      pool = workerpool(int(n_cores))\n      \n      image_batches = list(chunks_by_number_of_chunks(image_file_names, n_cores))\n      results = pool.map(partial(process_images, tf_detector=tf_detector, confidence_threshold=confidence_threshold), image_batches)\n      results = list(itertools.chain.from_iterable(results))\n    \n      #results = [pool.apply(process_images, args=c(im_file, tf_detector, confidence_threshold)) for im_file in image_file_names]\n      #results = pool.starmap(process_image, [(im_file, tf_detector, confidence_threshold) for im_file in image_batches])\n      #results = list(itertools.chain.from_iterable(results))\n      pool.close()\n\n    return results\n\n\n#%% Write Output JSON file\ndef write_results_to_file(results, output_file, relative_path_base=None):\n    \"\"\"Writes list of detection results to JSON output file. Format matches\n    https://github.com/microsoft/CameraTraps/tree/master/api/batch_processing#batch-processing-api-output-format\n\n    Args\n    - results: list of dict, each dict represents detections on one image\n    - output_file: str, path to JSON output file, should end in '.json'\n    - relative_path_base: str, path to a directory as the base for relative paths\n    \"\"\"\n    if relative_path_base is not None:\n        results_relative = []\n        for r in results:\n            r_relative = copy.copy(r)\n            r_relative['file'] = os.path.relpath(r_relative['file'], start=relative_path_base)\n            results_relative.append(r_relative)\n        results = results_relative\n\n    final_output = {\n        'images': results,\n        'detection_categories': TFDetector.DEFAULT_DETECTOR_LABEL_MAP,\n        'info': {\n            'detection_completion_time': datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),\n            'format_version': '1.0'\n        }\n    }\n    with open(output_file, 'w') as f:\n        json.dump(final_output, f, indent=1)\n    print('Output file saved at {}'.format(output_file))\n\n#%% Main Function\ndef run_megadetector_batch(detector_file, image_file, output_file, confidence_threshold=0,\n                           checkpoint_frequency=-1, n_cores=0, recurse=True, relative=True,\n                           resume_from_checkpoint=False):\n  \n    assert os.path.exists(detector_file), 'Specified detector_file does not exist'\n    assert 0.0 < confidence_threshold <= 1.0, 'Confidence threshold needs to be between 0 and 1'  # Python chained comparison\n    assert output_file.endswith('.json'), 'output_file specified needs to end with .json'\n    if checkpoint_frequency != -1:\n        assert checkpoint_frequency > 0, 'Checkpoint_frequency needs to be > 0 or == -1'\n    if relative:\n        assert os.path.isdir(image_file), 'image_file must be a directory when relative is set'\n    if os.path.exists(output_file):\n        print('Warning: output_file {} already exists and will be overwritten'.format(output_file))\n\n    # Load the checkpoint if available #\n    ## Relative file names are only output at the end; all file paths in the checkpoint are still full paths.\n    if resume_from_checkpoint:\n        assert os.path.exists(resume_from_checkpoint), 'File at resume_from_checkpoint specified does not exist'\n        with open(resume_from_checkpoint) as f:\n            saved = json.load(f)\n        assert 'images' in saved, \\\n            'The file saved as checkpoint does not have the correct fields; cannot be restored'\n        results = saved['images']\n        print('Restored {} entries from the checkpoint'.format(len(results)))\n    else:\n        results = []\n\n    # Find the images to score; images can be a directory, may need to recurse\n    if os.path.isdir(image_file):\n        image_file_names = ImagePathUtils.find_images(image_file, recursive=recurse)\n        print('{} image files found in the input directory'.format(len(image_file_names)))\n    # A json list of image paths\n    elif os.path.isfile(image_file) and image_file.endswith('.json'):\n        with open(image_file) as f:\n            image_file_names = json.load(f)\n        print('{} image files found in the json list'.format(len(image_file_names)))\n    # A single image file\n    elif os.path.isfile(image_file) and ImagePathUtils.is_image_file(image_file):\n        image_file_names = [image_file]\n        print('A single image at {} is the input file'.format(image_file))\n    else:\n        raise ValueError('image_file specified is not a directory, a json list, or an image file, '\n                         '(or does not have recognizable extensions).')\n\n    assert len(image_file_names) > 0, 'Specified image_file does not point to valid image files'\n    assert os.path.exists(image_file_names[0]), 'The first image to be scored does not exist at {}'.format(image_file_names[0])\n\n    output_dir = os.path.dirname(output_file)\n\n    if len(output_dir) > 0:\n        os.makedirs(output_dir,exist_ok=True)\n        \n    assert not os.path.isdir(output_file), 'Specified output file is a directory'\n\n    # Test that we can write to the output_file's dir if checkpointing requested\n    if checkpoint_frequency != -1:\n        checkpoint_path = os.path.join(output_dir, 'checkpoint_{}.json'.format(datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")))\n        with open(checkpoint_path, 'w') as f:\n            json.dump({'images': []}, f)\n        print('The checkpoint file will be written to {}'.format(checkpoint_path))\n    else:\n        checkpoint_path = None\n\n    start_time = time.time()\n    \n    n_cores = int(round(n_cores))\n\n    results = load_and_run_detector_batch(model_file=detector_file,\n                                          image_file_names=image_file_names,\n                                          checkpoint_path=checkpoint_path,\n                                          confidence_threshold=confidence_threshold,\n                                          checkpoint_frequency=checkpoint_frequency,\n                                          results=results,\n                                          n_cores=n_cores)\n\n    elapsed = time.time() - start_time\n    print('Finished inference in {}'.format(humanfriendly.format_timespan(elapsed)))\n\n    relative_path_base = None\n    if relative:\n        relative_path_base = image_file\n    write_results_to_file(results, output_file, relative_path_base=relative_path_base)\n\n    if checkpoint_path:\n        os.remove(checkpoint_path)\n        print('Deleted checkpoint file')\n\n    print('Done!')"
  },
  {
    "objectID": "eclipseproj.html",
    "href": "eclipseproj.html",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": "",
    "text": "image/svg+xml\n        \n        \n        \n          \n            Openclipart\n          \n        \n        Eclipse\n        2011-01-01T19:54:47\n        A simple rendering of an eclipse using very basic shapes and effects\n        https://openclipart.org/detail/102949/eclipse.svg-by-narrowhouse\n        \n          \n            narrowhouse\n          \n        \n        \n          \n            basic\n            blur\n            eclipse\n            flare\n            simple\n          \n        \n      \n      \n        \n        \n        \n      \n    \n  \n\n\n\n\nField Data\n664,128 total spatial records\n\n16 species\n\n\n\n18 sources\n\n\n\n22 attributes\nDuring my master’s thesis, I completed a side project funded by a NASA mini-grant which assessed wildlife movements during the 2017 Great American Solar Eclipse. GPS data was provided by a number of collaborators from across the country. I published one article related to this research, and another is currently in preparation, but the analysis is on-going. I recently enhanced this analysis by leveraging the powerful astronomical calculation Python module ephem into a function called by R to assess the conditions of the solar eclipse experienced by each recorded location of each individual animal in order to parse potential behavioral changes related to the eclipse. This research is currently being prepared for Movement Ecology."
  },
  {
    "objectID": "eclipseproj.html#fa-chart-gantt-behavioral-change-point-analysis",
    "href": "eclipseproj.html#fa-chart-gantt-behavioral-change-point-analysis",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": " Behavioral Change Point Analysis",
    "text": "Behavioral Change Point Analysis\nI am analyzing the wildlife movements collected during the 2017 Great American Solar Eclipse using behavioral change point analysis with the R package bcpa and smoove to examine potential abrupt changes in movement characteristics which could correspond with the onset of the eclipse.\n\n\n\nPurple vertical lines indicate candidate points in time where an animal’s behavior changed based on it’s movement characteristics (persistence velocity), The dark grey box corresponds with the time period of the ecilipse and black dotted line indicates the time of the maximum eclipse (i.e. totality)."
  },
  {
    "objectID": "eclipseproj.html#fa-scroll-python-function",
    "href": "eclipseproj.html#fa-scroll-python-function",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": " Python function",
    "text": "Python function\nI created a function in Python inspired by a script I found which calculated the start time for a particular eclipse (March 2015) at one particular location. I expanded it to return the start and end times of the eclipse, the time of the maximum eclipse, and the maximum obscuration percentage (how much of the sun was blocked at the eclipse maximum).\n\n#------------------------- Eclipse Percent Py ------------------------------------------#\n# Sourced from : Graeme Coates, March 18, 2015\n# Accessed: 10/8/21\n# https://www.chromosphere.co.uk/wp-content/blogs.dir/1/files/2015/03/eclipse_percent.py\n# https://www.chromosphere.co.uk/2015/03/18/eclipse-calculations-using-python/\n#---------------------------------------------------------------------------------------#\n# Modified by Rob Ritson, 10/18/2021 into a function for Great American Solar Eclipse\n# Args: Longitude (dd.mmmm), Latitude (dd.mmmm), Elevation (meters)\n# Returns: MaxEclipseTime (GMT), MaxEclipsePercent (obscuration), FirstContactTime, LastContactTime\n# Uses Python module ephem\n#---------------------------------------------------------------------------------------#\nimport ephem\nimport math\nimport numpy as n\nfrom operator import itemgetter\n\ndef check_non_zero(x):\n    return x > 0\n\ndef eclipse_calculator(longitude, latitude, elevation):\n  \"\"\"Calculate Eclipse Conditions\"\"\"\n  timetuple=(2017, 8, 21, 00, 00, 00)\n  gatech=ephem.Observer()\n  gatech.epoch= '2017'\n  gatech.date=timetuple\n  gatech.lon=longitude\n  gatech.lat=latitude\n  gatech.elevation=elevation\n  gatech.compute_pressure()\n  sun, moon = ephem.Sun(gatech), ephem.Moon(gatech)\n  results=[]\n  for x in range(0,86400):\n      gatech.date= (ephem.date(ephem.date(timetuple)+x*ephem.second))\n      sun.compute(gatech)\n      moon.compute(gatech)\n      r_sun=(sun.size/2.0)/3600.0\n      r_moon=(moon.size/2.0)/3600.0\n      s=n.degrees(ephem.separation((sun.az, sun.alt), (moon.az, moon.alt)))\n      try:\n          if s<(r_moon+r_sun):\n              lunedelta=0.25*math.sqrt((r_sun+r_moon+s)*(r_moon+s-r_sun)*(s+r_sun-r_moon)*(r_sun+r_moon-s))\n          else: \n              lunedelta=None\n              percent_eclipse=0\n          if lunedelta: \n              lune_area=2*lunedelta + r_sun*r_sun*(math.acos(((r_moon*r_moon)-(r_sun*r_sun)-(s*s))/(2*r_sun*s))) - r_moon*r_moon*(math.acos(((r_moon*r_moon)+(s*s)-(r_sun*r_sun))/(2*r_moon*s)))\n              percent_eclipse=(1-(lune_area/(math.pi*r_sun*r_sun)))*100 \n          \n          results.append([gatech.date.datetime(),s,sun.size,moon.size,lune_area if lunedelta else 0, percent_eclipse]) \n      except ValueError:\n        pass\n\n  gen=(x for x in results) \n  max_eclipse=max(gen, key=itemgetter(5))\n  MaxEclipseTime = str(max_eclipse[0])\n  MaxEclipsePercent = max_eclipse[5]\n  gen=(x for x in results) \n  try:\n    FirstContactTime = str(next(x for x in gen if check_non_zero(x[5]))[0]) \n  except:\n    FirstContactTime = str('NA') \n  try:\n    LastContactTime = str(next(x for x in gen if x[5]==0)[0]) \n  except: \n    LastContactTime = str('NA')\n  out = [MaxEclipseTime, MaxEclipsePercent, FirstContactTime, LastContactTime]\n  return out\n\nIn the next step, I could subset the locations of individuals which actually experienced the eclipse, based on whether the timestamp of the particular location was within the start and end time of the eclipse at that location, and calculate how much of the sun was obscured at that particular instance. This will be used in further analyses in R examining behavioral change points and segementation to examine whether changes in behavior correspond with or relate to eclipse conditions.\n\n------------------------- Eclipse Percent Py ------------------------------------------#\n# Sourced from : Graeme Coates, March 18, 2015\n# Accessed: 10/8/21\n# https://www.chromosphere.co.uk/wp-content/blogs.dir/1/files/2015/03/eclipse_percent.py\n# https://www.chromosphere.co.uk/2015/03/18/eclipse-calculations-using-python/\n#---------------------------------------------------------------------------------------#\n# Modified by Rob Ritson, 1/17/2022 into a function for Great American Solar Eclipse\n# Args: hr (hour), mn (minutes), sc (seconds), Longitude (dd.mmmm), Latitude (dd.mmmm), Elevation (meters)\n# First three arguments are used to create timetuple object for calculating eclipse circumstances\n# Returns: percent eclipse\n# Uses Python module ephem\n#---------------------------------------------------------------------------------------#\nimport ephem\nimport math\nimport numpy as n\n\ndef eclipse_calculator_local(hr, mn, sc, longitude, latitude, elevation):\n  \"\"\"Calculate Eclipse Conditions\"\"\"\n  timetuple=(2017, 8, 21, hr, mn, sc)\n  gatech=ephem.Observer()\n  gatech.epoch= '2017'\n  gatech.date=timetuple\n  gatech.lon=longitude\n  gatech.lat=latitude\n  gatech.elevation=elevation\n  gatech.compute_pressure()\n  sun, moon = ephem.Sun(gatech), ephem.Moon(gatech)\n  sun.compute(gatech)\n  moon.compute(gatech)\n  r_sun=(sun.size/2.0)/3600.0\n  r_moon=(moon.size/2.0)/3600.0\n  s=n.degrees(ephem.separation((sun.az, sun.alt), (moon.az, moon.alt)))\n  if s<(r_moon+r_sun):\n      lunedelta=0.25*math.sqrt((r_sun+r_moon+s)*(r_moon+s-r_sun)*(s+r_sun-r_moon)*(r_sun+r_moon-s))\n  else:\n      lunedelta=None\n      percent_eclipse=0\n  if lunedelta: \n      lune_area=2*lunedelta + r_sun*r_sun*(math.acos(((r_moon*r_moon)-(r_sun*r_sun)-(s*s))/(2*r_sun*s))) - r_moon*r_moon*(math.acos(((r_moon*r_moon)+(s*s)-(r_sun*r_sun))/(2*r_moon*s)))\n      percent_eclipse=(1-(lune_area/(math.pi*r_sun*r_sun)))*100 \n\n  return percent_eclipse"
  },
  {
    "objectID": "eclipseproj.html#fa-code-r-code",
    "href": "eclipseproj.html#fa-code-r-code",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": " R Code",
    "text": "R Code\nThis R script calls the the above Python script using reticulate, executes these in parallel using the furrr package, then saves the outputs for further analysis.\n\n## Calculate Local Circumstances of Great American Solar Eclipse ####\n# Load required packages\nlapply(c(\"data.table\",\"reticulate\",\"furrr\",\"readr\",\"progressr\",\"future\"),require,character.only=T)\n\n# Source Python Script (EclipseCalculator.py)\nreticulate::source_python(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/EclipseCalculator.py\")\n\n# Load data\ndf <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASE_elevation.csv\")\nstr(df)\ndf$Latitude <- as.character(df$Latitude)\ndf$Longitude <- as.character(df$Longitude)\n\n## Calculate Local Circumstances of Eclipse\n#todo <- df\ntodo <- subset(df,!(df$ID %in% out_df$ID))\nout_df <- NULL\nfor(i in 1:length(unique(todo$ID))){\n  elev_df <- subset(todo, todo$ID == unique(todo$ID)[i])\n  arg_list <- elev_df[,c(\"Longitude\",\"Latitude\",\"elevation\")]\n  colnames(arg_list) <- NULL\n  future::plan(multicore,workers = availableCores()-1) #parallel processing\n  skip <- F\n  tryCatch({\n    progressr::with_progress({\n      p <- progressr::progressor(steps = nrow(arg_list))\n      final <- furrr::future_pmap(arg_list, function(long, lat, elev){ \n        p() #add progress bar\n        e <- eclipse_calculator(long, lat, elev)\n      })\n    })\n  },error = function(e){skip <<- T})\n  if(skip){next}\n  \n  final_df <- data.frame(matrix(unlist(final), nrow = length(final), byrow=TRUE))\n  colnames(final_df) <- c(\"MaxEclipseTime\",\"MaxObscuration\",\"FirstContact\",\"LastContact\")\n  out <- cbind(elev_df,final_df)\n  \n  out[[\"MaxEclipseTime\"]] <- as.POSIXct(out[[\"MaxEclipseTime\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  out[[\"FirstContact\"]] <- as.POSIXct(out[[\"FirstContact\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  out[[\"LastContact\"]] <- as.POSIXct(out[[\"LastContact\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  \n  out_df <- rbind(out_df, out)\n  \n  print(paste(\"Iteration\",i,\"of\",length(unique(todo$ID)),\"Completed\"))\n}\nreadr::write_csv(out_df,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\nnas <- subset(out_df,is.na(out_df$FirstContact)) #Indiv 154 is only NAs (brown pelican)\nout_df<- subset(out_df,!is.na(out_df$FirstContact))\nany(is.na(out_df$FirstContact))\nreadr::write_csv(out_df,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\") #Clean file\n#####\n## Calculate Eclipse Duration and Identify Eclipse Locations ####\nrequire(lubridate)\neclipse <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\neclipse$interval <- lubridate::interval(eclipse$FirstContact, eclipse$LastContact)\neclipse$duration_sec <- as.numeric(lubridate::as.duration(eclipse$interval))\neclipse$active_eclipse <- ifelse(eclipse$Timestamp %within% eclipse$interval,'Yes','No')\nreadr::write_csv(eclipse,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\n####\n## Load packages\nlapply(c(\"data.table\",\"reticulate\",\"furrr\",\"readr\",\"progressr\",\"future\"),require,character.only=T)\n\n## Load Data\neclipse <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\n\n# Subset Eclipse Locations\nactive <- subset(eclipse,eclipse$active_eclipse=='Yes')\nactive$hour <- lubridate::hour(active$Timestamp)\nactive$minute <- lubridate::minute(active$Timestamp)\nactive$second <- lubridate::second(active$Timestamp)\n\n# Calculate percent eclipse for each location recorded during the eclipse #\nreticulate::source_python(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/EclipseCalculatorLocalConditions.py\")\n\n## Calculate Local Circumstances of Eclipse Conditions\narg_list <- active[,c(\"hour\",\"minute\",\"second\",\"Longitude\",\"Latitude\",\"elevation\")]\ncolnames(arg_list) <- NULL\nfuture::plan(multicore,workers = availableCores()-1) #parallel processing\nprogressr::with_progress({\n  p <- progressr::progressor(steps = nrow(arg_list))\n  final <- furrr::future_pmap(arg_list, function(hr, mn, sc, long, lat, elev){ \n        p() #add progress bar\n        e <- eclipse_calculator_local(hr, mn, sc, long, lat, elev)\n      })\n    })\nfinal_df <- data.frame(matrix(unlist(final), nrow = length(final), byrow=TRUE))\ncolnames(final_df) <- \"Observed_Obscuration\"\nout <- cbind(active,final_df)\nreadr::write_csv(out,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions_Active.csv\")\n#####"
  },
  {
    "objectID": "fieldexperience.html",
    "href": "fieldexperience.html",
    "title": "Field Experience",
    "section": "",
    "text": "Snapshots of my wildlife research field experiences."
  },
  {
    "objectID": "fsvmproj.html",
    "href": "fsvmproj.html",
    "title": "Fine Scale Vegetation Model",
    "section": "",
    "text": "Field Data\n674,414 total spatial records\n\n5,918 vegetation surveys\n\n\n\n17 sources\n\n\n\n34 attributes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCovariates\n42,825,874 eCognition polygons\n\n58 attributes\nAs a Research Associate for the Wildlife Management Institute, I contributed to the on-going development of Idaho Department of Fish and Game’s Fine Scale Vegetation Model. The purpose of this project is to model understory forage vegetation species important to big game ungulates at a one meter spatial resolution. To accomplish this, IDFG contracted with University of Idaho to develop a covariate database, which was created using eCognition object-oriented image analysis that divided Idaho into ~44 million individual shapes, each of which was populated with landscape covariates.\nMy contribution to further this project was to streamline the modeling process by creating R package fsvm. Using the eCognition covariate database, along with IDFG and partner vegetation survey data, were modeled using machine learning algorithms. In addition to managing the modeling algorithms, the fsvm package provides tools to manage and format survey data as well create prediction maps."
  },
  {
    "objectID": "fsvmproj.html#fa-computer-code-fsvm-r-package",
    "href": "fsvmproj.html#fa-computer-code-fsvm-r-package",
    "title": "Fine Scale Vegetation Model",
    "section": " fsvm R package",
    "text": "fsvm R package\n\n\n\nIn order to assist in IDFG’s Fine Scale Vegetation Model, I wrote an R package to streamline the workflow and ensure reproducability. Among the package’s functions are helpers for uploading and formatting new survey data, rectify taxonomic names to ensure standardization, as well as functions for training machine learning models and producing prediction maps.\n\n\n\n \n\n Vignettes\nI wrote several vignettes demonstrating the functions and tools included in the fsvm package in order to document the processes as well as assist others in using the package.\n\n\n\n Predictions\n\n\n\nAssociating the fsvm predictions with the eCognition polygons is technically challenging compared to traditional rasters"
  },
  {
    "objectID": "fsvmproj.html#fa-leaf-ui-ms-project-assistance",
    "href": "fsvmproj.html#fa-leaf-ui-ms-project-assistance",
    "title": "Fine Scale Vegetation Model",
    "section": " UI MS Project Assistance",
    "text": "UI MS Project Assistance\n\n\n\nAccess database created to assist FSVM survey data entry for University of Idaho master’s students\n\n\n\nField LPI Generation\n\n\n\n\n\n\nIn order to more effectively sample the irregularly shaped eCognition polygons for new vegetation surveys, I wrote code which randomly selects one of polygons, then attempts to fit a 50 meter line within it so the standard line point intercept (LPI) survey protocol effectively samples it. The code works by first randomly generating a starting location within the polygon, randomly selecting a direction, then draws a 50 meter survey line. If that line intersects the border of the polygon, then the process is repeated until a 50 meter line is drawn which does not intersect the polygon or after 100 failed attempts.\nThis process can then be repeated with additional randomly selected polygons until the desired number of survey options is achieved. This gives field personnel fixed options when conducting field vegetation surveys and ensures the surveys they conduct effectively sample the polygon instead of straddling multiple polygons. This also saves the analyst time by automating the generation of possible surveys which meet the desired criteria.\n\n\n R Functions\n\nbuff_sample <- function(poly,buff,r=10){\n  p <- sf::st_cast(poly,\"MULTILINESTRING\")\n  n <- 0\n  repeat{\n    n <- n + 1\n    rand_start <- sf::st_sample(poly,1)\n    d <- as.numeric(sf::st_distance(rand_start,p))\n    if(d >= buff | n == r){\n      break\n    }\n  }\n  if(n == r & d < buff){\n    return(NA)\n    }else{\n      return(rand_start)\n  }\n}\n\nst_fitLPI <- function(poly, r=200, buff=5, len=50){\n  poly <- sf::st_transform(poly,crs = \"WGS84\")\n  p <- sf::st_cast(poly,\"MULTILINESTRING\")\n  permute_dirs  <- sample(1:360) \n  rs <- buff_sample(poly,buff,r) \n  if(is.na(rs)){\n    return(NULL)\n  }else{rs <- sf::st_transform(rs,crs = \"WGS84\")}\n  for(j in 1:length(permute_dirs)){\n    dp <- geosphere::destPoint(rs[[1]][], b = permute_dirs[j], d = len) %>%\n      sf::st_point(.) %>% sf::st_sfc(.) %>% sf::`st_crs<-`(\"WGS84\")\n    lpi <- sf::st_cast(c(rs[[1]],dp[[1]]),\"LINESTRING\")\n    int <- sf::st_intersects(lpi,p, sparse = F)\n    if(isFALSE(int)){break}\n  }\n  if(isTRUE(int)){\n    return(NULL)\n  }\n  df <- data.frame(QPID = poly$QuadPolyID,\n                   Shape = sf::st_geometry(lpi)) %>%\n    sf::st_sf(.) %>% sf::`st_crs<-`(\"WGS84\")\n  return(df)\n}\n\n\n\n R Code\n\nrequire(dplyr)\nusgs24k <- sf::st_read(\"C:/Users/rritson/Documents/GitHub/USGS24k/USGS24k.shp\")\nr1quads <- sf::st_read(\"C:/Users/rritson/Documents/GitHub/Extents/IDFG Regions.shp\") %>% \n  dplyr::filter(ID == \"1\") %>%\n  sf::st_intersects(.,usgs24k) %>% as.data.frame(.) %>%\n  dplyr::mutate(Quad = usgs24k$UID[col.id]) %>%\n  dplyr::select(-row.id,-col.id)\nquads <- dir(\"A:/Fine scale vegetation analysis/dbases_4modeling/24kpolys\",pattern=\".rds\",full.names = T)\nflist <- quads[which(basename(quads) %in% paste0(\"q\",r1quads$Quad,\".rds\"))]\nwater <- sf::st_read(\"C:/Users/rritson/Documents/GitHub/extents/ID_Lakes.shp\")\nfgrid <- readRDS(\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/Faragut_QuadPoly_Selections.rds\")\n\n## Loop through list\nout <- sf::st_sfc() \nsf::st_crs(out) <- sf::st_crs(usgs24k)\nfor(i in 1:length(flist)){\n  print(paste(i,\"of\",length(flist)))\n  \n  # Read 24k quad w/ in R1 grid\n  temp <- readRDS(flist[i]) %>% dplyr::mutate(QuadPolyID = paste0(quad,\"_\",id))\n  wint <- sf::st_intersection(temp,water)\n  temp <- temp[which(!(temp$id %in% wint$id)),] #Filter out open water quad polygons\n  temp <- temp[which(!(temp$QuadPolyID %in% fgrid$QuadPolyID)),]\n  \n  # Randomly select 50 quadpolys from each Faragut quad\n  int <- temp %>%\n    dplyr::filter(QuadPolyID %in% QuadPolyID[sample(1:nrow(.),50)]) %>% \n    dplyr::select(QuadPolyID,Shape)\n  \n  # Collect output\n  out <- rbind(out,int)\n}\nnrow(out) == length(unique(out$QuadPolyID))\nsaveRDS(out,\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Selections.rds\")\n\n# Draw LPIs a priori\nrgrid <- readRDS(\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Selections.rds\")\nsource(\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/fitLPI_inpoly_function2.R\")\nrequire(dplyr)\n\n##Try Drawing One 50m line\n#reps <- 50 #number of repeats\nlen <- 50 #LPI line length (in meters)\nbuff <- 5 #Buffer distance from polygon edge\nout <- sf::st_sfc() \nsf::st_crs(out) <- sf::st_crs(\"WGS84\")\nfor (i in 301:600) {\n  print(paste(\"Beginning\",i,\"of\",nrow(rgrid)))\n  pb = txtProgressBar(min = 0, max = 360, initial = 0) \n  poly <- rgrid[i,] %>% sf::st_transform(.,crs = \"WGS84\")\n  p <- sf::st_cast(poly,\"MULTILINESTRING\")\n  permute_dirs  <- sample(1:360) \n  rs <- buff_sample(poly,buff,r=200) \n  if(is.na(rs)){next}else{rs <- sf::st_transform(rs,crs = \"WGS84\")}\n  for(j in 1:length(permute_dirs)){\n    setTxtProgressBar(pb,360)\n    dp <- geosphere::destPoint(rs[[1]][], b = permute_dirs[j], d = len) %>%\n      sf::st_point(.) %>% sf::st_sfc(.) %>% sf::`st_crs<-`(\"WGS84\")\n    lpi <- sf::st_cast(c(rs[[1]],dp[[1]]),\"LINESTRING\")\n    int <- sf::st_intersects(lpi,p, sparse = F)\n    if(isFALSE(int) | j == length(permute_dirs)){\n      break\n    }\n  }\n  close(pb)\n  if(isTRUE(int) & j == length(permute_dirs)){\n    print(\"Failed.\")\n    next\n  }\n  print(\"Success!\")\n  df <- data.frame(QPID = poly$QuadPolyID,\n                   Shape = sf::st_geometry(lpi)) %>%\n    sf::st_sf(.) %>% sf::`st_crs<-`(\"WGS84\")\n  out <- rbind(out,df)\n  gc()\n}\nsaveRDS(out,\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Lines_1.rds\")\nsf::st_write(out,\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Lines.shp\")"
  },
  {
    "objectID": "idfg.html",
    "href": "idfg.html",
    "title": "IDFG Regional Projects",
    "section": "",
    "text": "While most of my projects for IDFG generally have a statewide-focus, I occasionally help with specific asks from bureau staff.\n\n\nUsing the fine scale vegetation model I developed, I was able to provide our staff ecologist with predictions for lodgepole pine to help guide their field sampling efforts. \n\n\n\nLodepole pine predicted probability of presence\n\n\n\n\n\nTo assist with my regular tasks accessing collar and capture data, I wrote R code to easily access those SQL databases.\n\n## Download Collar Locations from SQL Database (filtered by species)\ngetSQLData_locs <- function(sqltable = \"Collars_Locations_ALL\", \n                            species){\n\n  species <- match.arg(species,\n                       c(\"Elk\",\"Mule Deer\",\"Pronghorn Antelope\",\"Moose\",\"Wolf\",\"Black Bear\",\"White-tailed Deer\",\n                         \"Mountain Goat\",\"Rocky Mountain Bighorn Sheep\",\"California Bighorn Sheep\",\"Mountain Lion\"),\n                       several.ok = T)\n  con <- DBI::dbConnect(\n    odbc::odbc(),\n    driver = \"SQL Server\",\n    database = \"IFWIS_WildlifeReporting\",\n    uid = \"CollarManager\",\n    pwd = #REDACTED,\n    server = #REDACTED,\n    port = #REDACTED)\n  locdata <- DBI::dbReadTable(con,sqltable)\n  DBI::dbDisconnect(con)\n  sel <- dplyr::filter(locdata,Game %in% species)\n  rm(con,sqltable,locdata)\n  return(sel)\n}\n\n## Download Necropsy data from SQL Database (filtered by species)\ngetSQLData_nec = function(sqltable = \"SAMM_Necropsy\", species) {\n  species <- match.arg(species,\n                       c(\"Elk\",\"Mule Deer\",\"Pronghorn Antelope\",\"Moose\",\"Wolf\",\"Black Bear\",\"White-tailed Deer\",\n                         \"Mountain Goat\",\"Rocky Mountain Bighorn Sheep\",\"California Bighorn Sheep\",\"Mountain Lion\"),\n                       several.ok = T)\n  con <- DBI::dbConnect(\n    odbc::odbc(),\n    driver = \"SQL Server\",\n    database = \"IFWIS_WildlifeReporting\",\n    uid =  \"ShinyUserInternal\",\n    pwd = #REDACTED,\n    server = #REDACTED,\n    port = #REDACTED)\n  \n  columns = c(\"CaptureID\",\"Animal_ID\",\"GameID\",\"FateID\",\"FateDate\",\n              \"CensorID\",\"CensorDate\",\"RadFreq\",\"Latitude\",\"Longitude\",\n              \"Bnumber\",\"LastLoc\",\"FateDate_OG\",\"CensorDate_OG\",\"NecID\",\n              \"BGMR\",\"BlueEarTag\")\n  \n  queries = paste0(\"SELECT \", \n                   columns, \n                   \" from \", sqltable)\n  \n  res = lapply(queries, function(query) {\n    res = DBI::dbGetQuery(con, query)\n    res\n  })\n  res = dplyr::bind_cols(res)\n  \n  lut_game <- DBI::dbGetQuery(con, \"SELECT GAMEID, Game from GAME_PIC_GAME\") %>%\n    dplyr::filter(Game %in% species) %>%\n    dplyr::select(GAMEID) %>%\n    unique() %>%\n    unlist()\n  \n  lut_fate <- DBI::dbGetQuery(con, \"SELECT FateID, FateDesc from SAMM_PIC_FateTypes\")\n\n  sel <- dplyr::filter(res,GameID %in% lut_game) %>%\n    dplyr::left_join(.,lut_fate,by=\"FateID\")\n  \n  rm(con,sqltable,res,queries,columns,lut_game,lut_fate)\n  \n  return(sel)\n}\n\n## Download Capture data from SQL Database (filtered by species)\ngetSQLData_cap = function(sqltable = \"SAMM_Capture\", species) {\n  library(dplyr)\n  library(dbplyr)\n  species <- match.arg(species,\n                       c(\"Elk\",\"Mule Deer\",\"Pronghorn Antelope\",\"Moose\",\"Wolf\",\"Black Bear\",\"White-tailed Deer\",\n                         \"Mountain Goat\",\"Rocky Mountain Bighorn Sheep\",\"California Bighorn Sheep\",\"Mountain Lion\"),\n                       several.ok = T)\n  con <- DBI::dbConnect(\n    odbc::odbc(),\n    driver = \"SQL Server\",\n    database = \"IFWIS_WildlifeReporting\",\n    uid =  \"ShinyUserInternal\",\n    pwd = #REDACTED,\n    server = #REDACTED,\n    port = #REDACTED)\n  \n  tab = tbl(con,sqltable)\n  columns = colnames(tab)\n  queries = paste0(\"SELECT \", \n                   columns, \n                   \" from \", sqltable)\n  res = lapply(queries, function(query) {\n    res = DBI::dbGetQuery(con, query)\n    res\n  })\n  res = dplyr::bind_cols(res)\n  \n  lut <- DBI::dbGetQuery(con, \"SELECT GAMEID, Game from GAME_PIC_GAME\") %>%\n    dplyr::filter(Game %in% species) %>%\n    dplyr::select(GAMEID) %>%\n    unique() %>%\n    unlist()\n  \n  sel <- dplyr::filter(res,GameID %in% lut)\n  \n  rm(con,sqltable,res,queries,columns,lut)\n  \n  return(sel)\n}\n#cap <- getSQLData_cap(species = \"Mule Deer\")\n\n## Download Vegetation field data from SQL Database \ngetSQLData_veg <- function(sqltable = \"Veg_fsvm_understory_model_data\"){\n  con <- DBI::dbConnect(\n    odbc::odbc(),\n    driver = \"SQL Server\",\n    database = \"IFWIS_WildlifeReporting\",\n    uid = \"CollarManager\",\n    pwd = #REDACTED,\n    server = #REDACTED,\n    port = #REDACTED)\n  fielddata <- DBI::dbReadTable(con,sqltable)\n  DBI::dbDisconnect(con); rm(con,sqltable)\n  return(fielddata)\n}\n\n\n\n\nMy expertise with using R for GIS manipulations has been previously called upon to assist with covariate formatting for northern Idaho ground squirrel habitat modeling efforts.\n\n# Load packages\nsource('B:/Seasonal Range Analysis/Mule Deer/Smokey-Boise/winter/RScripts/instaload_function.R')\ninstaload(c('sf','terra','exactextractr'))\n\n# Load Grid Shapefile\nfp <- \"Q:/RegionMcc/Diane EM/NIDGS/Covariates/2022_GISLayers_for_covariates/grid 100m_entire range_edited 2018 for Tamarack S_2021 S3 Revision.shp\"\ngrid_shp <- sf::st_read(fp)\n\n# List Veg Class Rasters\nhveg_list <- dir(\"B:/Seasonal Range Analysis/Mule Deer/Covariates/hveg\",pattern = \"_2020.tif$\",full.names = T)\n\n# Load, Clamp, and Stack Rasters\n## Function\nload_clamp <- function(x){\n  r <- terra::rast(x) %>% terra::clamp(.,lower=1,values=F)\n  return(r)\n}\nhveg_stack <- do.call(load_clamp,list(hveg_list))\n\n# ReProject grid shape (match raster stack)\ngrid_proj <- sf::st_transform(grid_shp,terra::crs(hveg_stack))\n\n# Extract coverage areas\ngrid_extract <- exactextractr::exact_extract(hveg_stack,\n                                             grid_proj,\n                                             coverage_area = T,\n                                             fun=\"sum\",\n                                             force_df =T)\n\n# Rename columns\ncolnames(grid_extract) <- gsub(\"sum.\",\"\",colnames(grid_extract))\ncolnames(grid_extract) <- paste0(colnames(grid_extract),\"_m2\")\n\n# Add to original\ngrid_final <- cbind(grid_shp,grid_extract)\n\n# Load Canopy Cover Raster\ncancov <- terra::rast(\"C:/Users/rritson/Documents/Projects/forErin/treecc30.tif\")\n\n# ReProject grid shape (match raster)\ngrid_proj <- sf::st_transform(grid_shp,terra::crs(cancov))\n\n# Extract coverage areas\ngrid_extract <- exactextractr::exact_extract(cancov,\n                                             grid_proj,\n                                             coverage_area = T,\n                                             fun=\"mean\",\n                                             force_df =T)\n# Rename column\ncolnames(grid_extract) <- \"NLCD_mean\"\n\n# Add to original\ngrid_final <- cbind(grid_final,grid_extract)\n\n#Save New Grid Shape\nsf::st_write(grid_final,dsn = \"Q:/RegionMcc/Diane EM/NIDGS/Covariates/2022_GISLayers_for_covariates/grid 100m_entire range_edited 2018 for Tamarack S_2021 S3 Revision_covs.shp\")\n\n#clean-up \nterra::tmpFiles(remove = T)\nrm(cancov,hveg_list,hveg_stack,grid_shp,grid_proj,grid_extract,grid_final,fp,load_clamp,instaload)\ngc()\n\n###\n# Load Grid\ngrid_final <- sf::st_read(\"Q:/RegionMcc/Diane EM/NIDGS/Covariates/2022_GISLayers_for_covariates/grid 100m_entire range_edited 2018 for Tamarack S_2021 S3 Revision_covs.shp\")\n\n# Load remaining covariates\n## Soil Bulk Density\nbulkdens <- terra::rast(\"Q:/RegionMcc/Diane EM/NIDGS/Covariates/EnvironmentalData/Soils/POLARIS/bulkdens\")\n\n# ReProject grid shape (match raster)\ngrid_proj <- sf::st_transform(grid_final,terra::crs(bulkdens))\n\n# Extract coverage areas\ngrid_extract <- exactextractr::exact_extract(bulkdens,\n                                             grid_proj,\n                                             coverage_area = T,\n                                             fun=\"mean\",\n                                             force_df =T)\n# Rename column\ncolnames(grid_extract) <- \"BulkDensity_mean\"\n\n# Add to original\ngrid_final <- cbind(grid_final,grid_extract)\n\n## Percent Silt\nsiltperc <- terra::rast(\"Q:/RegionMcc/Diane EM/NIDGS/Covariates/EnvironmentalData/Soils/POLARIS/siltperc\")\n\n# ReProject grid shape (match raster)\ngrid_proj <- sf::st_transform(grid_final,terra::crs(siltperc))\n\n# Extract coverage areas\ngrid_extract <- exactextractr::exact_extract(siltperc,\n                                             grid_proj,\n                                             coverage_area = T,\n                                             fun=\"mean\",\n                                             force_df =T)\n# Rename column\ncolnames(grid_extract) <- \"PercSilt_mean\"\n\n# Add to original\ngrid_final <- cbind(grid_final,grid_extract)\n\n## Soil Depth\nresdep <- terra::rast(\"Q:/RegionMcc/Diane EM/NIDGS/Covariates/EnvironmentalData/Soils/POLARIS/resdep\")\n\n# ReProject grid shape (match raster)\ngrid_proj <- sf::st_transform(grid_final,terra::crs(resdep))\n\n# Extract coverage areas\ngrid_extract <- exactextractr::exact_extract(resdep,\n                                             grid_proj,\n                                             coverage_area = T,\n                                             fun=\"mean\",\n                                             force_df =T)\n# Rename column\ncolnames(grid_extract) <- \"SoilDepth_mean\"\n\n# Add to original\ngrid_final <- cbind(grid_final,grid_extract)\n\n\n#install.packages('spatialEco')\nrequire(spatialEco)\ndem <- terra::rast(\"C:/Users/rritson/Documents/Projects/forErin/DEM10M_1.tif\")\n## CLIP IS TOO SMALL!!!!!\n\n## Aspect\nasp <- terra::terrain(dem,\"aspect\")\n\n# ReProject grid shape (match raster)\ngrid_proj <- sf::st_transform(grid_final,terra::crs(asp))\n\n# Extract coverage areas\ngrid_extract <- exactextractr::exact_extract(asp,\n                                             grid_proj,\n                                             coverage_area = T,\n                                             fun='mean',\n                                             force_df =T)\n# Rename column\ncolnames(grid_extract) <- \"Aspect_mean\"\n\n# Add to original\ngrid_final <- cbind(grid_final,grid_extract)\n\n## Heat Load Index\nhli <- spatialEco::hli(dem)\n\n# ReProject grid shape (match raster)\ngrid_proj <- sf::st_transform(grid_final,terra::crs(hli))\n\n# Extract coverage areas\ngrid_extract <- exactextractr::exact_extract(hli,\n                                             grid_proj,\n                                             coverage_area = T,\n                                             fun='mean',\n                                             force_df =T)\n# Rename column\ncolnames(grid_extract) <- \"HEAT_mean\"\n\n# Add to original\ngrid_final <- cbind(grid_final,grid_extract)\n\ngrid_final$AspectClass <- ifelse(23 <= grid_final$Aspect_mean & grid_final$Aspect_mean <= 68,\"Northeast\",\n                                 ifelse(69 <= grid_final$Aspect_mean  & grid_final$Aspect_mean<= 112,\"East\",\n                                        ifelse(113 <= grid_final$Aspect_mean & grid_final$Aspect_mean <= 158,\"Southeast\",\n                                               ifelse(159 <= grid_final$Aspect_mean & grid_final$Aspect_mean <= 202,\"South\",\n                                                      ifelse(203 <= grid_final$Aspect_mean & grid_final$Aspect_mean <= 248,\"Southwest\",\n                                                             ifelse(249 <= grid_final$Aspect_mean & grid_final$Aspect_mean <= 292,\"West\",\n                                                                    ifelse(293 <= grid_final$Aspect_mean & grid_final$Aspect_mean <= 338,\"Northwest\",\"North\")))))))\n\n#Save New Grid Shape\nsf::st_write(grid_final,dsn = \"Q:/RegionMcc/Diane EM/NIDGS/Covariates/2022_GISLayers_for_covariates/grid 100m_entire range_edited 2018 for Tamarack S_2021 S3 Revision_covs2.shp\")\n\n#clean-up \nterra::tmpFiles(remove = T)\nrm(grid_proj,grid_extract,grid_final,asp,dem,resdep,siltperc,bulkdens,hli)\ngc()\n\n\n\n\nRecently, I developed code for manipulating fire data from MTBS into covariate rasters relevant to the FSVM and ungulate seasonal range modeling efforts.\n\n# Load packages\nrequire(sf)\nrequire(terra)\nrequire(foreign)\nrequire(dplyr)\nrequire(stringr)\nrequire(lubridate)\n\n### Set-up ------------------------------------------\n## significant digits (7 digit coordinate + 10 digits after decimal (for nanometers) = 17 significant digits)\nif(options()$digits != 17){\n  options(digits = 17)\n}\n## 'terra' options\n#'INT2S'\nterra::terraOptions(datatype = 'INT2S') # same data type Brendan used, default in 'terra' is 'FLT4S'\nterra::terraOptions(tolerance = 1e-10)\nterra::terraOptions()\n## proj4strings\n#WGS84 Longitude and Latitude\nlonlat = \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n#Idaho Transverse Mercator\n#idtm = \"+proj=tmerc +lat_0=42 +lon_0=-114 +k=0.9996 +x_0=2500000 +y_0=1200000 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0\"\nidtm <- \"epsg:8826\"\n\n#Load base grid\nbase <- terra::rast('B:/Covariates/base_grid/idaho_buffer_100km_30m.tif')\nterra::res(base)\nterra::crs(base)\nbase <- terra::project(base, idtm)\n\n#Load Idaho state boundary\nidaho <- sf::st_read(\"B:/GIS_ReferenceLayers/ID_StateBoundary/IDTM\", \"IdahoBoundary_IDTM\")  %>% \n  terra::vect(.) %>%\n  terra::project(.,base) #ensure projections match\nterra::plot(terra::ext(base))\nterra::plot(idaho, add = T)\n\n#Create bounding box from base grid\nbbox <- base %>% \n  sf::st_bbox(.,crs = sf::st_crs(base)) %>% \n  sf::st_as_sfc(.) %>% \n  sf::st_as_sf(.) %>% \n  dplyr::mutate(PolyID = \"NDVI_30m_Idaho_100kmBuff\") %>%\n  terra::vect(.)\n\n# Load MTBS perimeter file\n## Download at: https://mtbs.gov/direct-download; Burned Areas Boundaries Dataset\nfire <- sf::st_read(\"C:/Users/rritson/Documents/Covariates/Fire/MTBS_perimeter_shape/mtbs_perims_DD.shp\",quiet=T) %>%\n  sf::st_transform(.,idtm) %>%\n  dplyr::select(Event_ID,Incid_Name,Incid_Type,BurnBndAc,Ig_Date,Comment) %>%\n  dplyr::rowwise(.) %>%\n  dplyr::mutate(Year = stringr::str_split_fixed(Ig_Date,\"-\",3)[[1]],\n                Month = stringr::str_split_fixed(Ig_Date,\"-\",3)[[2]],\n                Day = stringr::str_split_fixed(Ig_Date,\"-\",3)[[3]]) %>%\n  dplyr::select(Event_ID,Incid_Name,Incid_Type,BurnBndAc,Year,Month,Day,Comment) %>%\n  terra::vect(.) %>%\n  terra::crop(.,bbox) %>%\n  sf::st_as_sf(.) #Important for filtering!!!\n\n# Create Binary Burned Rasters\n## Filter by Year\nyrs <- 2000:2021\nfor(yr in yrs){\n  print(paste0(\"Calculating \",yr,\"...\"))\n  ### since 1984\n  print(paste(\"All Years\"))\n  fire_yr <- fire %>%\n    dplyr::filter(Year <= yr) %>%\n    dplyr::mutate(Burned = 1) %>%\n    dplyr::select(Burned) %>%\n    terra::vect(.)\n  fire_rast <- terra::rasterize(fire_yr,base,fun=\"max\",background=0,touches=F,na.rm=T,update=F,by=NULL,cover=F)\n  names(fire_rast) <- \"Burned\"\n  terra::writeRaster(fire_rast,paste0(\"E:/Seasonal_range_covars/fire/Burned_allyrs_\",yr,\".tif\"))\n  \n  ### Last 10 yrs\n  print(paste(\"Last Ten Years\"))\n  fire_yr <- fire %>%\n    dplyr::filter(Year <= yr & Year >= (yr-10)) %>%\n    dplyr::mutate(Burned = 1) %>%\n    dplyr::select(Burned) %>%\n    terra::vect(.)\n  fire_rast <- terra::rasterize(fire_yr,base,fun=\"max\",background=0,touches=F,na.rm=T,update=F,by=NULL,cover=F)\n  names(fire_rast) <- \"Burned\"\n  terra::writeRaster(fire_rast,paste0(\"E:/Seasonal_range_covars/fire/Burned_last10_\",yr,\".tif\"))\n  \n  ### Only Year of\n  print(paste(\"Year of Only\"))\n  fire_yr <- fire %>%\n    dplyr::filter(Year == yr) %>%\n    dplyr::mutate(Burned = 1) %>%\n    dplyr::select(Burned) %>%\n    terra::vect(.)\n  fire_rast <- terra::rasterize(fire_yr,base,fun=\"max\",background=0,touches=F,na.rm=T,update=F,by=NULL,cover=F)\n  names(fire_rast) <- \"Burned\"\n  terra::writeRaster(fire_rast,paste0(\"E:/Seasonal_range_covars/fire/Burned_yrof_\",yr,\".tif\"))\n}\n\n## Frequency of Fire (N unique)\nyrs <- 2000:2021\nfor(yr in yrs){\n  print(paste0(\"Calculating \",yr,\"...\"))\n  ### since 1984\n  print(paste(\"All Years\"))\n  fire_yr <- fire %>%\n    dplyr::filter(Year <= yr) %>%\n    dplyr::mutate(Burned = 1) %>%\n    dplyr::select(Burned) %>%\n    terra::vect(.)\n  fire_rast <- terra::rasterize(fire_yr,base,fun=\"sum\",background=0,touches=F,na.rm=T,update=F,by=NULL,cover=F)\n  names(fire_rast) <- \"N_fires\"\n  terra::writeRaster(fire_rast,paste0(\"E:/Seasonal_range_covars/fire/FireFrequency_allyrs_\",yr,\".tif\"))\n  \n  ### Last 10 yrs\n  print(paste(\"Last Ten Years\"))\n  fire_yr <- fire %>%\n    dplyr::filter(Year <= yr & Year >= (yr-10)) %>%\n    dplyr::mutate(Burned = 1) %>%\n    dplyr::select(Burned) %>%\n    terra::vect(.)\n  fire_rast <- terra::rasterize(fire_yr,base,fun=\"sum\",background=0,touches=F,na.rm=T,update=F,by=NULL,cover=F)\n  names(fire_rast) <- \"N_fires\"\n  terra::writeRaster(fire_rast,paste0(\"E:/Seasonal_range_covars/fire/FireFrequency_last10_\",yr,\".tif\"))\n  \n  ### Only Year of\n  print(paste(\"Year of Only\"))\n  fire_yr <- fire %>%\n    dplyr::filter(Year == yr) %>%\n    dplyr::mutate(Burned = 1) %>%\n    dplyr::select(Burned) %>%\n    terra::vect(.)\n  fire_rast <- terra::rasterize(fire_yr,base,fun=\"sum\",background=0,touches=F,na.rm=T,update=F,by=NULL,cover=F)\n  names(fire_rast) <- \"N_fires\"\n  terra::writeRaster(fire_rast,paste0(\"E:/Seasonal_range_covars/fire/FireFrequency_yrof_\",yr,\".tif\"))\n}\n\n## Time since last fire (Year)\nyrs <- 2000:2021\nfor(yr in yrs){\n  print(paste0(\"Calculating \",yr,\"...\"))\n  \n  ## since 1984\n  print(paste(\"All Years\"))\n  fire_yr <- fire %>%\n    dplyr::filter(Year <= yr) %>%\n    #dplyr::rowwise(.) %>%\n    dplyr::mutate(TSF = yr-as.numeric(Year)) %>%\n    dplyr::select(TSF,geometry) #%>%\n    #dplyr::ungroup(.) %>%\n    #terra::vect(.)\n  fire_rast <- terra::rasterize(fire_yr,base,\"TSF\",fun=min,background=-9999,touches=F,na.rm=T,update=F,by=NULL,cover=F) #9999 never burned or not burned within defined period\n  names(fire_rast) <- \"TSF\" #time since last fire (years)\n  terra::writeRaster(fire_rast,paste0(\"E:/Seasonal_range_covars/fire/YearSinceFire_allyrs_\",yr,\".tif\"))\n\n  ## Last 10 years\n  print(paste(\"Last Ten Years\")) \n  fire_yr <- fire %>%\n    dplyr::filter(Year <= yr & Year >= (yr-10)) %>%\n    dplyr::rowwise(.) %>%\n    dplyr::mutate(TSF = yr-as.numeric(Year)) %>%\n    dplyr::select(TSF) %>%\n    terra::vect(.)\n  fire_rast <- terra::rasterize(fire_yr,base,\"TSF\",fun=min,background=-9999,touches=F,na.rm=T,update=F,by=NULL,cover=F) #9999 never burned or not burned within defined period\n  names(fire_rast) <- \"TSF\" #time since last fire (years)\n  terra::writeRaster(fire_rast,paste0(\"E:/Seasonal_range_covars/fire/YearSinceFire_last10_\",yr,\".tif\"),overwrite=T)\n}"
  },
  {
    "objectID": "idfg.html#fa-building-shield-region-5",
    "href": "idfg.html#fa-building-shield-region-5",
    "title": "IDFG Regional Projects",
    "section": " Region 5",
    "text": "Region 5\nBeing stationed in the regional office, I occasionally assist staff with GIS-related questions and tasks. I have also helped out with field tasks including mule deer drive nets, pronghorn surveys, and fisheries.\n\nSterling WMA Spatially Balanced Random Sampling\nGeneralized random tessellation stratified (GRTS) algorithm\n\n\n\n\n\n\n\n\nBlackfoot Reservoir Lowland Lake Survey Sites\n\n\n\n\n\n\n\nR code: fishnetR\n\nfishnetR <- function(shp,cell_size,n,stratify=TRUE,seed=1){\n  require(dplyr)\n  \n  # Create grid (fishnet)\n  grid <- sf::st_make_grid(shp, cellsize = cell_size, what = \"polygons\", square = T) %>% \n    terra::vect(.) %>%\n    terra::crop(.,terra::vect(shp)) %>% \n    sf::st_as_sf(.) %>%\n    sf::st_cast(.,\"POLYGON\") %>%\n    dplyr::mutate(id = seq(1,nrow(.), by=1))\n  \n  #Calculate Stratas\n  stratas <- rep(c(1:n),each=floor(nrow(grid)/n))\n  \n  # randomly assign remainder\n  extra <- sample.int(n,nrow(grid)%%n,F)\n  \n  # combine strata\n  stratas <- sort(c(stratas,extra))\n  \n  # Set stratas\n  grid <- dplyr::mutate(grid,strata = as.factor(stratas))\n    \n  #Stratify Random Sample\n  set.seed(seed)\n  if(stratify){\n    i=sample(1:1000,1)\n    repeat{\n      i= i+1\n      set.seed(i)\n      spx <- sf::st_drop_geometry(grid)\n      if(!inherits(spx[,\"strata\"], \"factor\")) \n        spx[,\"strata\"] <- factor(spx[,\"strata\"]) \n      spx$REP <- NA\n      reps=1\n      nn=1\n      results <- list()\n      for(j in levels(spx[, \"strata\"])) {\n        d <- spx[spx[,\"strata\"] == j,]\n        d$rowname <- rownames(d)\n        if(nrow(d) > n) {   \n          for (i in 1:reps) {   \n            s <- lapply(1, function(ij) {\n              d[sample(1:nrow(d), nn),]})\n            s[[1]]$REP <- i\n            results[[paste(j,i,sep=\"_\")]] <-s[[1]] \n          }\n        } else {\n          d$REP <- 1\n          results[[paste(j,i,sep=\"_\")]] <- d\n        }\n      }\n      results\n      results <- do.call(rbind, results)\n      replace=F\n      if(!replace){\n        if(any(duplicated(results$rowname))){\n          results <- results[-which(duplicated(results$rowname)),]\n        }\n      }\n      results <- stats::na.omit(results[,c(\"rowname\",\"REP\")])\n      results <- merge(grid, results, by.y=\"rowname\", by.x = 'row.names', \n                       all.x = FALSE, all.y = TRUE)\n      strat_rand_samp <- results %>% \n        sf::st_as_sf(.)\n      if(any(sf::st_relate(strat_rand_samp, pattern = \"F***1****\",sparse=F)==T)==F && nrow(strat_rand_samp)==21){\n        break\n      }\n    }\n    #return(strat_rand_samp)\n    return(list(strat_rand_samp = strat_rand_samp, grid = grid))\n    \n    #Simple Random Sample\n  }else{\n    randsamp <- sample.int(nrow(grid), size = n, replace=F)\n    locs <- grid[randsamp,]\n    #sf::st_write(locs,filepath) #write grids to filepath (forthcoming)\n    return(locs)\n  }\n}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Robert Ritson’s Wildlife Research Portfolio",
    "section": "",
    "text": "I’m Rob Ritson. I am a wildlife research scientist specializing in movement and spatial ecology. I am skilled at creating and managing large geographic information databases and proficient in RStudio and the ESRI suite. I am continuing to develop my coding skills in Python and currently teaching myself Julia.\nI have 8+ years of field experience conducting population and habitat monitoring with a diversity of species in collaboration with state and federal agencies as well as 5+ years analytical experience managing large GPS data sets, assessing spatial patterns, and composing scientific manuscripts.\n\n\n\nChecking wildlife camera traps in North Idaho as an IDFG Widlife Technicain\n\n\n Places I’ve worked"
  },
  {
    "objectID": "migrations.html",
    "href": "migrations.html",
    "title": "Migrations",
    "section": "",
    "text": "I am currently an Associate Research Scientist for the Wyoming Cooperative Fish and Wildlife Research Unit modeling ungulate seasonal ranges and migrations for Idaho Department of Fish and Game in support of S.O. 3362. One of my primary duties is to classify migrations of Idaho’s mule deer, elk, and pronghorn using net-squared displacement analysis. I also maintain and enhance the analysis code to streamline the workflow and allow for flexibility to accommodate complex migration patterns."
  },
  {
    "objectID": "migrations.html#fa-chart-line-net-squared-displacement-analysis",
    "href": "migrations.html#fa-chart-line-net-squared-displacement-analysis",
    "title": "Migrations",
    "section": " Net-squared displacement analysis",
    "text": "Net-squared displacement analysis\n\n\n Enhanced Interactive Classifier\n\n## Enhanced Classifier ###\n# Load packages\ndevtools::source_url(\"https://github.com/r2j2ritson/RSpatial_Wildlife/blob/main/R/coords_as_sf.R?raw=TRUE\")\ndevtools::source_url(\"https://github.com/r2j2ritson/RSpatial_Wildlife/blob/main/R/instaload.R?raw=TRUE\")\ninstaload(c('data.table','lubridate','plyr','zoo','mapboxer','rmarkdown','markdown','tinytex',\n            'ggplot2','ggmap','dplyr'))\n\n#### USER INPUT - set up directories; create file copy to overwrite classifications \nspecies <- \"mule deer\"\ninpath <- \"K:/Wildlife/sbergen/forRitson/nsd/ID_MD_2019_NSD\"\nscriptdir <- \"C:/Users/rritson/Documents/Projects/NSD/sandbox\"\nsetwd(inpath) # change working directory to deer or elk folder\ni=5\nherd <- paste0(\"Sel\",i) \nfile <- paste0(\"ID_MD_2019_locs_cleaned_NSD_sel\",i,\"_go.csv\")\nrawdir <- paste0(getwd(), \"/unclassified_data\")\ndatadir <- paste0(getwd(), \"/classified_data\")\noutfile <- paste0(datadir, \"/\", file)\n###\n\n# Read in the file prepared in last script\nall_recs <- outfile %>%\n  fread(., header = TRUE, stringsAsFactors = FALSE) %>%\n  dplyr::rowwise(.) %>%\n  dplyr::mutate(GMT = as.POSIXct(paste0(Year,\"-\",Month,\"-\",Day,\" \",Hour,\":\",Minute,\":\",Second),\n                                 format = \"%Y-%m-%d %H:%M:%S\", tz = \"GMT\")) %>%\n  dplyr::ungroup(.) %>%\n  as.data.frame(.)\nstr(all_recs)\n\nyrs <- unique(year(all_recs$GMT))\nyrs <- sort(yrs)\n#######################\n\nsavecounter = 0\n\n# Prep Color Palette\nhab_palette <- data.frame(\"Habitat\" = c(\"Discard\",\n                                        \"Not assigned\",\n                                        \"Not assigned\",\n                                        \"blank\",\n                                        \"Winter\",\n                                        \"Winter\",\n                                        \"Summer\",\n                                        \"Summer\",\n                                        \"SpringMig\",\n                                        \"FallMig\",\n                                        \"Resident\",\n                                        \"Nomad\"),\n                          \"color\" = c(\"#BEBEBE\",\n                                      \"#000000\",\n                                      \"#000000\",\n                                      \"#000000\",\n                                      \"#0000FF\",\n                                      \"#BFEFFF\",\n                                      \"#FFFF00\",\n                                      \"#EEDD82\",\n                                      \"#B8860B\",\n                                      \"#008000\",\n                                      \"#FF00FF\",\n                                      \"#40E0D0\"),\n                          \"Hab_code\" =c(\"Discard\",\n                                        \"not assigned\",\n                                        NA,\n                                        \"\",\n                                        \"winter\",\n                                        \"wntmov\",\n                                        \"summer\",\n                                        \"summov\",\n                                        \"fallmig\",\n                                        \"sprmig\",\n                                        \"Resident\",\n                                        \"Nomad\"))\n\n# Classify Dates Function                            \nclassify_dates <- function(id_recs){\n  ## Look-up Tables\n  spring_lut <- id_recs %>%\n    dplyr::filter(Hab_code == \"sprmig\") %>%\n    dplyr::group_by(habitat) %>%\n    dplyr::summarise(Start = min(GMT),\n                     End = max(GMT)) %>%\n    dplyr::arrange(.,Start)\n  \n  fall_lut <- id_recs %>%\n    dplyr::filter(Hab_code == \"fallmig\") %>%\n    dplyr::group_by(habitat) %>%\n    dplyr::summarise(Start = min(GMT),\n                     End = max(GMT)) %>%\n    dplyr::arrange(.,Start)\n  \n  ## Func Codes\n  last_summer <- function(){\n    paste0(\"summer\", (as.numeric(year)-1))\n  }\n  last_winter <- function(){\n    paste0(\"winter\", (as.numeric(year)-1))\n  }\n  next_summer <- function(){\n    paste0(\"summer\", (as.numeric(year)+1))\n  }\n  next_winter <- function(){\n    paste0(\"winter\", (as.numeric(year)+1))\n  }\n  current_summer <- function(){\n    paste0(\"summer\", year)\n  }\n  current_winter <- function(){\n    paste0(\"winter\", year)\n  }\n  \n  ## Classify Dates\n  ### Only One Spring Migration classified\n  if(nrow(spring_lut) == 1 & nrow(fall_lut) == 0){ #classic partial sequence\n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT < spring_lut$Start,\n                              current_winter(), id_recs$habitat)\n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT > spring_lut$End,\n                              current_summer(), id_recs$habitat)\n  }\n  ### Only One Fall Migration classified\n  if(nrow(spring_lut) == 0 & nrow(fall_lut) == 1){ \n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT < fall_lut$Start,\n                              last_summer(), id_recs$habitat)\n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT > fall_lut$End,\n                              current_winter(), id_recs$habitat)\n  }\n  ### One Spring and One Fall Migration classified\n  if(nrow(spring_lut) == 1 & nrow(fall_lut) == 1){\n    if(spring_lut$Start < fall_lut$Start){ #Classic complete sequence\n      id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT < spring_lut$Start,\n                                current_winter(), id_recs$habitat)\n      id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT > spring_lut$End & id_recs$GMT < fall_lut$Start,\n                                current_summer(), id_recs$habitat)\n      id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT > fall_lut$End,\n                                next_winter(), id_recs$habitat)\n    }else{\n      id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT < fall_lut$Start,\n                                last_summer(), id_recs$habitat)\n      id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT > fall_lut$End & id_recs$GMT < spring_lut$Start,\n                                current_winter(), id_recs$habitat)\n      id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT > spring_lut$End,\n                                current_summer(), id_recs$habitat)\n    }\n  }\n  ### Two Fall Migrations and One Spring Spring Migration classified\n  if(nrow(spring_lut) == 1 & nrow(fall_lut) == 2){\n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT < fall_lut$Start[1],\n                              last_summer(), id_recs$habitat)  \n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT < spring_lut$Start & id_recs$GMT > fall_lut$End[1],\n                              current_winter(), id_recs$habitat)\n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT > spring_lut$End & id_recs$GMT < fall_lut$Start[2],\n                              current_summer(), id_recs$habitat)  \n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT > fall_lut$End[2],\n                              next_winter(), id_recs$habitat)  \n    \n  }\n  ### One Fall Migrations and Two Spring Spring Migration classified\n  if(nrow(spring_lut) == 2 & nrow(fall_lut) == 1){\n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT < spring_lut$Start[1],\n                              current_winter(), id_recs$habitat)  \n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT > spring_lut$End[1] & id_recs$GMT < fall_lut$Start,\n                              current_summer(), id_recs$habitat)\n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT > fall_lut$End & id_recs$GMT < spring_lut$Start[2],\n                              next_winter(), id_recs$habitat)  \n    id_recs$habitat <- ifelse(id_recs$color == \"#000000\" & id_recs$GMT > spring_lut$End[2],\n                              next_summer(), id_recs$habitat)\n  }\n  ### Add Years to Winter and Summer Movements\n  id_recs$Hab_code <- stringr::str_split_fixed(id_recs$habitat,\"[:digit:]\",2)[,1]\n  winter_lut <- id_recs %>%\n    dplyr::filter(Hab_code == \"winter\") %>%\n    dplyr::group_by(habitat) %>%\n    dplyr::summarise(Start = min(GMT),\n                     End = max(GMT)) %>%\n    dplyr::arrange(.,Start) %>%\n    dplyr::rowwise(.) %>%\n    dplyr::mutate(Year = stringr::str_split_fixed(habitat,\"winter\",2)[,2]) %>%\n    dplyr::ungroup(.) %>%\n    as.data.frame(.)\n  \n  summer_lut <- id_recs %>%\n    dplyr::filter(Hab_code == \"summer\") %>%\n    dplyr::group_by(habitat) %>%\n    dplyr::summarise(Start = min(GMT),\n                     End = max(GMT)) %>%\n    dplyr::arrange(.,Start) %>%\n    dplyr::rowwise(.) %>%\n    dplyr::mutate(Year = stringr::str_split_fixed(habitat,\"summer\",2)[,2]) %>%\n    dplyr::ungroup(.) %>%\n    as.data.frame(.)\n  \n  if(nrow(winter_lut) >=1){\n    for(i in 1:nrow(winter_lut)){\n    id_recs$habitat <- ifelse(id_recs$habitat == \"wntmov\" & id_recs$GMT > winter_lut$Start[i] & id_recs$GMT < winter_lut$End[i],\n                            paste0(\"wntmov\", winter_lut$Year[i]), id_recs$habitat)\n  }\n  }\n  if(nrow(summer_lut) >=1){\n  for(i in 1:nrow(summer_lut)){\n    id_recs$habitat <- ifelse(id_recs$habitat == \"summov\" & id_recs$GMT > summer_lut$Start[i] & id_recs$GMT < summer_lut$End[i],\n                              paste0(\"summov\", winter_lut$Year[i]), id_recs$habitat)\n  }\n  }\n  \n  id_recs$Hab_code <- NULL\n  id_recs$color <- NULL\n  id_recs$Hab_code <- stringr::str_split_fixed(id_recs$habitat,\"[:digit:]\",2)[,1]\n  id_recs <- dplyr::left_join(id_recs,hab_palette[,c(-1)],by=\"Hab_code\")\n  return(id_recs)\n  }\n\n# Begin Year loop\nfor(y in 1:length(yrs)){ \n  print(paste(\"Looking for year\", yrs[y], \"records needing classification\"))\n  \n  ## Set-up ###\n  # Subset dataset yr by yr; Jan-Feb of next yr kept too in case fall migration carries over\n  yr_recs <- all_recs[year(all_recs$GMT) == yrs[y] | \n                        year(all_recs$GMT) == yrs[y] + 1 & \n                        month(all_recs$GMT) < 5, ]\n  \n  # Read in overall notes table  \n  notes_tab <-  read.csv(paste0(getwd(), \"/unsorted_output/\", herd, \"/\", yrs[y], \n                                \"/\", yrs[y], \"_overall.csv\"), header = TRUE)\n  notes_tab[] <- lapply(notes_tab, as.character)\n\n  ## Create list of individuals to analyze ###\n  if(exists(\"id_list\")){\n    if(! is.null(id_list)){\n      individs_list <- id_list\n    } else {\n      fb <- readline(\"Pick-up where you left off (pu) OR review all (ra)? \")\n      if(fb == \"pu\"){\n        individs_list <- notes_tab[is.na(notes_tab$Skip) | notes_tab$Skip == \"\", ]$Animal_ID\n      }else{\n        individs_list <- notes_tab$Animal_ID\n      }\n    }\n  } else {\n    fb <- readline(\"Pick-up where you left off (pu) OR review all (ra)? \")\n    if(fb == \"pu\"){\n      individs_list <- notes_tab[is.na(notes_tab$Skip) | notes_tab$Skip == \"\", ]$Animal_ID\n    }else{\n      individs_list <- notes_tab$Animal_ID\n    }\n  }\n  individs_list <- individs_list[which(individs_list %in% all_recs$Animal_ID)]\n  # If empty, review revisits?\n  if(length(individs_list) == 0){\n    revisit <- readline(\"No individuals left to be classified. Review revisits? Y or N \")\n    if(revisit == \"Y\"){\n      individs_list <- notes_tab[notes_tab$Skip == \"N\" & notes_tab$Revisit == \"Y\", ]$Animal_ID\n      individs_list <- individs_list[which(individs_list %in% all_recs$Animal_ID)]\n    }\n  }\n  if(length(individs_list)==0){\n    message(\"There are no revisits remaining in this file.\")\n    next\n    }\n\n  ## Begin Migration Analysis ###\n  # Individual loop\n  for(id in 1:length(individs_list)){\n    # Check previous plots if revisiting...\n    if(revisit == \"Y\"){\n      ## Query previous NSDs\n      source(\"K:/Wildlife/sbergen/forRitson/nsd/ID_MD_2019_NSD/query_previous_nsds.R\")\n      find_nsds(id = individs_list[id], species = species)\n      \n      ## What are we checking?\n      if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Skip == \"Y\"){\n        message(\"This individual was previously skipped.\")\n      }else if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Strategy == \"M\"){\n        message(\"This individual was previously labeled a migrant.\")\n      }else if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Strategy == \"MM\"){\n        message(\"This individual was previously labeled a mixed-migrant.\")\n      }else if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Strategy == \"R\"){\n        message(\"This individual was previously labeled a resident.\")\n      }else if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Strategy == \"N\"){\n        message(\"This individual was previously labeled a nomad.\")\n      }else if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Strategy == \"U\"){\n        message(\"This individual was previously labeled unknown.\")\n      }\n      ## View current NSD plot\n      message(paste(\"Check:\",notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Notes))\n      shell.exec(paste0(getwd(), \"/unsorted_output/\",herd, \"/\", yrs[y],\"/\",individs_list[id], \"_graphic.html\", sep = \"\"))\n      ## Resume?\n      skip_revisit <- readline(\"Keep current NSD (skip this revisit)? Y or N \")\n      notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Revisit <- readline(\"Revisit another time? Y or N \")\n      if(skip_revisit == \"Y\"){\n        fwrite(notes_tab, paste0(getwd(), \"/unsorted_output/\", herd, \"/\", yrs[y], \n                                 \"/\", yrs[y], \"_overall.csv\"), row.names = FALSE, \n               dateTimeAs = c(\"write.csv\"))\n        system2(\"taskkill\",args=\"/im chrome.exe\")\n        next\n        }\n    }\n    \n    # Examine Movements...\n    repeat{\n       id_recs <- yr_recs[yr_recs$Animal_ID == individs_list[id], ]\n      \n      #Show locs\n      print({\n        shp <- coords_as_sf(id_recs,\"WGS84_Long\",\"WGS84_Lat\",\"WGS84\")\n        tile1 <- maptiles::get_tiles(shp, provider = \"Esri.WorldTopoMap\", crop=T, zoom=10, cachedir = \".\") %>%\n          terra::project(.,terra::crs(shp))\n        grDevices::x11()\n        ggplot() + \n          tidyterra::geom_spatraster_rgb(data = tile1, maxcell = Inf) +\n          geom_sf(data = shp) + \n          labs(title = paste0(\"Animal ID: \",individs_list[id]))\n      })\n      unlink(paste0(inpath,\"/EsriWTM\"),recursive = T)\n      \n      ## Step 1: Select Anchor Date\n      repeat{\n      def <- readline(\"Use Default Anchor Date (March 1) or reveiw options? Y or N \")\n      if(def == \"N\"){\n        rmarkdown::render(paste0(scriptdir, \"/\", \"mapbox_anchor.Rmd\"),  \n                          output_file =  paste0(individs_list[id], \"_anchors.html\"), \n                          output_dir = paste0(getwd(), \"/unsorted_output/\", \n                                              herd, \"/\", yrs[y], sep = \"\"))\n        shell.exec(paste0(getwd(), \"/unsorted_output/\",herd, \"/\", yrs[y],\"/\",individs_list[id], \"_anchors.html\", sep = \"\"))\n        \n        repeat{\n          anc_date <- readline(\"Enter Anchor Date (M-DD) \")\n          print(paste(\"Using Anchor Date \", anc_date))\n          orig_date <- as.POSIXct(strptime(paste0(yrs[y], \"-\",anc_date,\" 00:00:00\"), format = \"%Y-%m-%d %H:%M:%S\"), \n                                  origin = \"1970-01-01 00:00:00\") \n          orig_date_recs <- id_recs[abs(id_recs$GMT - orig_date) == \n                                      min(abs(id_recs$GMT - orig_date)), ][1, ]\n          print(paste(\"NSD calculated from origin at\", orig_date_recs$GMT))\n          id_recs[year(id_recs$GMT) == yrs[y] , \"Root_NSD\"] <- \n            ((id_recs[year(id_recs$GMT) == yrs[y] , \"IDTM_X\"] - orig_date_recs$IDTM_X)^2 + \n               (id_recs[year(id_recs$GMT) == yrs[y] , \"IDTM_Y\"] - orig_date_recs$IDTM_Y)^2)^0.5\n          print(ggplot(id_recs,aes(x=GMT,y=Root_NSD)) + \n            geom_point(color=id_recs$color) + geom_line(color=id_recs$color) +\n            labs(x=\"GMT\",y=\"Root_NSD\",\n                 title = paste0(\"Animal ID: \",individs_list[id]),\n                 caption=paste0(\"Anchor Date: \",format.Date(orig_date,\"%B %d\"))))\n          BR <- readline(\"NSD and Anchor Date look good? Y or N \")\n          if(BR == \"Y\"){\n            break\n          }\n        }\n      }else{\n        # Set date of origin\n        print(\"Using Default Anchor Date (March 1).\")\n        orig_date <- as.POSIXct(strptime(paste0(yrs[y], \"-3-01 00:00:00\"), format = \"%Y-%m-%d %H:%M:%S\"), \n                                origin = \"1970-01-01 00:00:00\") # origin date is March 1\n        orig_date_recs <- id_recs[abs(id_recs$GMT - orig_date) == \n                                    min(abs(id_recs$GMT - orig_date)), ][1, ]\n        print(paste(\"NSD calculated from origin at\", orig_date_recs$GMT))\n      }\n      notes_tab[notes_tab$Animal_ID == individs_list[id], ]$AnchorDate <- format.Date(orig_date,\"%B %d\")  \n      id_recs[year(id_recs$GMT) == yrs[y] , \"Root_NSD\"] <- \n        ((id_recs[year(id_recs$GMT) == yrs[y] , \"IDTM_X\"] - orig_date_recs$IDTM_X)^2 + \n           (id_recs[year(id_recs$GMT) == yrs[y] , \"IDTM_Y\"] - orig_date_recs$IDTM_Y)^2)^0.5\n      print(ggplot(id_recs,aes(x=GMT,y=Root_NSD)) + \n        geom_point(color=id_recs$color) + geom_line(color=id_recs$color) +\n        labs(x=\"GMT\",y=\"Root_NSD\",\n             title = paste0(\"Animal ID: \",individs_list[id]),\n             caption=paste0(\"Anchor Date: \",format.Date(orig_date,\"%B %d\"))))\n        BR <- readline(\"NSD and Anchor Date look good? Y or N \")\n        if(BR == \"Y\"){\n          break\n        }\n      }\n      ###\n      \n      # Skip animal or classify migration dates\n      notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Skip <- readline(\"Skip this animal? Y or N  \")\n      \n      ## Step 2: Trim or Discard spurious points\n      if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Skip == \"N\"){\n        notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim <- readline(\"Trim points from the graph? Y or N  \")\n        if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim == \"Y\"){\n          discard_all <- NULL\n          repeat{\n            TR <- readline(\"Discard points from the top(T), bottom(B) right(R), or left(L) of graph? T, B, R, or L \")\n            if(TR == \"T\"){\n              print(\"Click below the points to discard.\")\n              discard  <- ggmap::gglocator(n=1,mercator = F)\n              discarded <- id_recs[as.numeric(na.omit(id_recs$Root_NSD)) > discard$Root_NSD, ]\n              id_recs <- id_recs[as.numeric(na.omit(id_recs$Root_NSD)) < discard$Root_NSD, ]\n              notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type <- ifelse(is.na(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type),TR,\n                                                                                        paste0(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type,TR))\n            } else if(TR == \"R\") {\n              print(\"Click left of the points to discard.\")\n              discard  <- ggmap::gglocator(n=1,mercator = F)\n              discarded <- id_recs[as.numeric(na.omit(id_recs$GMT)) > discard$GMT, ]\n              id_recs <- id_recs[as.numeric(na.omit(id_recs$GMT)) < discard$GMT, ]\n              notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type <- ifelse(is.na(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type),TR,\n                                                                                        paste0(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type,TR))\n            } else if(TR == \"L\") {\n              print(\"Click right of the points to discard.\")\n              discard  <- ggmap::gglocator(n=1,mercator = F)\n              discarded <- id_recs[as.numeric(na.omit(id_recs$GMT)) < discard$GMT, ]\n              id_recs <- id_recs[as.numeric(na.omit(id_recs$GMT)) > discard$GMT, ]\n              notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type <- ifelse(is.na(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type),TR,\n                                                                                        paste0(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type,TR))\n            } else if(TR == \"B\") {\n              print(\"Click above the points to discard.\")\n              discard  <- ggmap::gglocator(n=1,mercator = F)\n              discarded <- id_recs[as.numeric(na.omit(id_recs$Root_NSD)) < discard$Root_NSD, ]\n              id_recs <- id_recs[as.numeric(na.omit(id_recs$Root_NSD)) > discard$Root_NSD, ]\n              notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type <- ifelse(is.na(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type),TR,\n                                                                                        paste0(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Trim_type,TR))\n            }\n            discard_all <- rbind(discard_all,discarded)\n            BR <- readline(\"Discard more points? Y or N \")\n            if(BR == \"N\"){\n              break\n            }\n          }\n        }\n        ###\n        repeat{\n          print(ggplot(id_recs,aes(x=GMT,y=Root_NSD)) + \n                  geom_point(color=id_recs$color) + geom_line(color=id_recs$color) +\n                  labs(x=\"GMT\",y=\"Root_NSD\",\n                       title = paste0(\"Animal ID: \",individs_list[id]),\n                       caption=paste0(\"Anchor Date: \",format.Date(orig_date,\"%B %d\"))))\n          \n        notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Strategy <- readline(\"Identify tentative migration strategy. \nPlease list M (migratory), MM(mixed-migratory), R(resident), N(nomadic), or U(unclear)  \")\n        if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Strategy == \"R\"){\n          id_recs$habitat <- \"Resident\"\n          id_recs$Hab_code <- \"Resident\"\n          id_recs <- dplyr::left_join(id_recs[,-which(stringr::str_detect(colnames(id_recs),\"color\")==T)],hab_palette[,c(-1)],by=\"Hab_code\")\n          rmarkdown::render(paste0(scriptdir, \"/\", \"mapbox_plot.Rmd\"),  \n                            output_file =  paste0(individs_list[id], \"_graphic.html\"), \n                            output_dir = paste0(getwd(), \"/unsorted_output/\", \n                                                herd, \"/\", yrs[y], sep = \"\"))\n          shell.exec(paste0(getwd(), \"/unsorted_output/\",herd, \"/\", yrs[y],\"/\",individs_list[id], \"_graphic.html\", sep = \"\"))\n          if(readline(\"Open the output file. Look good? Y or N  \") == \"Y\"){\n            break\n          }else{\n            id_recs$habitat <- \"not assigned\"\n            id_recs$color <- \"#000000\"\n            id_recs$Hab_code <- NULL\n          }\n        }\n        if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Strategy == \"N\"){\n          id_recs$habitat <- \"Nomad\"\n          id_recs$Hab_code <- \"Nomad\"\n          id_recs <- dplyr::left_join(id_recs[,-which(stringr::str_detect(colnames(id_recs),\"color\")==T)],hab_palette[,c(-1)],by=\"Hab_code\")\n          rmarkdown::render(paste0(scriptdir, \"/\", \"mapbox_plot.Rmd\"),  \n                            output_file =  paste0(individs_list[id], \"_graphic.html\"), \n                            output_dir = paste0(getwd(), \"/unsorted_output/\", \n                                                herd, \"/\", yrs[y], sep = \"\"))\n          \n          shell.exec(paste0(getwd(), \"/unsorted_output/\",herd, \"/\", yrs[y],\"/\",individs_list[id], \"_graphic.html\", sep = \"\"))\n          if(readline(\"Open the output file. Look good? Y or N  \") == \"Y\"){\n            break\n        }else{\n          id_recs$habitat <- \"not assigned\"\n          id_recs$color <- \"#000000\"\n          id_recs$Hab_code <- NULL\n          }\n        }\n        if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Strategy != \"R\" &\n           notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Strategy != \"N\"){\n          \n          ## Step 3: Classify Movement Dates\n          repeat{\n            \n            # Plot NSD\n            print(plt <-ggplot(id_recs,aes(x=GMT,y=Root_NSD)) + \n                    geom_point(color=id_recs$color) + geom_line(color=id_recs$color) +\n                    labs(x=\"GMT\",y=\"Root NSD\",title = paste0(\"Animal ID: \",individs_list[id]))+\n                    theme_bw())\n            \n            \n            mig <- readline(\"What kind of movement is this? Spring(sp), Fall(fa), Winter movement (wm), or Summer movement (sm)? \")\n            \n            if(mig == \"sp\"){\n              print(\"Select Spring Migration Dates\")\n              repeat{\n                # Plot NSD\n                print(\n                  plt <-ggplot(id_recs,aes(x=GMT,y=Root_NSD)) + \n                    geom_point(color=id_recs$color) + geom_line(color=id_recs$color) +\n                    labs(x=\"GMT\",y=\"Root NSD\",title = paste0(\"Animal ID: \",individs_list[id]))+\n                    theme_bw()\n                )\n                # Zoom in on dates of spring migration\n                print(\"Click the earlier date of the range you'd like to zoom to\")\n                windowstart <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt + geom_vline(xintercept = windowstart))\n                print(\"Click the later date of the range you'd like to zoom to\")\n                windowend <- ggmap::gglocator(n=1,mercator = F)$GMT\n                window_recs <- id_recs[as.numeric(na.omit(id_recs$GMT)) > \n                                         windowstart & as.numeric(na.omit(id_recs$GMT)) < windowend, ]\n                print(plt <- ggplot(window_recs,aes(x=GMT,y=Root_NSD)) + \n                        geom_point(color=window_recs$color) + geom_line(color=window_recs$color) +\n                        labs(x=\"GMT\",y=\"Root NSD\",title = paste0(\"Animal ID: \",individs_list[id])))\n                \n                # Pick start/end dates with locator;  assign/paste makes new variables for the loop\n                print(\"Click the start of the spring migration\")\n                start <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt <- plt + geom_vline(xintercept = start, color='limegreen'))\n                print(\"Click the end of the spring migration\")\n                end <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt <- plt + geom_vline(xintercept = end, color='darkred'))\n                \n                # Identify dates in selected range\n                year <- substr(yrs[y], 3, 4)\n                spring_start <- as.POSIXct(start, origin = \"1970-01-01 00:00:00\",tz='GMT')\n                spring_end <- as.POSIXct(end, origin = \"1970-01-01 00:00:00\",tz='GMT')\n                if(spring_start > orig_date){ #spring identified in current year sequence\n                  id_recs$habitat <- ifelse(spring_start <= id_recs$GMT & id_recs$GMT <= spring_end,paste0(\"sprmig\", year),\n                                          id_recs$habitat)\n                }else{#spring identified in last year sequence\n                  id_recs$habitat <- ifelse(spring_start <= id_recs$GMT & id_recs$GMT <= spring_end,paste0(\"sprmig\", (as.numeric(year)-1)),\n                                            id_recs$habitat)\n                }\n                id_recs$Hab_code <- stringr::str_split_fixed(id_recs$habitat,\"[:digit:]\",2)[,1]\n                id_recs <- dplyr::left_join(id_recs[,-which(stringr::str_detect(colnames(id_recs),\"color\")==T)],hab_palette[,c(-1)],by=\"Hab_code\")\n                \n                # ~~*plotting magic*~~\n                rmarkdown::render(paste0(scriptdir, \"/\", \"mapbox_plot.Rmd\"),  \n                                  output_file =  paste0(individs_list[id], \"_graphic.html\"), \n                                  output_dir = paste0(getwd(), \"/unsorted_output/\", \n                                                      herd, \"/\", yrs[y], sep = \"\"))\n                \n                shell.exec(paste0(getwd(), \"/unsorted_output/\",herd, \"/\", yrs[y],\"/\",individs_list[id], \"_graphic.html\", sep = \"\"))\n                if(readline(\"Open the output file. Look good? Y or N  \") == \"Y\"){\n                  break\n                }else{\n                  id_recs$habitat <- ifelse(spring_start <= id_recs$GMT & id_recs$GMT <= spring_end,\"not assigned\",\n                                            id_recs$habitat)\n                  id_recs$color <- ifelse(spring_start <= id_recs$GMT & id_recs$GMT <= spring_end,\"#000000\",\n                                          id_recs$color)\n                  id_recs$Hab_code <- NULL\n                }\n                \n              } # end of repeat for spring migration dates\n              \n              try({\n                # Identify the migration start and end dates and distance. Date_times are written in excel format to ensure consistency.\n                s_migration_start_date <- spring_start\n                notes_tab[notes_tab$Animal_ID == individs_list[id], ]$SprMig_Start <- \n                  toString(format(s_migration_start_date, format = \"%m/%d/%Y %H:%M:%S\"))\n                s_migration_end_date <- spring_end\n                notes_tab[notes_tab$Animal_ID == individs_list[id], ]$SprMig_End <- \n                  toString(format(s_migration_end_date, format = \"%m/%d/%Y %H:%M:%S\"))\n                \n                ss <- id_recs %>%\n                  dplyr::filter(abs(difftime(GMT,s_migration_start_date)) == min(abs(difftime(GMT,s_migration_start_date)))) %>%\n                  dplyr::select(IDTM_X,IDTM_Y) %>%\n                  unique(.)\n                se <- id_recs %>%\n                  dplyr::filter(abs(difftime(GMT,s_migration_end_date)) == min(abs(difftime(GMT,s_migration_end_date)))) %>%\n                  dplyr::select(IDTM_X,IDTM_Y) %>%\n                  unique(.)\n                \n                s_migration_distance <- ((ss$IDTM_X - se$IDTM_X)^2 + (ss$IDTM_Y - se$IDTM_Y)^2)^0.5 \n                \n                notes_tab[notes_tab$Animal_ID == individs_list[id], ]$SprMig_Dist <- s_migration_distance\n              })\n            }\n            if(mig == \"fa\"){\n              print(\"Select Fall Migration Dates\")\n              repeat{\n                # Plot NSD\n                print(\n                  plt <-ggplot(id_recs,aes(x=GMT,y=Root_NSD)) + \n                    geom_point(color=id_recs$color) + geom_line(color=id_recs$color) +\n                    labs(x=\"GMT\",y=\"Root NSD\",title = paste0(\"Animal ID: \",individs_list[id]))+\n                    theme_bw()\n                )\n                # Zoom in on dates of spring migration\n                print(\"Click the earlier date of the range you'd like to zoom to\")\n                windowstart <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt + geom_vline(xintercept = windowstart))\n                print(\"Click the later date of the range you'd like to zoom to\")\n                windowend <- ggmap::gglocator(n=1,mercator = F)$GMT\n                window_recs <- id_recs[as.numeric(na.omit(id_recs$GMT)) > \n                                         windowstart & as.numeric(na.omit(id_recs$GMT)) < windowend, ]\n                print(plt <- ggplot(window_recs,aes(x=GMT,y=Root_NSD)) + \n                        geom_point(color=window_recs$color) + geom_line(color=window_recs$color) +\n                        labs(x=\"GMT\",y=\"Root NSD\",title = paste0(\"Animal ID: \",individs_list[id])))\n                \n                # Pick start/end dates with locator;  assign/paste makes new variables for the loop\n                print(\"Click the start of the fall migration\")\n                start <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt <- plt + geom_vline(xintercept = start, color='limegreen'))\n                print(\"Click the end of the fall migration\")\n                end <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt <- plt + geom_vline(xintercept = end, color='darkred'))\n                \n                # Identify dates in selected range; identify habitat for dates prior to this range\n                year <- substr(yrs[y], 3, 4)\n                fall_start <- as.POSIXct(start, origin = \"1970-01-01 00:00:00\",tz='UTC')\n                fall_end <- as.POSIXct(end, origin = \"1970-01-01 00:00:00\",tz='UTC')\n                if(fall_start > orig_date){ #spring identified in current year sequence\n                  id_recs$habitat <- ifelse(fall_start <= id_recs$GMT & id_recs$GMT <= fall_end,paste0(\"fallmig\", year),\n                                            id_recs$habitat)\n                }else{#spring identified in last year sequence\n                  id_recs$habitat <- ifelse(fall_start <= id_recs$GMT & id_recs$GMT <= fall_end,paste0(\"fallmig\", (as.numeric(year)-1)),\n                                            id_recs$habitat)\n                }\n                id_recs$Hab_code <- stringr::str_split_fixed(id_recs$habitat,\"[:digit:]\",2)[,1]\n                id_recs <- dplyr::left_join(id_recs[,-which(stringr::str_detect(colnames(id_recs),\"color\")==T)],hab_palette[,c(-1)],by=\"Hab_code\")\n                \n                # ~~*plotting magic*~~\n                rmarkdown::render(paste0(scriptdir, \"/\", \"mapbox_plot.Rmd\"),  \n                                  output_file =  paste0(individs_list[id], \"_graphic.html\"), \n                                  output_dir = paste0(getwd(), \"/unsorted_output/\", \n                                                      herd, \"/\", yrs[y], sep = \"\"))\n                \n                shell.exec(paste0(getwd(), \"/unsorted_output/\",herd, \"/\", yrs[y],\"/\",individs_list[id], \"_graphic.html\", sep = \"\"))\n                if(readline(\"Open the output file. Look good? Y or N  \") == \"Y\"){\n                  break\n                }else{\n                  id_recs$habitat <- ifelse(fall_start <= id_recs$GMT & id_recs$GMT <= fall_end,\"not assigned\",\n                                            id_recs$habitat)\n                  id_recs$color <- ifelse(fall_start <= id_recs$GMT & id_recs$GMT <= fall_end,\"#000000\",\n                                          id_recs$color)\n                  id_recs$Hab_code <- NULL\n                }\n                \n              } # end of repeat for fall migration dates\n              try({\n                if(nrow(id_recs[id_recs$habitat == paste0(\"fallmig\", year), ]) != 0){\n                  # identify the migration start and end dates and distance\n                  f_migration_start_date <- fall_start\n                  notes_tab[notes_tab$Animal_ID == individs_list[id], ]$FallMig_Start <- \n                    toString(format(f_migration_start_date, format = \"%m/%d/%Y %H:%M:%S\"))\n                  f_migration_end_date <- fall_end\n                  notes_tab[notes_tab$Animal_ID == individs_list[id], ]$FallMig_End <- \n                    toString(format(f_migration_end_date, format = \"%m/%d/%Y %H:%M:%S\"))\n                  \n                  fs <- id_recs %>%\n                    dplyr::filter(abs(difftime(GMT,f_migration_start_date)) == min(abs(difftime(GMT,f_migration_start_date)))) %>%\n                    dplyr::select(IDTM_X,IDTM_Y) %>%\n                    unique(.)\n                  fe <- id_recs %>%\n                    dplyr::filter(abs(difftime(GMT,f_migration_end_date)) == min(abs(difftime(GMT,f_migration_end_date)))) %>%\n                    dplyr::select(IDTM_X,IDTM_Y) %>%\n                    unique(.)\n                  \n                  f_migration_distance <- ((fs$IDTM_X - fe$IDTM_X)^2 + (fs$IDTM_Y - fe$IDTM_Y)^2)^0.5 \n                  \n                  notes_tab[notes_tab$Animal_ID == individs_list[id], ]$FallMig_Dist <- f_migration_distance\n                }\n              })\n            } \n            if(mig == \"wm\"){\n              print(\"Select Winter Movement Dates\")\n              repeat{\n                # Plot NSD\n                print(\n                  plt <-ggplot(id_recs,aes(x=GMT,y=Root_NSD)) + \n                    geom_point(color=id_recs$color) + geom_line(color=id_recs$color) +\n                    labs(x=\"GMT\",y=\"Root NSD\",title = paste0(\"Animal ID: \",individs_list[id]))+\n                    theme_bw()\n                )\n                # Zoom in on dates of spring migration\n                print(\"Click the earlier date of the range you'd like to zoom to\")\n                windowstart <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt + geom_vline(xintercept = windowstart))\n                print(\"Click the later date of the range you'd like to zoom to\")\n                windowend <- ggmap::gglocator(n=1,mercator = F)$GMT\n                window_recs <- id_recs[as.numeric(na.omit(id_recs$GMT)) > \n                                         windowstart & as.numeric(na.omit(id_recs$GMT)) < windowend, ]\n                print(plt <- ggplot(window_recs,aes(x=GMT,y=Root_NSD)) + \n                        geom_point(color=window_recs$color) + geom_line(color=window_recs$color) +\n                        labs(x=\"GMT\",y=\"Root NSD\",title = paste0(\"Animal ID: \",individs_list[id])))\n                \n                # Pick start/end dates with locator;  assign/paste makes new variables for the loop\n                print(\"Click the start of the winter movement\")\n                start <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt <- plt + geom_vline(xintercept = start, color='limegreen'))\n                print(\"Click the end of the winter movement\")\n                end <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt <- plt + geom_vline(xintercept = end, color='darkred'))\n                \n                # Identify dates in selected range; identify habitat for dates prior to this range\n                year <- substr(yrs[y], 3, 4)\n                s <- as.POSIXct(start, origin = \"1970-01-01 00:00:00\",tz='UTC')\n                e <- as.POSIXct(end, origin = \"1970-01-01 00:00:00\",tz='UTC')\n                id_recs$habitat <- ifelse(s <= id_recs$GMT & id_recs$GMT <= e,\"wntmov\",id_recs$habitat)\n                id_recs$Hab_code <- stringr::str_split_fixed(id_recs$habitat,\"[:digit:]\",2)[,1]\n                id_recs <- dplyr::left_join(id_recs[,-which(stringr::str_detect(colnames(id_recs),\"color\")==T)],hab_palette[,c(-1)],by=\"Hab_code\")\n                \n                # ~~*plotting magic*~~\n                rmarkdown::render(paste0(scriptdir, \"/\", \"mapbox_plot.Rmd\"),  \n                                  output_file =  paste0(individs_list[id], \"_graphic.html\"), \n                                  output_dir = paste0(getwd(), \"/unsorted_output/\", \n                                                      herd, \"/\", yrs[y], sep = \"\"))\n                \n                shell.exec(paste0(getwd(), \"/unsorted_output/\",herd, \"/\", yrs[y],\"/\",individs_list[id], \"_graphic.html\", sep = \"\"))\n                if(readline(\"Open the output file. Look good? Y or N  \") == \"Y\"){\n                  break\n                }else{\n                  id_recs$habitat <- ifelse(s <= id_recs$GMT & id_recs$GMT <= e,\"not assigned\",\n                                            id_recs$habitat)\n                  id_recs$color <- ifelse(s <= id_recs$GMT & id_recs$GMT <= e,\"#000000\",\n                                          id_recs$color)\n                  id_recs$Hab_code <- NULL\n                }\n                \n              } # end of repeat for winter movement dates\n            } \n            if(mig == \"sm\"){\n              print(\"Select Summer Movement Dates\")\n              repeat{\n                # Plot NSD\n                print(\n                  plt <-ggplot(id_recs,aes(x=GMT,y=Root_NSD)) + \n                    geom_point(color=id_recs$color) + geom_line(color=id_recs$color) +\n                    labs(x=\"GMT\",y=\"Root NSD\",title = paste0(\"Animal ID: \",individs_list[id]))+\n                    theme_bw()\n                )\n                # Zoom in on dates of spring migration\n                print(\"Click the earlier date of the range you'd like to zoom to\")\n                windowstart <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt + geom_vline(xintercept = windowstart))\n                print(\"Click the later date of the range you'd like to zoom to\")\n                windowend <- ggmap::gglocator(n=1,mercator = F)$GMT\n                window_recs <- id_recs[as.numeric(na.omit(id_recs$GMT)) > \n                                         windowstart & as.numeric(na.omit(id_recs$GMT)) < windowend, ]\n                print(plt <- ggplot(window_recs,aes(x=GMT,y=Root_NSD)) + \n                        geom_point(color=window_recs$color) + geom_line(color=window_recs$color) +\n                        labs(x=\"GMT\",y=\"Root NSD\",title = paste0(\"Animal ID: \",individs_list[id])))\n                \n                # Pick start/end dates with locator;  assign/paste makes new variables for the loop\n                print(\"Click the start of the summer movement\")\n                start <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt <- plt + geom_vline(xintercept = start, color='limegreen'))\n                print(\"Click the end of the summer movement\")\n                end <- ggmap::gglocator(n=1,mercator = F)$GMT\n                print(plt <- plt + geom_vline(xintercept = end, color='darkred'))\n                \n                # Identify dates in selected range; identify habitat for dates prior to this range\n                year <- substr(yrs[y], 3, 4)\n                s <- as.POSIXct(start, origin = \"1970-01-01 00:00:00\",tz='UTC')\n                e <- as.POSIXct(end, origin = \"1970-01-01 00:00:00\",tz='UTC')\n                id_recs$habitat <- ifelse(s <= id_recs$GMT & id_recs$GMT <= e,\"summov\",id_recs$habitat)\n                id_recs$Hab_code <- stringr::str_split_fixed(id_recs$habitat,\"[:digit:]\",2)[,1]\n                id_recs <- dplyr::left_join(id_recs[,-which(stringr::str_detect(colnames(id_recs),\"color\")==T)],hab_palette[,c(-1)],by=\"Hab_code\")\n                \n                # ~~*plotting magic*~~\n                rmarkdown::render(paste0(scriptdir, \"/\", \"mapbox_plot.Rmd\"),  \n                                  output_file =  paste0(individs_list[id], \"_graphic.html\"), \n                                  output_dir = paste0(getwd(), \"/unsorted_output/\", \n                                                      herd, \"/\", yrs[y], sep = \"\"))\n                \n                shell.exec(paste0(getwd(), \"/unsorted_output/\",herd, \"/\", yrs[y],\"/\",individs_list[id], \"_graphic.html\", sep = \"\"))\n                if(readline(\"Open the output file. Look good? Y or N  \") == \"Y\"){\n                  break\n                }else{\n                  id_recs$habitat <- ifelse(s <= id_recs$GMT & id_recs$GMT <= e,\"not assigned\",\n                                            id_recs$habitat)\n                  id_recs$color <- ifelse(s <= id_recs$GMT & id_recs$GMT <= e,\"#000000\",\n                                          id_recs$color)\n                  id_recs$Hab_code <- NULL\n                }\n                \n              } # end of repeat for summer movement dates\n            }\n            BR <- readline(\"Classify more movements? Y or N \")\n            if(BR == \"N\"){\n              notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Strategy <- readline(\"Identify final migration strategy. \nPlease list M (migratory), MM(mixed-migratory), or U(unclear)  \")\n              break\n            }\n          } # end of repeat for migration date classifications\n        } # end of Date Selection    \n        rmarkdown::render(paste0(scriptdir, \"/\", \"mapbox_plot.Rmd\"),  \n                          output_file =  paste0(individs_list[id], \"_graphic.html\"), \n                          output_dir = paste0(getwd(), \"/unsorted_output/\", \n                                              herd, \"/\", yrs[y], sep = \"\"))\n        \n        shell.exec(paste0(getwd(), \"/unsorted_output/\",herd, \"/\", yrs[y],\"/\",individs_list[id], \"_graphic.html\", sep = \"\"))\n        if(readline(\"Open the output file. Look good? Y or N  \") == \"Y\"){break}\n        } #classify repeat\n        # Finish Classifying Dates\n        if(exists(\"discard_all\")){\n          discard_all$habitat <- \"Discard\"\n          discard_all$Hab_code <- \"Discard\"\n          discard_all <- dplyr::left_join(discard_all[,-which(stringr::str_detect(colnames(discard_all),\"color\")==T)],hab_palette[,c(-1)],by=\"Hab_code\")\n          id_recs <- id_recs %>%\n            rbind(.,discard_all) %>%\n            dplyr::arrange(.,GMT)\n          rm(discard_all,discard,discarded)\n        }\n        id_recs <- classify_dates(id_recs)\n        \n        #~~*plotting magic*~~\n        rmarkdown::render(paste0(scriptdir, \"/\", \"mapbox_plot.Rmd\"),   \n                          output_file =  paste0(individs_list[id], \"_graphic.html\"), \n                          output_dir = paste0(getwd(), \"/unsorted_output/\", \n                                              herd, \"/\", yrs[y], sep = \"\"))\n        \n        shell.exec(paste0(getwd(), \"/unsorted_output/\",herd, \"/\", yrs[y],\"/\",individs_list[id], \"_graphic.html\", sep = \"\"))\n        if(readline(\"Look good? Y or N  \") == \"Y\"){break}\n      }\n      if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Skip == \"Y\"){break}\n    } # end of repeat for individual\n      \n    notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Revisit <- readline(\"Revisit this animal later? Y or N \")\n    notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Notes <- readline(\"Write whatever notes you want \")\n    \n    # Paste labels onto the graphics\n    if(notes_tab[notes_tab$Animal_ID == individs_list[id], ]$Skip == \"Y\"){\n      id_recs$habitat  <- \"not assigned\"\n      notes_tab[notes_tab$Animal_ID == individs_list[id], !names(notes_tab) %in% c(\"Skip\", \"Months_of_Data\", \"Animal_ID\", \"Notes\",\"Region\",\"AnchorDate\",\"Revisit\")] <- NA  # ; wipe out any data created for this animal, b/c skipping it now\n    } \n    \n    # Flag Migrations that might be too short (less than 5 km)\n    notes_tab[notes_tab$Animal_ID == individs_list[id],]$FlagMig <- ifelse(is.na(notes_tab[notes_tab$Animal_ID == individs_list[id],]$SprMig_Dist)==T & is.na(notes_tab[notes_tab$Animal_ID == individs_list[id],]$FallMig_Dist)==T, F,\n                                                                           ifelse(is.na(notes_tab[notes_tab$Animal_ID == individs_list[id],]$FallMig_Dist)==T & is.na(notes_tab[notes_tab$Animal_ID == individs_list[id],]$SprMig_Dist)==F & notes_tab[notes_tab$Animal_ID == individs_list[id],]$SprMig_Dist <= 5000, T,\n                                                                                  ifelse(is.na(notes_tab[notes_tab$Animal_ID == individs_list[id],]$FallMig_Dist)==F & is.na(notes_tab[notes_tab$Animal_ID == individs_list[id],]$SprMig_Dist)==T & notes_tab[notes_tab$Animal_ID == individs_list[id],]$FallMig_Dist <= 5000, T,\n                                                                                        ifelse(notes_tab[notes_tab$Animal_ID == individs_list[id],]$FallMig_Dist <= 5000 | notes_tab[notes_tab$Animal_ID == individs_list[id],]$SprMig_Dist <= 5000, T, F))))\n    \n    print(\"Finalizing output graphics.\")\n    id_recs <- id_recs[year(id_recs$GMT) == yrs[y], ] # redefine id_records, now that id_recs is classified\n    rmarkdown::render(paste0(scriptdir, \"/\", \"mapbox_plot.Rmd\"),   \n                      output_file =  paste0(individs_list[id], \"_graphic.html\"), \n                      output_dir = paste0(getwd(), \"/unsorted_output/\", herd, \n                                          \"/\", yrs[y], sep = \"\"))\n    \n    print(\"Writing output tables.\")  \n    fwrite(id_recs, paste0(getwd(), \"/unsorted_output/\", herd, \"/\", yrs[y], \n                           \"/\", individs_list[id], \".csv\"), row.names = FALSE, \n           dateTimeAs = c(\"write.csv\"))\n    fwrite(notes_tab, paste0(getwd(), \"/unsorted_output/\", herd, \"/\", yrs[y], \n                             \"/\", yrs[y], \"_overall.csv\"), row.names = FALSE, \n           dateTimeAs = c(\"write.csv\"))\n    \n    \n    print(\"Updating overall table with new values.\")\n    all_recs <- all_recs %>%\n      dplyr::anti_join(.,id_recs[,-which(stringr::str_detect(colnames(id_recs),\"color|habitat|Hab_code\")==T)],by=c(\"Animal_ID\",\"GMT\")) %>%\n      rbind(.,id_recs[,-which(stringr::str_detect(colnames(id_recs),\"Hab_code\")==T)]) %>%\n      dplyr::arrange(.,Animal_ID,GMT)\n    \n    savecounter <- savecounter + 1\n    if(savecounter == 5){\n      print(\"5 animals done. Backing up the data table.\")\n      fwrite(all_recs, outfile, row.names = FALSE,  dateTimeAs = c(\"write.csv\"))\n      savecounter <- 0\n    } else if (readline(\"Save manually? Do this if you are exiting the script. Y or N  \") == \"Y\") {\n      fwrite(all_recs, outfile, row.names = FALSE, dateTimeAs = c(\"write.csv\"))\n      savecounter <- 0  \n    } else {\n      print(paste(\"Overall file will back up automatically after\", 5 - savecounter, \"more animals\"))\n    }  \n    grDevices::dev.off()\n    system2(\"taskkill\",args=\"/im chrome.exe\")\n  } # individual loop      \n  \n} # year loop"
  },
  {
    "objectID": "seasonalranges.html",
    "href": "seasonalranges.html",
    "title": "Ungulate Seasonal Ranges",
    "section": "",
    "text": "Created by potrace 1.15, written by Peter Selinger 2001-2017\n\n\n\n\n\n\n\n\nMule deer\n300,081 winter range locations\n\n987,558 total locations\n\n\n\n22 attributes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreated by potrace 1.15, written by Peter Selinger 2001-2017\n\n\n\n\n\n\n\n\nElk\n764,119 winter range locations\n\n2,661,400 total locations\n\n\n\n19 attributes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreated by potrace 1.8, written by Peter Selinger 2001-2007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPronghorn\n187,860 winter range locations\n\n731,025 total locations\n\n\n\n19 attributes\nI am currently an Associate Research Scientist for the Wyoming Cooperative Fish and Wildlife Research Unit modeling ungulate seasonal ranges and migrations for Idaho Department of Fish and Game in support of S.O. 3362. So far, I’ve completed winter range models for mule deer using the random forest machine learning algorithm in a resource selection function framework. I assembled these predictions into a dashboard to assist in assessing the predictions and outputs. Included in the dashboard are maps depicting the average predicted winter range for mule deer in each of IDFG’s mule deer data analysis units (DAUs). In addition, I’ve started to analyze the changes in winter range predictions across years."
  },
  {
    "objectID": "seasonalranges.html#fa-chart-line-winter-range-analysis-dashboard",
    "href": "seasonalranges.html#fa-chart-line-winter-range-analysis-dashboard",
    "title": "Ungulate Seasonal Ranges",
    "section": " Winter Range Analysis Dashboard",
    "text": "Winter Range Analysis Dashboard"
  },
  {
    "objectID": "seasonalranges.html#fa-map-average-winter-range-maps",
    "href": "seasonalranges.html#fa-map-average-winter-range-maps",
    "title": "Ungulate Seasonal Ranges",
    "section": " Average Winter Range Maps",
    "text": "Average Winter Range Maps\n\n\n\nStatewide average predicted mule deer winter range.\n\n\n\n\n\nStatewide average predicted elk winter range.\n\n\n\n\n\nStatewide average predicted pronghorn winter range.\n\n\n\n\n\nAverage predicted mule deer winter range in the Smokey-Boise Data Analysis Unit."
  },
  {
    "objectID": "seasonalranges.html#fa-snowflake-annual-winter-range-predictions",
    "href": "seasonalranges.html#fa-snowflake-annual-winter-range-predictions",
    "title": "Ungulate Seasonal Ranges",
    "section": " Annual Winter Range Predictions",
    "text": "Annual Winter Range Predictions"
  },
  {
    "objectID": "seasonalranges.html#fa-layer-group-vegetation-classification-covariates",
    "href": "seasonalranges.html#fa-layer-group-vegetation-classification-covariates",
    "title": "Ungulate Seasonal Ranges",
    "section": " Vegetation Classification Covariates",
    "text": "Vegetation Classification Covariates\nA major component of the seasonal range models is IDFG’s vegetation classification covariates which are derived from LANDFIRE. The models explicitly require each vegetation class to be transformed to a focal value based on the average daily movement distance of individuals in the DAU. To streamline this covariate transformation, I wrote a Python function using ESRI’s arcpy and Spatial Analyst tools, which are called by an R script I wrote to iterate the process over each collection of DAU covariates.\n\n Python Function\n\n# --------------------------------------------------------\n# Calculate Hurley Vegetation Focal Statistics\n# Author: Robert Ritson, Associate Research Scientist (UW)\n# Last Updated: 5/10/2022\n# Description: Calculate square meters of Hurley\n#   vegetation classes (binary rasters derrived from LANDFIRE)\n#   given a mean daily movement distance (from an ungulate population),\n#   clipped by a population DAU boundary\n# --------------------------------------------------------\n#Import modules\nimport arcpy\nfrom arcpy.sa import *\nimport datetime\nimport csv\nimport os\narcpy.CheckOutExtension(\"Spatial\")\n#Define function\ndef hveg_focal(path_to_dau, mdm_ci95, path_to_hveg, dau_hveg_folder, scratch = \"C:\\\\Users\\\\rritson\\\\Documents\\\\ArcGIS\\\\scratch\\\\\"):\n    try:\n        print 'begin script on '+datetime.datetime.now().date().isoformat()+' at '+datetime.datetime.now().time().isoformat()[0:8]\n\n        # Set path to folders and workspace\n        dauws = path_to_dau\n        rastws = path_to_hveg\n        outws = dau_hveg_folder\n        neighborhood = arcpy.sa.NbrCircle(mdm_ci95,\"MAP\")\n        arcpy.env.overwriteOuptput = False\n        arcpy.env.workspace = scratch\n\n        # Buffer Selected DAU by provided mean daily movement\n        print 'buffering DAU shape by mean daily movement input (meters)'\n        arcpy.Buffer_analysis(dauws,scratch+'\\\\DAU_Buffer.shp', mdm_ci95,\"FULL\",\"ROUND\",\"NONE\",\"\",\"PLANAR\")\n        \n        # List Hurley Vegetation Rasters\n        arcpy.env.workspace = rastws\n        try:\n            print 'listing Hveg rasters'\n            hveg_list = [hveg for hveg in arcpy.ListRasters()]\n        except:  print arcpy.GetMessages(2)\n\n        # Clip Hurley Vegetation Raster to buffered DAU and calculate focal statistics\n        arcpy.env.workspace = scratch\n        for hveg in hveg_list:\n            print 'loading raster '+hveg\n            arcpy.MakeRasterLayer_management(rastws+'/'+hveg,'temp_rast.tif',\"\",scratch+'/DAU_Buffer.shp',\"\") #load raster and clip to buffered DAU extent\n\n            print 'calculating focal statistics'\n            arcpy.CheckOutExtension(\"Spatial\")\n            fstat = FocalStatistics('temp_rast.tif',  neighborhood, \"SUM\", \"DATA\") #Focal sum of binaries by mean daily movement distance\n            \n            print 'converting to square meters'\n            outrast = fstat * (30^2) #multiply focal sum by cell dimensions (convert to square meters)\n            outrast.save(outws+hveg) #save output\n\n            print hveg+' raster saved to '+outws+' at '+datetime.datetime.now().time().isoformat()[0:8]\n\n        print 'Finished: Completed Hurley vegetation density rasters for '+dauws+' located in '+outws\n        print 'script completed on '+datetime.datetime.now().date().isoformat()+' at '+datetime.datetime.now().time().isoformat()[0:8]\n\n    except:  print arcpy.GetMessages(2)\narcpy.CheckInExtension(\"Spatial\")\n# # # # # END OF FUNCTION # # # # # # #\n\n\n\n R code\n\n## Hurley Vegetation Density Raster Calculations ##\n### Loop through remaining DAUs (~10min per DAU) ###\n#Load package\nrequire(dplyr)\n\n#devtools::install_github(\"rstudio/reticulate\")\n#Sys.setenv(RETICULATE_PYTHON = \"C:\\\\Python27\\\\ArcGIS10.8\\\\\\\\pythonw.exe\")\nSys.setenv(RETICULATE_PYTHON = 'C:/Users/rritson/AppData/Local/Programs/ArcGIS/Pro/bin/Python/envs/arcgispro-py3/python.exe')\nrequire(reticulate)\n\n\n#DAU List\ndau_list <- sf::st_read('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/DAU_BBox_10kbuff.shp') %>%\n  as.data.frame(.) %>%\n  dplyr::select(NAME) %>%\n  #dplyr::filter(NAME == \"Island Park\")\n  dplyr::filter(NAME %in% c(\"Bannock\",\"Caribou\",\"Mountain Valley\",\"Portneuf\",\"Weiser-McCall\"))\n  #dplyr::filter(!(NAME %in% c(\"Bitterroot\",\"Panhandle\",\"Lower Salmon\",\"Snake River\",\"Smokey-Boise\",\"Island Park\")))\n\n#DAU shape (all)\ndau_shp <- sf::st_read('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/DAU_BBox_10kbuff.shp') %>%\n  #dplyr::select(-GlobalID,-Shape_Leng,-Shape_Area) %>% \n  sfheaders::sf_remove_holes(.)\n\n#Movement Data\ndat <- readRDS(\"C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/Winter_RSF/MD_Winter_Locs_1pd.rds\") %>% as.data.frame(.)\n\n# Check R Session Info\nif(sessionInfo()$R.version$arch != \"i386\"){\n  print(\"STOP: Must run R in 32-bit Architecture to source 'arcpy'\")\n  }\nif(paste0(sessionInfo()$R.version$major,\".\",sessionInfo()$R.version$minor) > \"4.0.4\"){\n  print(\"STOP: Must run R in version prior or equal to 4.0.4 to source 'arcpy'\") \n  # reticulate does not want to work with R version 4.1.0...\n  }\n\n# Initiate Python before beginning loop\n#reticulate::use_python(\"C:\\\\Python27\\\\ArcGIS10.8\\\\\\\\pythonw.exe\", required = T)\nreticulate::use_python('C:/Users/rritson/AppData/Local/Programs/ArcGIS/Pro/bin/Python/envs/arcgispro-py3/python.exe', required = T)\nreticulate::py_config()\nreticulate::source_python(\"C:/Users/rritson/Documents/Python Scripts/hveg_focal_func.py\")\n#reticulate::source_python(\"C:/Users/rritson/Documents/Python Scripts/hveg_focal_func_sing.py\") #for dealing with a single raster (must change file paths below if so)\n\n# Loop through DAUs\nfor (i in 1:nrow(dau_list)){\n  \n  # Select DAU\n  print(paste(\"Beginning DAU:\",dau_list[i,],\"(\",nrow(dau_list)-i,\"remaining)...\"))\n  dau_sel <- dau_list[i,] \n  \n  # Create folder for outputs\n  #print(\"Creating output folder...\")\n  #dir.create(\"F:/Seasonal_range_covars/mdmci95_2buff\") \n  #dir.create(paste0(\"F:/Seasonal_range_covars/mdmci95_2buff/\",dau_sel)) \n  \n  # Write DAU shapefile\n  #print(\"Writing shapefile...\")\n  #dau <- dau_shp %>% dplyr::filter(NAME == dau_sel)\n  #sf::write_sf(dau,paste0('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/SeasonalRanges/',dau_sel,\".shp\"),append=F)\n  \n  # Get Mean Daily Movements for DAU\n  print(\"Accessing mean daily movement (95% CI, in meters)...\")\n  mdm_ci95 <- dat %>% dplyr::filter(DAU == dau_sel) %>% dplyr::select(MDM_CI95_avg) %>% dplyr::slice(1)\n  mdm_ci95 <- mdm_ci95[[1]]\n  mdm_ci95_2 <- mdm_ci95 / 2\n  \n  # Calculate Hurley vegetation density raster for DAU: Mean Daily Movement\n  print(\"Reticulating HVeg Density Raster Calculation (Mean Daily Movement)...\")\n  hveg_focal(path_to_dau = paste0('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/SeasonalRanges/',dau_sel,\".shp\"),\n             mdm_ci95 = mdm_ci95, #mean daily movement\n             path_to_hveg = \"F:\\\\Seasonal_range_covars\\\\hveg\",\n             dau_hveg_folder = paste0(\"F:/Seasonal_range_covars/mdmci95_buff/\",dau_sel,\"/\"), #CHANGE THIS!!! (to match output folder)\n             scratch = \"C:/Users/rritson/Documents/ArcGIS/scratch\")\n  \n  #Delete temp files\n  lapply(list.files(\"C:/Users/rritson/Documents/ArcGIS/scratch\",full.names = T),file.remove)\n  gc()\n  \n  # Calculate Hurley vegetation density raster for DAU: One-half Mean Daily Movement\n  print(\"Reticulating HVeg Density Raster Calculation (One-Half Mean Daily Movement)...\")\n  hveg_focal(path_to_dau = paste0('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/SeasonalRanges/',dau_sel,\".shp\"),\n             mdm_ci95 = mdm_ci95_2, #one-half mean daily movement\n             path_to_hveg = \"F:\\\\Seasonal_range_covars\\\\hveg\",\n             dau_hveg_folder = paste0(\"F:/Seasonal_range_covars/mdmci95_2buff/\",dau_sel,\"/\"), #CHANGE THIS!!! (to match output folder)\n             scratch = \"C:/Users/rritson/Documents/ArcGIS/scratch\")\n  \n  #Delete temp files\n  lapply(list.files(\"C:/Users/rritson/Documents/ArcGIS/scratch\",full.names = T),file.remove)\n  gc()\n}"
  },
  {
    "objectID": "thesis.html",
    "href": "thesis.html",
    "title": "Bison Spatial Ecology",
    "section": "",
    "text": "Bison\n145,577 locations\n\n5 study areas\n\n\n\n16 attributes\nMy master’s thesis examined the space-use and resource selection patterns of five variously managed bison herds to ascertain ecological function. I was particularly interested in how these patterns varied between free-range herds and fenced herds."
  },
  {
    "objectID": "thesis.html#fa-chart-line-space-use-patterns",
    "href": "thesis.html#fa-chart-line-space-use-patterns",
    "title": "Bison Spatial Ecology",
    "section": " Space-Use Patterns",
    "text": "Space-Use Patterns\nOne of the major spatial aspects I was interested in was how much space bison required to be ‘ecologically effective’. I looked at two aspects of this including home range size which I modeled using autocorrelated kernel density estimates and forage patch size which I estimated using first-passage time analysis. My most interesting finding was that home range size appeared to significantly differ between herds while forage patch size did not. This has implications for the scale at which we conserve and manage bison. \n\n Autocorrelated Kernel Density Estimation\nBison home range estimation\n\n\n\n\n\n\nModel outputs of covariate influences on home range sizes.\n\n\n\n First-Passage Time Analysis\nDuring the growing season, free-range bison appear to forage at larger scales than fenced bison."
  },
  {
    "objectID": "thesis.html#fa-map-location-dot-habitat-selection",
    "href": "thesis.html#fa-map-location-dot-habitat-selection",
    "title": "Bison Spatial Ecology",
    "section": " Habitat Selection",
    "text": "Habitat Selection\n\n\nResource Selection Functions"
  },
  {
    "objectID": "writingsamples.html",
    "href": "writingsamples.html",
    "title": "Writing Samples",
    "section": "",
    "text": "Thesis"
  },
  {
    "objectID": "writingsamples.html#publications",
    "href": "writingsamples.html#publications",
    "title": "Writing Samples",
    "section": "Publications",
    "text": "Publications\n\n\n\nSolar Eclipse"
  },
  {
    "objectID": "writingsamples.html#fsvm-package-vignettes",
    "href": "writingsamples.html#fsvm-package-vignettes",
    "title": "Writing Samples",
    "section": "fsvm Package Vignettes",
    "text": "fsvm Package Vignettes\n\n\n\nData formatting vignette\n\n\n\n\n\nModel training vignette"
  }
]