[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Robert Ritson’s GIS Portfolio",
    "section": "",
    "text": "Hello,\nI’m Rob Ritson. I am a wildlife research scientist specializing in movement and spatial ecology. I am skilled at creating and managing large geographic information databases and proficient in RStudio and the ESRI suite. I am continuing to develop my coding skills in Python and currently teaching myself Julia.\nI have 5+ years of field experience conducting population and habitat monitoring with a diversity of species in collaboration with state and federal agencies as well as 5+ years analytical experience managing large GPS data sets, assessing spatial patterns, and composing scientific manuscripts.\n\n\n\nChecking wildlife camera traps in North Idaho as an IDFG Widlife Technicain"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "M.S. Biology, University of Nebraska-Kearney (2019)\n B.S. Wildlife and Fisheries Sciences, The Pennsylvania State University (2014)"
  },
  {
    "objectID": "Solar Eclipse.html",
    "href": "Solar Eclipse.html",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": "",
    "text": "Background on master’s side project, assessing movements during 2017 solar eclipse\nI wrote a python function to be called from R…"
  },
  {
    "objectID": "Solar Eclipse.html#python-function",
    "href": "Solar Eclipse.html#python-function",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": "Python function",
    "text": "Python function\n\n#------------------------- Eclipse Percent Py ------------------------------------------#\n# Sourced from : Graeme Coates, March 18, 2015\n# Accessed: 10/8/21\n# https://www.chromosphere.co.uk/wp-content/blogs.dir/1/files/2015/03/eclipse_percent.py\n# https://www.chromosphere.co.uk/2015/03/18/eclipse-calculations-using-python/\n#---------------------------------------------------------------------------------------#\n# Modified by Rob Ritson, 10/18/2021 into a function for Great American Solar Eclipse\n# Args: Longitude (dd.mmmm), Latitude (dd.mmmm), Elevation (meters)\n# Returns: MaxEclipseTime (GMT), MaxEclipsePercent (obscuration), FirstContactTime, LastContactTime\n# Uses Python module ephem\n#---------------------------------------------------------------------------------------#\nimport ephem\nimport math\nimport numpy as n\nfrom operator import itemgetter\n\ndef check_non_zero(x):\n    return x > 0\n\ndef eclipse_calculator(longitude, latitude, elevation):\n  \"\"\"Calculate Eclipse Conditions\"\"\"\n  timetuple=(2017, 8, 21, 00, 00, 00)\n  gatech=ephem.Observer()\n  gatech.epoch= '2017'\n  gatech.date=timetuple\n  gatech.lon=longitude\n  gatech.lat=latitude\n  gatech.elevation=elevation\n  gatech.compute_pressure()\n  sun, moon = ephem.Sun(gatech), ephem.Moon(gatech)\n  results=[]\n  for x in range(0,86400):\n      gatech.date= (ephem.date(ephem.date(timetuple)+x*ephem.second))\n      sun.compute(gatech)\n      moon.compute(gatech)\n      r_sun=(sun.size/2.0)/3600.0\n      r_moon=(moon.size/2.0)/3600.0\n      s=n.degrees(ephem.separation((sun.az, sun.alt), (moon.az, moon.alt)))\n      try:\n          if s<(r_moon+r_sun):\n              lunedelta=0.25*math.sqrt((r_sun+r_moon+s)*(r_moon+s-r_sun)*(s+r_sun-r_moon)*(r_sun+r_moon-s))\n          else: \n              lunedelta=None\n              percent_eclipse=0\n          if lunedelta: \n              lune_area=2*lunedelta + r_sun*r_sun*(math.acos(((r_moon*r_moon)-(r_sun*r_sun)-(s*s))/(2*r_sun*s))) - r_moon*r_moon*(math.acos(((r_moon*r_moon)+(s*s)-(r_sun*r_sun))/(2*r_moon*s)))\n              percent_eclipse=(1-(lune_area/(math.pi*r_sun*r_sun)))*100 \n          \n          results.append([gatech.date.datetime(),s,sun.size,moon.size,lune_area if lunedelta else 0, percent_eclipse]) \n      except ValueError:\n        pass\n\n  gen=(x for x in results) \n  max_eclipse=max(gen, key=itemgetter(5))\n  MaxEclipseTime = str(max_eclipse[0])\n  MaxEclipsePercent = max_eclipse[5]\n  gen=(x for x in results) \n  try:\n    FirstContactTime = str(next(x for x in gen if check_non_zero(x[5]))[0]) \n  except:\n    FirstContactTime = str('NA') \n  try:\n    LastContactTime = str(next(x for x in gen if x[5]==0)[0]) \n  except: \n    LastContactTime = str('NA')\n  out = [MaxEclipseTime, MaxEclipsePercent, FirstContactTime, LastContactTime]\n  return out\n\n\n------------------------- Eclipse Percent Py ------------------------------------------#\n# Sourced from : Graeme Coates, March 18, 2015\n# Accessed: 10/8/21\n# https://www.chromosphere.co.uk/wp-content/blogs.dir/1/files/2015/03/eclipse_percent.py\n# https://www.chromosphere.co.uk/2015/03/18/eclipse-calculations-using-python/\n#---------------------------------------------------------------------------------------#\n# Modified by Rob Ritson, 1/17/2022 into a function for Great American Solar Eclipse\n# Args: hr (hour), mn (minutes), sc (seconds), Longitude (dd.mmmm), Latitude (dd.mmmm), Elevation (meters)\n# First three arguments are used to create timetuple object for calculating eclipse circumstances\n# Returns: percent eclipse\n# Uses Python module ephem\n#---------------------------------------------------------------------------------------#\nimport ephem\nimport math\nimport numpy as n\n\ndef eclipse_calculator_local(hr, mn, sc, longitude, latitude, elevation):\n  \"\"\"Calculate Eclipse Conditions\"\"\"\n  timetuple=(2017, 8, 21, hr, mn, sc)\n  gatech=ephem.Observer()\n  gatech.epoch= '2017'\n  gatech.date=timetuple\n  gatech.lon=longitude\n  gatech.lat=latitude\n  gatech.elevation=elevation\n  gatech.compute_pressure()\n  sun, moon = ephem.Sun(gatech), ephem.Moon(gatech)\n  sun.compute(gatech)\n  moon.compute(gatech)\n  r_sun=(sun.size/2.0)/3600.0\n  r_moon=(moon.size/2.0)/3600.0\n  s=n.degrees(ephem.separation((sun.az, sun.alt), (moon.az, moon.alt)))\n  if s<(r_moon+r_sun):\n      lunedelta=0.25*math.sqrt((r_sun+r_moon+s)*(r_moon+s-r_sun)*(s+r_sun-r_moon)*(r_sun+r_moon-s))\n  else:\n      lunedelta=None\n      percent_eclipse=0\n  if lunedelta: \n      lune_area=2*lunedelta + r_sun*r_sun*(math.acos(((r_moon*r_moon)-(r_sun*r_sun)-(s*s))/(2*r_sun*s))) - r_moon*r_moon*(math.acos(((r_moon*r_moon)+(s*s)-(r_sun*r_sun))/(2*r_moon*s)))\n      percent_eclipse=(1-(lune_area/(math.pi*r_sun*r_sun)))*100 \n\n  return percent_eclipse"
  },
  {
    "objectID": "Solar Eclipse.html#r-code",
    "href": "Solar Eclipse.html#r-code",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": "R Code",
    "text": "R Code\n\n## Calculate Local Circumstances of Great American Solar Eclipse ####\n# Load required packages\nlapply(c(\"data.table\",\"reticulate\",\"furrr\",\"readr\",\"progressr\",\"future\"),require,character.only=T)\n\n# Source Python Script (EclipseCalculator.py)\nreticulate::source_python(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/EclipseCalculator.py\")\n\n# Load data\ndf <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASE_elevation.csv\")\nstr(df)\ndf$Latitude <- as.character(df$Latitude)\ndf$Longitude <- as.character(df$Longitude)\n\n## Calculate Local Circumstances of Eclipse\n#todo <- df\ntodo <- subset(df,!(df$ID %in% out_df$ID))\nout_df <- NULL\nfor(i in 1:length(unique(todo$ID))){\n  elev_df <- subset(todo, todo$ID == unique(todo$ID)[i])\n  arg_list <- elev_df[,c(\"Longitude\",\"Latitude\",\"elevation\")]\n  colnames(arg_list) <- NULL\n  future::plan(multicore,workers = availableCores()-1) #parallel processing\n  skip <- F\n  tryCatch({\n    progressr::with_progress({\n      p <- progressr::progressor(steps = nrow(arg_list))\n      final <- furrr::future_pmap(arg_list, function(long, lat, elev){ \n        p() #add progress bar\n        e <- eclipse_calculator(long, lat, elev)\n      })\n    })\n  },error = function(e){skip <<- T})\n  if(skip){next}\n  \n  final_df <- data.frame(matrix(unlist(final), nrow = length(final), byrow=TRUE))\n  colnames(final_df) <- c(\"MaxEclipseTime\",\"MaxObscuration\",\"FirstContact\",\"LastContact\")\n  out <- cbind(elev_df,final_df)\n  \n  out[[\"MaxEclipseTime\"]] <- as.POSIXct(out[[\"MaxEclipseTime\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  out[[\"FirstContact\"]] <- as.POSIXct(out[[\"FirstContact\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  out[[\"LastContact\"]] <- as.POSIXct(out[[\"LastContact\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  \n  out_df <- rbind(out_df, out)\n  \n  print(paste(\"Iteration\",i,\"of\",length(unique(todo$ID)),\"Completed\"))\n}\nreadr::write_csv(out_df,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\nnas <- subset(out_df,is.na(out_df$FirstContact)) #Indiv 154 is only NAs (brown pelican)\nout_df<- subset(out_df,!is.na(out_df$FirstContact))\nany(is.na(out_df$FirstContact))\nreadr::write_csv(out_df,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\") #Clean file\n#####\n## Calculate Eclipse Duration and Identify Eclipse Locations ####\nrequire(lubridate)\neclipse <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\neclipse$interval <- lubridate::interval(eclipse$FirstContact, eclipse$LastContact)\neclipse$duration_sec <- as.numeric(lubridate::as.duration(eclipse$interval))\neclipse$active_eclipse <- ifelse(eclipse$Timestamp %within% eclipse$interval,'Yes','No')\nreadr::write_csv(eclipse,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\n####\n## Load packages\nlapply(c(\"data.table\",\"reticulate\",\"furrr\",\"readr\",\"progressr\",\"future\"),require,character.only=T)\n\n## Load Data\neclipse <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\n\n# Subset Eclipse Locations\nactive <- subset(eclipse,eclipse$active_eclipse=='Yes')\nactive$hour <- lubridate::hour(active$Timestamp)\nactive$minute <- lubridate::minute(active$Timestamp)\nactive$second <- lubridate::second(active$Timestamp)\n\n# Calculate percent eclipse for each location recorded during the eclipse #\nreticulate::source_python(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/EclipseCalculatorLocalConditions.py\")\n\n## Calculate Local Circumstances of Eclipse Conditions\narg_list <- active[,c(\"hour\",\"minute\",\"second\",\"Longitude\",\"Latitude\",\"elevation\")]\ncolnames(arg_list) <- NULL\nfuture::plan(multicore,workers = availableCores()-1) #parallel processing\nprogressr::with_progress({\n  p <- progressr::progressor(steps = nrow(arg_list))\n  final <- furrr::future_pmap(arg_list, function(hr, mn, sc, long, lat, elev){ \n        p() #add progress bar\n        e <- eclipse_calculator_local(hr, mn, sc, long, lat, elev)\n      })\n    })\nfinal_df <- data.frame(matrix(unlist(final), nrow = length(final), byrow=TRUE))\ncolnames(final_df) <- \"Observed_Obscuration\"\nout <- cbind(active,final_df)\nreadr::write_csv(out,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions_Active.csv\")\n#####"
  },
  {
    "objectID": "eclipseproj.html",
    "href": "eclipseproj.html",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": "",
    "text": "During my master’s thesis, I completed a side project funded by a NASA mini-grant which assessed wildlife movements during the 2017 Great American Solar Eclipse. GPS data was provided by a number of collaborators from across the country. I published one article related to this research, and another is currently in preparation, but the analysis is on-going. I recently enhanced this analysis by leveraging the powerful astronomical calculation Python module ephem into a function called by R to assess the conditions of the solar eclipse experienced by each recorded location of each individual animal in order to parse potential behavioral changes related to the eclipse. This research is currently being prepared for Movement Ecology."
  },
  {
    "objectID": "eclipseproj.html#python-function",
    "href": "eclipseproj.html#python-function",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": "Python function",
    "text": "Python function\n\n#------------------------- Eclipse Percent Py ------------------------------------------#\n# Sourced from : Graeme Coates, March 18, 2015\n# Accessed: 10/8/21\n# https://www.chromosphere.co.uk/wp-content/blogs.dir/1/files/2015/03/eclipse_percent.py\n# https://www.chromosphere.co.uk/2015/03/18/eclipse-calculations-using-python/\n#---------------------------------------------------------------------------------------#\n# Modified by Rob Ritson, 10/18/2021 into a function for Great American Solar Eclipse\n# Args: Longitude (dd.mmmm), Latitude (dd.mmmm), Elevation (meters)\n# Returns: MaxEclipseTime (GMT), MaxEclipsePercent (obscuration), FirstContactTime, LastContactTime\n# Uses Python module ephem\n#---------------------------------------------------------------------------------------#\nimport ephem\nimport math\nimport numpy as n\nfrom operator import itemgetter\n\ndef check_non_zero(x):\n    return x > 0\n\ndef eclipse_calculator(longitude, latitude, elevation):\n  \"\"\"Calculate Eclipse Conditions\"\"\"\n  timetuple=(2017, 8, 21, 00, 00, 00)\n  gatech=ephem.Observer()\n  gatech.epoch= '2017'\n  gatech.date=timetuple\n  gatech.lon=longitude\n  gatech.lat=latitude\n  gatech.elevation=elevation\n  gatech.compute_pressure()\n  sun, moon = ephem.Sun(gatech), ephem.Moon(gatech)\n  results=[]\n  for x in range(0,86400):\n      gatech.date= (ephem.date(ephem.date(timetuple)+x*ephem.second))\n      sun.compute(gatech)\n      moon.compute(gatech)\n      r_sun=(sun.size/2.0)/3600.0\n      r_moon=(moon.size/2.0)/3600.0\n      s=n.degrees(ephem.separation((sun.az, sun.alt), (moon.az, moon.alt)))\n      try:\n          if s<(r_moon+r_sun):\n              lunedelta=0.25*math.sqrt((r_sun+r_moon+s)*(r_moon+s-r_sun)*(s+r_sun-r_moon)*(r_sun+r_moon-s))\n          else: \n              lunedelta=None\n              percent_eclipse=0\n          if lunedelta: \n              lune_area=2*lunedelta + r_sun*r_sun*(math.acos(((r_moon*r_moon)-(r_sun*r_sun)-(s*s))/(2*r_sun*s))) - r_moon*r_moon*(math.acos(((r_moon*r_moon)+(s*s)-(r_sun*r_sun))/(2*r_moon*s)))\n              percent_eclipse=(1-(lune_area/(math.pi*r_sun*r_sun)))*100 \n          \n          results.append([gatech.date.datetime(),s,sun.size,moon.size,lune_area if lunedelta else 0, percent_eclipse]) \n      except ValueError:\n        pass\n\n  gen=(x for x in results) \n  max_eclipse=max(gen, key=itemgetter(5))\n  MaxEclipseTime = str(max_eclipse[0])\n  MaxEclipsePercent = max_eclipse[5]\n  gen=(x for x in results) \n  try:\n    FirstContactTime = str(next(x for x in gen if check_non_zero(x[5]))[0]) \n  except:\n    FirstContactTime = str('NA') \n  try:\n    LastContactTime = str(next(x for x in gen if x[5]==0)[0]) \n  except: \n    LastContactTime = str('NA')\n  out = [MaxEclipseTime, MaxEclipsePercent, FirstContactTime, LastContactTime]\n  return out\n\n\n------------------------- Eclipse Percent Py ------------------------------------------#\n# Sourced from : Graeme Coates, March 18, 2015\n# Accessed: 10/8/21\n# https://www.chromosphere.co.uk/wp-content/blogs.dir/1/files/2015/03/eclipse_percent.py\n# https://www.chromosphere.co.uk/2015/03/18/eclipse-calculations-using-python/\n#---------------------------------------------------------------------------------------#\n# Modified by Rob Ritson, 1/17/2022 into a function for Great American Solar Eclipse\n# Args: hr (hour), mn (minutes), sc (seconds), Longitude (dd.mmmm), Latitude (dd.mmmm), Elevation (meters)\n# First three arguments are used to create timetuple object for calculating eclipse circumstances\n# Returns: percent eclipse\n# Uses Python module ephem\n#---------------------------------------------------------------------------------------#\nimport ephem\nimport math\nimport numpy as n\n\ndef eclipse_calculator_local(hr, mn, sc, longitude, latitude, elevation):\n  \"\"\"Calculate Eclipse Conditions\"\"\"\n  timetuple=(2017, 8, 21, hr, mn, sc)\n  gatech=ephem.Observer()\n  gatech.epoch= '2017'\n  gatech.date=timetuple\n  gatech.lon=longitude\n  gatech.lat=latitude\n  gatech.elevation=elevation\n  gatech.compute_pressure()\n  sun, moon = ephem.Sun(gatech), ephem.Moon(gatech)\n  sun.compute(gatech)\n  moon.compute(gatech)\n  r_sun=(sun.size/2.0)/3600.0\n  r_moon=(moon.size/2.0)/3600.0\n  s=n.degrees(ephem.separation((sun.az, sun.alt), (moon.az, moon.alt)))\n  if s<(r_moon+r_sun):\n      lunedelta=0.25*math.sqrt((r_sun+r_moon+s)*(r_moon+s-r_sun)*(s+r_sun-r_moon)*(r_sun+r_moon-s))\n  else:\n      lunedelta=None\n      percent_eclipse=0\n  if lunedelta: \n      lune_area=2*lunedelta + r_sun*r_sun*(math.acos(((r_moon*r_moon)-(r_sun*r_sun)-(s*s))/(2*r_sun*s))) - r_moon*r_moon*(math.acos(((r_moon*r_moon)+(s*s)-(r_sun*r_sun))/(2*r_moon*s)))\n      percent_eclipse=(1-(lune_area/(math.pi*r_sun*r_sun)))*100 \n\n  return percent_eclipse"
  },
  {
    "objectID": "eclipseproj.html#r-code",
    "href": "eclipseproj.html#r-code",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": "R Code",
    "text": "R Code\n\n## Calculate Local Circumstances of Great American Solar Eclipse ####\n# Load required packages\nlapply(c(\"data.table\",\"reticulate\",\"furrr\",\"readr\",\"progressr\",\"future\"),require,character.only=T)\n\n# Source Python Script (EclipseCalculator.py)\nreticulate::source_python(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/EclipseCalculator.py\")\n\n# Load data\ndf <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASE_elevation.csv\")\nstr(df)\ndf$Latitude <- as.character(df$Latitude)\ndf$Longitude <- as.character(df$Longitude)\n\n## Calculate Local Circumstances of Eclipse\n#todo <- df\ntodo <- subset(df,!(df$ID %in% out_df$ID))\nout_df <- NULL\nfor(i in 1:length(unique(todo$ID))){\n  elev_df <- subset(todo, todo$ID == unique(todo$ID)[i])\n  arg_list <- elev_df[,c(\"Longitude\",\"Latitude\",\"elevation\")]\n  colnames(arg_list) <- NULL\n  future::plan(multicore,workers = availableCores()-1) #parallel processing\n  skip <- F\n  tryCatch({\n    progressr::with_progress({\n      p <- progressr::progressor(steps = nrow(arg_list))\n      final <- furrr::future_pmap(arg_list, function(long, lat, elev){ \n        p() #add progress bar\n        e <- eclipse_calculator(long, lat, elev)\n      })\n    })\n  },error = function(e){skip <<- T})\n  if(skip){next}\n  \n  final_df <- data.frame(matrix(unlist(final), nrow = length(final), byrow=TRUE))\n  colnames(final_df) <- c(\"MaxEclipseTime\",\"MaxObscuration\",\"FirstContact\",\"LastContact\")\n  out <- cbind(elev_df,final_df)\n  \n  out[[\"MaxEclipseTime\"]] <- as.POSIXct(out[[\"MaxEclipseTime\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  out[[\"FirstContact\"]] <- as.POSIXct(out[[\"FirstContact\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  out[[\"LastContact\"]] <- as.POSIXct(out[[\"LastContact\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  \n  out_df <- rbind(out_df, out)\n  \n  print(paste(\"Iteration\",i,\"of\",length(unique(todo$ID)),\"Completed\"))\n}\nreadr::write_csv(out_df,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\nnas <- subset(out_df,is.na(out_df$FirstContact)) #Indiv 154 is only NAs (brown pelican)\nout_df<- subset(out_df,!is.na(out_df$FirstContact))\nany(is.na(out_df$FirstContact))\nreadr::write_csv(out_df,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\") #Clean file\n#####\n## Calculate Eclipse Duration and Identify Eclipse Locations ####\nrequire(lubridate)\neclipse <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\neclipse$interval <- lubridate::interval(eclipse$FirstContact, eclipse$LastContact)\neclipse$duration_sec <- as.numeric(lubridate::as.duration(eclipse$interval))\neclipse$active_eclipse <- ifelse(eclipse$Timestamp %within% eclipse$interval,'Yes','No')\nreadr::write_csv(eclipse,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\n####\n## Load packages\nlapply(c(\"data.table\",\"reticulate\",\"furrr\",\"readr\",\"progressr\",\"future\"),require,character.only=T)\n\n## Load Data\neclipse <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\n\n# Subset Eclipse Locations\nactive <- subset(eclipse,eclipse$active_eclipse=='Yes')\nactive$hour <- lubridate::hour(active$Timestamp)\nactive$minute <- lubridate::minute(active$Timestamp)\nactive$second <- lubridate::second(active$Timestamp)\n\n# Calculate percent eclipse for each location recorded during the eclipse #\nreticulate::source_python(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/EclipseCalculatorLocalConditions.py\")\n\n## Calculate Local Circumstances of Eclipse Conditions\narg_list <- active[,c(\"hour\",\"minute\",\"second\",\"Longitude\",\"Latitude\",\"elevation\")]\ncolnames(arg_list) <- NULL\nfuture::plan(multicore,workers = availableCores()-1) #parallel processing\nprogressr::with_progress({\n  p <- progressr::progressor(steps = nrow(arg_list))\n  final <- furrr::future_pmap(arg_list, function(hr, mn, sc, long, lat, elev){ \n        p() #add progress bar\n        e <- eclipse_calculator_local(hr, mn, sc, long, lat, elev)\n      })\n    })\nfinal_df <- data.frame(matrix(unlist(final), nrow = length(final), byrow=TRUE))\ncolnames(final_df) <- \"Observed_Obscuration\"\nout <- cbind(active,final_df)\nreadr::write_csv(out,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions_Active.csv\")\n#####"
  },
  {
    "objectID": "fsvmproj.html",
    "href": "fsvmproj.html",
    "title": "Fine Scale Vegetation Model",
    "section": "",
    "text": "As a Research Associate for the Wildlife Management Institute, I contributed to the on-going development of Idaho Department of Fish and Game’s Fine Scale Vegetation Model. The purpose of this project is to model understory forage vegetation species important to big game ungulates at a one meter spatial resolution. To accomplish this, IDFG contracted with University of Idaho to develop a covariate database, which was created using eCognition object-oriented image analysis that divided Idaho into ~44 million individual shapes, each of which was populated with landscape covariates.\nMy contribution to further this project was to streamline the modeling process by creating R package fsvm. Using the eCognition covariate database, along with IDFG and partner vegetation survey data, were modeled using machine learning algorithms. In addition to managing the modeling algorithms, the fsvm package provides tools to manage and format survey data as well create prediction maps."
  },
  {
    "objectID": "seasonalranges.html",
    "href": "seasonalranges.html",
    "title": "Ungulate Seasonal Ranges",
    "section": "",
    "text": "I am currently an Associate Research Scientist for the Wyoming Cooperative Fish and Wildlife Research Unit modeling ungulate seasonal ranges and migrations for Idaho Department of Fish and Game in support of S.O. 3362. So far, I’ve completed winter range models for mule deer using the random forest machine learning algorithm in a resource selection function framework. I assembled these predictions into a dashboard to assist in assessing the predictions and outputs. Included in the dashboard are maps depicting the average predicted winter range for mule deer in each of IDFG’s mule deer data analysis units (DAUs). In addition, I’ve started to analyze the changes in winter range predictions across years."
  },
  {
    "objectID": "bisonproj.html",
    "href": "bisonproj.html",
    "title": "Bison",
    "section": "",
    "text": "I completed my master’s thesis in biology at the University of Nebraska-Kearney with Dr. Dustin Ranglack studying bison spatial ecology. My research examined space-use and habitat selection patterns across five different herds with varying management regimes including free-range and fenced pastures. My first chapter on space-use patterns is currently being prepared for Journal of Wildlife Management and my second chapter on habitat selection is being prepared for Conservation Biology."
  },
  {
    "objectID": "about.html#certifcations",
    "href": "about.html#certifcations",
    "title": "Curriculum Vitae",
    "section": "Certifcations",
    "text": "Certifcations\nAssociate Wildlife Biologist®, The Wildlife Society"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Curriculum Vitae",
    "section": "Experience",
    "text": "Experience\n Associate Research Scientist, University of Wyoming and Idaho Department of Fish and Game, February 2022 - present.\n Research Associate - Vegetation Modeling, Wildlife Management Institute and Idaho Department of Fish and Game, March 2021 - January 2022.\n Wildlife Technician, Idaho Department of Fish and Game, November 2019 - June 2020; November 2020 - March 2021.\n Habitat Biologist Technician, Wyoming Game and Fish Department, May - October 2019.\n Biological Science Technician (GS-05), USFS Rocky Mountain Research Station, June - September 2016; June - August 2017.\n Wild Turkey Technician, West Virginia University, April - June 2017.\n Lead Wildlife Research Technician, Idaho Department of Fish and Game, March - May 2016.\n Research Associate, Montana State University, June - October 2015.\n Sage-grouse Technician, University of Wyoming, March - June 2015.\n Snowshoe Hare Technician, Pennsylvania Cooperative Fish and Wildlife Research Unit, January - March 2015.\n Biological Science Aid (GS-03), Wind Cave National Park, June - August 2014."
  },
  {
    "objectID": "about.html#research-projects",
    "href": "about.html#research-projects",
    "title": "Curriculum Vitae",
    "section": "Research Projects",
    "text": "Research Projects\n Mule deer seasonal range analysis. February 2022 – present. Collaborators: Scott Bergen, Matt Mumma, Shane Roberts, Mark Hurley. Idaho Department of Fish and Game. Pocatello, ID.\n Fine-scale vegetation model. March 2021 – present. Collaborators: Erin Roche, Sara Thompson, Scott Bergen, Matt Mumma, Shane Roberts, Mark Hurley. Idaho Department of Fish and Game. Boise, ID.\n Thesis: Spatial Ecology of Bison in the American West. August 2017 - May 2019 Collaborators: Nate Bickford, Melissa Wuellner, Angela Hollman, and Dustin H. Ranglack. University of Nebraska-Kearney. Kearney, NE.\n Effects of 2017 solar eclipse on animal behavior. August 2017 - May 2019. Collaborators: Nate Bickford, Melissa Wuellner, Dustin H. Ranglack, et al. University of Nebraska-Kearney. Kearney, NE.\n Ecological Correlates of Game Bird Distribution in Northern Tanzania. February – May 2013. Advisor: John Kioko. The School for Field Studies Center for Wildlife Management Studies. Karatu, TZ."
  },
  {
    "objectID": "about.html#publications",
    "href": "about.html#publications",
    "title": "Curriculum Vitae",
    "section": "Publications",
    "text": "Publications\n Ritson R, Ranglack DH, Bickford N. 2019. Comparing Social Media Observations of Animals During a Solar Eclipse to Published Research. Animals 9(59):1-12. doi:10.3390/ani9020059\n\n Ritson R, Barg A, Shannon J, Hershey K, Shoenecker KA, Beard D, Kunkel K, Kinka D, Ranglack DH. Seasonal space use patterns of American bison across multiple management regimes. Prepared for Journal of Wildlife Management.\n\n\n Ritson R, Bickford N, Wuellner M, Fuda RK, Miller TA, Boulanger JR, Beasley JC, Brzorad JN, Fisher R, Orben RA, Barber M, Kays R, Watson JL, Ranglack DH. Obscured Sun, Obscure Behavior: Exploring the Effects of a Solar Eclipse on Animal Movement. Prepared for Movement Ecology."
  },
  {
    "objectID": "about.html#presentations-and-posters",
    "href": "about.html#presentations-and-posters",
    "title": "Curriculum Vitae",
    "section": "Presentations and Posters",
    "text": "Presentations and Posters\n Ritson R, Mumma M, Roche E, Bergen S, Roberts S, Hurley M. Towards a fine scale vegetation model. Idaho Chapter of The Wildlife Society Annual Meeting. Virtual. Feb 2022. Oral presentation.\n Bergen S, Ritson R, Hurley M, Roberts S. Mule deer population classification using meteorological, phenological and movement data. Idaho Chapter of The Wildlife Society Annual Meeting. Virtual. Feb 2022. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Variations in American bison resource selection across their former range. 6th Triennial Conference of the American Bison Society. Santa Fe, NM. Oct 2019. Poster.\n Ranglack DH, Ritson R, Bickford N. Variations in American bison resource selection across their former range. Joint Annual Conference of the American Fisheries Society and The Wildlife Society. Reno, NV. Sep 2019. Oral presentation.\n Ritson R. Spatial ecology of bison in the American West. Thesis defense. University of Nebraska-Kearney. Apr 2019. Oral presentation.\n Ritson R. Movement Ecology: Using Animal Locations for Fish and Wildlife Research. Guest Lecture for Quantitative Fish and Wildlife Analysis (BIOL 830P). University of Nebraska-Kearney. Mar 2019. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Seasonal space use patterns of Plains bison (Bison bison) across multiple ecological gradients and management regimes in the American West. Nebraska Chapter of The Wildlife Society Annual Meeting. York, NE. Feb 2019. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Spatial Requirements of Plains Bison (Bison bison) in the American West. The Wildlife Society 25th Annual Conference. Cleveland, OH. Oct 2018. Oral presentation.\n Bickford N, Ritson R, Ranglack DH. Wildlife Behavior Changes During a Solar Eclipse. The Wildlife Society 25th Annual Conference. Cleveland, OH. Oct 2018. Poster.\n Ritson R, Bickford N, Smith L, Bickford S, Bice MR, Ranglack DH. Evaluating the role of CSR and SLO in Ecotourism. Plains Safaris: A conference on tourism and conservation in the Great Plains. Kearney, NE. April 2018. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Does Wildlife Behavior Change in Response to a Solar Eclipse? The Nebraska Academy of Sciences Annual Meeting. Lincoln, NE. April 2018. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Spatial Requirements of Plains Bison (Bison bison) in the American West. Central Mountains and Plains Section of the Wildlife Society Annual Meeting. Kearney, NE. March 2018. Poster."
  },
  {
    "objectID": "about.html#professional-development",
    "href": "about.html#professional-development",
    "title": "Curriculum Vitae",
    "section": "Professional Development",
    "text": "Professional Development\n Animal movement analyses: A to Z, with lots of R. June 2018. British Ecological Society, Movement Ecology Special Interest Group. Vancouver, BC. Speakers: Marie Auger-Methe, Luca Borger, Garrett Street. Workshop"
  },
  {
    "objectID": "about.html#professional-service",
    "href": "about.html#professional-service",
    "title": "Curriculum Vitae",
    "section": "Professional Service",
    "text": "Professional Service\n\nIdaho Chapter of The Wildlife Society\n Co-chair, Sponsorship Committee\n Membership Committee\n Annual Meeting Volunteer\n\n\nNorthwest Section of The Wildlife Society\n Bylaws and Operations Manual Committee\n\n\nInternational Journal of Ecology\n Reviewer"
  },
  {
    "objectID": "about.html#honors-and-awards",
    "href": "about.html#honors-and-awards",
    "title": "Curriculum Vitae",
    "section": "Honors and Awards",
    "text": "Honors and Awards\n Most Outstanding Thesis Award, University of Nebraska-Kearney (2020)\n Shikar-Safari Club Scholarship (2014)\n Four Year Conservation Scholarship, Safari Club International Foundation (2014)\n Eagle Scout, Boy Scouts of America (2009)"
  },
  {
    "objectID": "eclipseproj.html#fa-python-python-function",
    "href": "eclipseproj.html#fa-python-python-function",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": " Python function",
    "text": "Python function\n\n#------------------------- Eclipse Percent Py ------------------------------------------#\n# Sourced from : Graeme Coates, March 18, 2015\n# Accessed: 10/8/21\n# https://www.chromosphere.co.uk/wp-content/blogs.dir/1/files/2015/03/eclipse_percent.py\n# https://www.chromosphere.co.uk/2015/03/18/eclipse-calculations-using-python/\n#---------------------------------------------------------------------------------------#\n# Modified by Rob Ritson, 10/18/2021 into a function for Great American Solar Eclipse\n# Args: Longitude (dd.mmmm), Latitude (dd.mmmm), Elevation (meters)\n# Returns: MaxEclipseTime (GMT), MaxEclipsePercent (obscuration), FirstContactTime, LastContactTime\n# Uses Python module ephem\n#---------------------------------------------------------------------------------------#\nimport ephem\nimport math\nimport numpy as n\nfrom operator import itemgetter\n\ndef check_non_zero(x):\n    return x > 0\n\ndef eclipse_calculator(longitude, latitude, elevation):\n  \"\"\"Calculate Eclipse Conditions\"\"\"\n  timetuple=(2017, 8, 21, 00, 00, 00)\n  gatech=ephem.Observer()\n  gatech.epoch= '2017'\n  gatech.date=timetuple\n  gatech.lon=longitude\n  gatech.lat=latitude\n  gatech.elevation=elevation\n  gatech.compute_pressure()\n  sun, moon = ephem.Sun(gatech), ephem.Moon(gatech)\n  results=[]\n  for x in range(0,86400):\n      gatech.date= (ephem.date(ephem.date(timetuple)+x*ephem.second))\n      sun.compute(gatech)\n      moon.compute(gatech)\n      r_sun=(sun.size/2.0)/3600.0\n      r_moon=(moon.size/2.0)/3600.0\n      s=n.degrees(ephem.separation((sun.az, sun.alt), (moon.az, moon.alt)))\n      try:\n          if s<(r_moon+r_sun):\n              lunedelta=0.25*math.sqrt((r_sun+r_moon+s)*(r_moon+s-r_sun)*(s+r_sun-r_moon)*(r_sun+r_moon-s))\n          else: \n              lunedelta=None\n              percent_eclipse=0\n          if lunedelta: \n              lune_area=2*lunedelta + r_sun*r_sun*(math.acos(((r_moon*r_moon)-(r_sun*r_sun)-(s*s))/(2*r_sun*s))) - r_moon*r_moon*(math.acos(((r_moon*r_moon)+(s*s)-(r_sun*r_sun))/(2*r_moon*s)))\n              percent_eclipse=(1-(lune_area/(math.pi*r_sun*r_sun)))*100 \n          \n          results.append([gatech.date.datetime(),s,sun.size,moon.size,lune_area if lunedelta else 0, percent_eclipse]) \n      except ValueError:\n        pass\n\n  gen=(x for x in results) \n  max_eclipse=max(gen, key=itemgetter(5))\n  MaxEclipseTime = str(max_eclipse[0])\n  MaxEclipsePercent = max_eclipse[5]\n  gen=(x for x in results) \n  try:\n    FirstContactTime = str(next(x for x in gen if check_non_zero(x[5]))[0]) \n  except:\n    FirstContactTime = str('NA') \n  try:\n    LastContactTime = str(next(x for x in gen if x[5]==0)[0]) \n  except: \n    LastContactTime = str('NA')\n  out = [MaxEclipseTime, MaxEclipsePercent, FirstContactTime, LastContactTime]\n  return out\n\n\n------------------------- Eclipse Percent Py ------------------------------------------#\n# Sourced from : Graeme Coates, March 18, 2015\n# Accessed: 10/8/21\n# https://www.chromosphere.co.uk/wp-content/blogs.dir/1/files/2015/03/eclipse_percent.py\n# https://www.chromosphere.co.uk/2015/03/18/eclipse-calculations-using-python/\n#---------------------------------------------------------------------------------------#\n# Modified by Rob Ritson, 1/17/2022 into a function for Great American Solar Eclipse\n# Args: hr (hour), mn (minutes), sc (seconds), Longitude (dd.mmmm), Latitude (dd.mmmm), Elevation (meters)\n# First three arguments are used to create timetuple object for calculating eclipse circumstances\n# Returns: percent eclipse\n# Uses Python module ephem\n#---------------------------------------------------------------------------------------#\nimport ephem\nimport math\nimport numpy as n\n\ndef eclipse_calculator_local(hr, mn, sc, longitude, latitude, elevation):\n  \"\"\"Calculate Eclipse Conditions\"\"\"\n  timetuple=(2017, 8, 21, hr, mn, sc)\n  gatech=ephem.Observer()\n  gatech.epoch= '2017'\n  gatech.date=timetuple\n  gatech.lon=longitude\n  gatech.lat=latitude\n  gatech.elevation=elevation\n  gatech.compute_pressure()\n  sun, moon = ephem.Sun(gatech), ephem.Moon(gatech)\n  sun.compute(gatech)\n  moon.compute(gatech)\n  r_sun=(sun.size/2.0)/3600.0\n  r_moon=(moon.size/2.0)/3600.0\n  s=n.degrees(ephem.separation((sun.az, sun.alt), (moon.az, moon.alt)))\n  if s<(r_moon+r_sun):\n      lunedelta=0.25*math.sqrt((r_sun+r_moon+s)*(r_moon+s-r_sun)*(s+r_sun-r_moon)*(r_sun+r_moon-s))\n  else:\n      lunedelta=None\n      percent_eclipse=0\n  if lunedelta: \n      lune_area=2*lunedelta + r_sun*r_sun*(math.acos(((r_moon*r_moon)-(r_sun*r_sun)-(s*s))/(2*r_sun*s))) - r_moon*r_moon*(math.acos(((r_moon*r_moon)+(s*s)-(r_sun*r_sun))/(2*r_moon*s)))\n      percent_eclipse=(1-(lune_area/(math.pi*r_sun*r_sun)))*100 \n\n  return percent_eclipse"
  },
  {
    "objectID": "eclipseproj.html#fa-scroll-python-function",
    "href": "eclipseproj.html#fa-scroll-python-function",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": " Python function",
    "text": "Python function\nI created a function in Python inspired by a script I found which calculated the start time for a particular eclipse (March 2015) at one particular location. I expanded it to return the start and end times of the eclipse, the time of the maximum eclipse, and the maximum obscuration percentage (how much of the sun was blocked at the eclipse maximum).\n\n#------------------------- Eclipse Percent Py ------------------------------------------#\n# Sourced from : Graeme Coates, March 18, 2015\n# Accessed: 10/8/21\n# https://www.chromosphere.co.uk/wp-content/blogs.dir/1/files/2015/03/eclipse_percent.py\n# https://www.chromosphere.co.uk/2015/03/18/eclipse-calculations-using-python/\n#---------------------------------------------------------------------------------------#\n# Modified by Rob Ritson, 10/18/2021 into a function for Great American Solar Eclipse\n# Args: Longitude (dd.mmmm), Latitude (dd.mmmm), Elevation (meters)\n# Returns: MaxEclipseTime (GMT), MaxEclipsePercent (obscuration), FirstContactTime, LastContactTime\n# Uses Python module ephem\n#---------------------------------------------------------------------------------------#\nimport ephem\nimport math\nimport numpy as n\nfrom operator import itemgetter\n\ndef check_non_zero(x):\n    return x > 0\n\ndef eclipse_calculator(longitude, latitude, elevation):\n  \"\"\"Calculate Eclipse Conditions\"\"\"\n  timetuple=(2017, 8, 21, 00, 00, 00)\n  gatech=ephem.Observer()\n  gatech.epoch= '2017'\n  gatech.date=timetuple\n  gatech.lon=longitude\n  gatech.lat=latitude\n  gatech.elevation=elevation\n  gatech.compute_pressure()\n  sun, moon = ephem.Sun(gatech), ephem.Moon(gatech)\n  results=[]\n  for x in range(0,86400):\n      gatech.date= (ephem.date(ephem.date(timetuple)+x*ephem.second))\n      sun.compute(gatech)\n      moon.compute(gatech)\n      r_sun=(sun.size/2.0)/3600.0\n      r_moon=(moon.size/2.0)/3600.0\n      s=n.degrees(ephem.separation((sun.az, sun.alt), (moon.az, moon.alt)))\n      try:\n          if s<(r_moon+r_sun):\n              lunedelta=0.25*math.sqrt((r_sun+r_moon+s)*(r_moon+s-r_sun)*(s+r_sun-r_moon)*(r_sun+r_moon-s))\n          else: \n              lunedelta=None\n              percent_eclipse=0\n          if lunedelta: \n              lune_area=2*lunedelta + r_sun*r_sun*(math.acos(((r_moon*r_moon)-(r_sun*r_sun)-(s*s))/(2*r_sun*s))) - r_moon*r_moon*(math.acos(((r_moon*r_moon)+(s*s)-(r_sun*r_sun))/(2*r_moon*s)))\n              percent_eclipse=(1-(lune_area/(math.pi*r_sun*r_sun)))*100 \n          \n          results.append([gatech.date.datetime(),s,sun.size,moon.size,lune_area if lunedelta else 0, percent_eclipse]) \n      except ValueError:\n        pass\n\n  gen=(x for x in results) \n  max_eclipse=max(gen, key=itemgetter(5))\n  MaxEclipseTime = str(max_eclipse[0])\n  MaxEclipsePercent = max_eclipse[5]\n  gen=(x for x in results) \n  try:\n    FirstContactTime = str(next(x for x in gen if check_non_zero(x[5]))[0]) \n  except:\n    FirstContactTime = str('NA') \n  try:\n    LastContactTime = str(next(x for x in gen if x[5]==0)[0]) \n  except: \n    LastContactTime = str('NA')\n  out = [MaxEclipseTime, MaxEclipsePercent, FirstContactTime, LastContactTime]\n  return out\n\nIn the next step, I could subset the locations of individuals which actually experienced the eclipse, based on whether the timestamp of the particular location was within the start and end time of the eclipse at that location, and calculate how much of the sun was obscured at that particular instance. This will be used in further analyses in R examining behavioral change points and segementation to examine whether changes in behavior correspond with or relate to eclipse conditions.\n\n------------------------- Eclipse Percent Py ------------------------------------------#\n# Sourced from : Graeme Coates, March 18, 2015\n# Accessed: 10/8/21\n# https://www.chromosphere.co.uk/wp-content/blogs.dir/1/files/2015/03/eclipse_percent.py\n# https://www.chromosphere.co.uk/2015/03/18/eclipse-calculations-using-python/\n#---------------------------------------------------------------------------------------#\n# Modified by Rob Ritson, 1/17/2022 into a function for Great American Solar Eclipse\n# Args: hr (hour), mn (minutes), sc (seconds), Longitude (dd.mmmm), Latitude (dd.mmmm), Elevation (meters)\n# First three arguments are used to create timetuple object for calculating eclipse circumstances\n# Returns: percent eclipse\n# Uses Python module ephem\n#---------------------------------------------------------------------------------------#\nimport ephem\nimport math\nimport numpy as n\n\ndef eclipse_calculator_local(hr, mn, sc, longitude, latitude, elevation):\n  \"\"\"Calculate Eclipse Conditions\"\"\"\n  timetuple=(2017, 8, 21, hr, mn, sc)\n  gatech=ephem.Observer()\n  gatech.epoch= '2017'\n  gatech.date=timetuple\n  gatech.lon=longitude\n  gatech.lat=latitude\n  gatech.elevation=elevation\n  gatech.compute_pressure()\n  sun, moon = ephem.Sun(gatech), ephem.Moon(gatech)\n  sun.compute(gatech)\n  moon.compute(gatech)\n  r_sun=(sun.size/2.0)/3600.0\n  r_moon=(moon.size/2.0)/3600.0\n  s=n.degrees(ephem.separation((sun.az, sun.alt), (moon.az, moon.alt)))\n  if s<(r_moon+r_sun):\n      lunedelta=0.25*math.sqrt((r_sun+r_moon+s)*(r_moon+s-r_sun)*(s+r_sun-r_moon)*(r_sun+r_moon-s))\n  else:\n      lunedelta=None\n      percent_eclipse=0\n  if lunedelta: \n      lune_area=2*lunedelta + r_sun*r_sun*(math.acos(((r_moon*r_moon)-(r_sun*r_sun)-(s*s))/(2*r_sun*s))) - r_moon*r_moon*(math.acos(((r_moon*r_moon)+(s*s)-(r_sun*r_sun))/(2*r_moon*s)))\n      percent_eclipse=(1-(lune_area/(math.pi*r_sun*r_sun)))*100 \n\n  return percent_eclipse"
  },
  {
    "objectID": "eclipseproj.html#fa-code-r-code",
    "href": "eclipseproj.html#fa-code-r-code",
    "title": "Solar Eclipse and Wildlife Movements",
    "section": " R Code",
    "text": "R Code\nThis R script calls the the above Python script using reticulate, executes these in parallel using the furrr package, then saves the outputs for further analysis.\n\n## Calculate Local Circumstances of Great American Solar Eclipse ####\n# Load required packages\nlapply(c(\"data.table\",\"reticulate\",\"furrr\",\"readr\",\"progressr\",\"future\"),require,character.only=T)\n\n# Source Python Script (EclipseCalculator.py)\nreticulate::source_python(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/EclipseCalculator.py\")\n\n# Load data\ndf <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASE_elevation.csv\")\nstr(df)\ndf$Latitude <- as.character(df$Latitude)\ndf$Longitude <- as.character(df$Longitude)\n\n## Calculate Local Circumstances of Eclipse\n#todo <- df\ntodo <- subset(df,!(df$ID %in% out_df$ID))\nout_df <- NULL\nfor(i in 1:length(unique(todo$ID))){\n  elev_df <- subset(todo, todo$ID == unique(todo$ID)[i])\n  arg_list <- elev_df[,c(\"Longitude\",\"Latitude\",\"elevation\")]\n  colnames(arg_list) <- NULL\n  future::plan(multicore,workers = availableCores()-1) #parallel processing\n  skip <- F\n  tryCatch({\n    progressr::with_progress({\n      p <- progressr::progressor(steps = nrow(arg_list))\n      final <- furrr::future_pmap(arg_list, function(long, lat, elev){ \n        p() #add progress bar\n        e <- eclipse_calculator(long, lat, elev)\n      })\n    })\n  },error = function(e){skip <<- T})\n  if(skip){next}\n  \n  final_df <- data.frame(matrix(unlist(final), nrow = length(final), byrow=TRUE))\n  colnames(final_df) <- c(\"MaxEclipseTime\",\"MaxObscuration\",\"FirstContact\",\"LastContact\")\n  out <- cbind(elev_df,final_df)\n  \n  out[[\"MaxEclipseTime\"]] <- as.POSIXct(out[[\"MaxEclipseTime\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  out[[\"FirstContact\"]] <- as.POSIXct(out[[\"FirstContact\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  out[[\"LastContact\"]] <- as.POSIXct(out[[\"LastContact\"]],format = \"%Y-%m-%d %H:%M:%OS\",tz=\"GMT\")\n  \n  out_df <- rbind(out_df, out)\n  \n  print(paste(\"Iteration\",i,\"of\",length(unique(todo$ID)),\"Completed\"))\n}\nreadr::write_csv(out_df,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\nnas <- subset(out_df,is.na(out_df$FirstContact)) #Indiv 154 is only NAs (brown pelican)\nout_df<- subset(out_df,!is.na(out_df$FirstContact))\nany(is.na(out_df$FirstContact))\nreadr::write_csv(out_df,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\") #Clean file\n#####\n## Calculate Eclipse Duration and Identify Eclipse Locations ####\nrequire(lubridate)\neclipse <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\neclipse$interval <- lubridate::interval(eclipse$FirstContact, eclipse$LastContact)\neclipse$duration_sec <- as.numeric(lubridate::as.duration(eclipse$interval))\neclipse$active_eclipse <- ifelse(eclipse$Timestamp %within% eclipse$interval,'Yes','No')\nreadr::write_csv(eclipse,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\n####\n## Load packages\nlapply(c(\"data.table\",\"reticulate\",\"furrr\",\"readr\",\"progressr\",\"future\"),require,character.only=T)\n\n## Load Data\neclipse <- data.table::fread(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions.csv\")\n\n# Subset Eclipse Locations\nactive <- subset(eclipse,eclipse$active_eclipse=='Yes')\nactive$hour <- lubridate::hour(active$Timestamp)\nactive$minute <- lubridate::minute(active$Timestamp)\nactive$second <- lubridate::second(active$Timestamp)\n\n# Calculate percent eclipse for each location recorded during the eclipse #\nreticulate::source_python(\"C:/Users/r2j2r/Documents/Research Projects/eclipse/EclipseCalculatorLocalConditions.py\")\n\n## Calculate Local Circumstances of Eclipse Conditions\narg_list <- active[,c(\"hour\",\"minute\",\"second\",\"Longitude\",\"Latitude\",\"elevation\")]\ncolnames(arg_list) <- NULL\nfuture::plan(multicore,workers = availableCores()-1) #parallel processing\nprogressr::with_progress({\n  p <- progressr::progressor(steps = nrow(arg_list))\n  final <- furrr::future_pmap(arg_list, function(hr, mn, sc, long, lat, elev){ \n        p() #add progress bar\n        e <- eclipse_calculator_local(hr, mn, sc, long, lat, elev)\n      })\n    })\nfinal_df <- data.frame(matrix(unlist(final), nrow = length(final), byrow=TRUE))\ncolnames(final_df) <- \"Observed_Obscuration\"\nout <- cbind(active,final_df)\nreadr::write_csv(out,\"C:/Users/r2j2r/Documents/Research Projects/eclipse/GASELocalConditions_Active.csv\")\n#####"
  },
  {
    "objectID": "about.html#fa-certificate-certifcations",
    "href": "about.html#fa-certificate-certifcations",
    "title": "Curriculum Vitae",
    "section": " Certifcations",
    "text": "Certifcations\nAssociate Wildlife Biologist®, The Wildlife Society"
  },
  {
    "objectID": "about.html#fa-building-experience",
    "href": "about.html#fa-building-experience",
    "title": "Curriculum Vitae",
    "section": " Experience",
    "text": "Experience\n Associate Research Scientist, University of Wyoming and Idaho Department of Fish and Game, February 2022 - present.\n Research Associate - Vegetation Modeling, Wildlife Management Institute and Idaho Department of Fish and Game, March 2021 - January 2022.\n Wildlife Technician, Idaho Department of Fish and Game, November 2019 - June 2020; November 2020 - March 2021.\n Habitat Biologist Technician, Wyoming Game and Fish Department, May - October 2019.\n Biological Science Technician (GS-05), USFS Rocky Mountain Research Station, June - September 2016; June - August 2017.\n Wild Turkey Technician, West Virginia University, April - June 2017.\n Lead Wildlife Research Technician, Idaho Department of Fish and Game, March - May 2016.\n Research Associate, Montana State University, June - October 2015.\n Sage-grouse Technician, University of Wyoming, March - June 2015.\n Snowshoe Hare Technician, Pennsylvania Cooperative Fish and Wildlife Research Unit, January - March 2015.\n Biological Science Aid (GS-03), Wind Cave National Park, June - August 2014."
  },
  {
    "objectID": "about.html#fa-diagram-project-research-projects",
    "href": "about.html#fa-diagram-project-research-projects",
    "title": "Curriculum Vitae",
    "section": "Research Projects",
    "text": "Research Projects\n Mule deer seasonal range analysis. February 2022 – present. Collaborators: Scott Bergen, Matt Mumma, Shane Roberts, Mark Hurley. Idaho Department of Fish and Game. Pocatello, ID.\n Fine-scale vegetation model. March 2021 – present. Collaborators: Erin Roche, Sara Thompson, Scott Bergen, Matt Mumma, Shane Roberts, Mark Hurley. Idaho Department of Fish and Game. Boise, ID.\n Thesis: Spatial Ecology of Bison in the American West. August 2017 - May 2019 Collaborators: Nate Bickford, Melissa Wuellner, Angela Hollman, and Dustin H. Ranglack. University of Nebraska-Kearney. Kearney, NE.\n Effects of 2017 solar eclipse on animal behavior. August 2017 - May 2019. Collaborators: Nate Bickford, Melissa Wuellner, Dustin H. Ranglack, et al. University of Nebraska-Kearney. Kearney, NE.\n Ecological Correlates of Game Bird Distribution in Northern Tanzania. February – May 2013. Advisor: John Kioko. The School for Field Studies Center for Wildlife Management Studies. Karatu, TZ."
  },
  {
    "objectID": "about.html#fa-file-pen-publications",
    "href": "about.html#fa-file-pen-publications",
    "title": "Curriculum Vitae",
    "section": "Publications",
    "text": "Publications\n Ritson R, Ranglack DH, Bickford N. 2019. Comparing Social Media Observations of Animals During a Solar Eclipse to Published Research. Animals 9(59):1-12. doi:10.3390/ani9020059\n\n Ritson R, Barg A, Shannon J, Hershey K, Shoenecker KA, Beard D, Kunkel K, Kinka D, Ranglack DH. Seasonal space use patterns of American bison across multiple management regimes. Prepared for Journal of Wildlife Management.\n\n\n Ritson R, Bickford N, Wuellner M, Fuda RK, Miller TA, Boulanger JR, Beasley JC, Brzorad JN, Fisher R, Orben RA, Barber M, Kays R, Watson JL, Ranglack DH. Obscured Sun, Obscure Behavior: Exploring the Effects of a Solar Eclipse on Animal Movement. Prepared for Movement Ecology."
  },
  {
    "objectID": "about.html#fa-chalkboard-user-presentations-and-posters",
    "href": "about.html#fa-chalkboard-user-presentations-and-posters",
    "title": "Curriculum Vitae",
    "section": " Presentations and Posters",
    "text": "Presentations and Posters\n Ritson R, Mumma M, Roche E, Bergen S, Roberts S, Hurley M. Towards a fine scale vegetation model. Idaho Chapter of The Wildlife Society Annual Meeting. Virtual. Feb 2022. Oral presentation.\n Bergen S, Ritson R, Hurley M, Roberts S. Mule deer population classification using meteorological, phenological and movement data. Idaho Chapter of The Wildlife Society Annual Meeting. Virtual. Feb 2022. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Variations in American bison resource selection across their former range. 6th Triennial Conference of the American Bison Society. Santa Fe, NM. Oct 2019. Poster.\n Ranglack DH, Ritson R, Bickford N. Variations in American bison resource selection across their former range. Joint Annual Conference of the American Fisheries Society and The Wildlife Society. Reno, NV. Sep 2019. Oral presentation.\n Ritson R. Spatial ecology of bison in the American West. Thesis defense. University of Nebraska-Kearney. Apr 2019. Oral presentation.\n Ritson R. Movement Ecology: Using Animal Locations for Fish and Wildlife Research. Guest Lecture for Quantitative Fish and Wildlife Analysis (BIOL 830P). University of Nebraska-Kearney. Mar 2019. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Seasonal space use patterns of Plains bison (Bison bison) across multiple ecological gradients and management regimes in the American West. Nebraska Chapter of The Wildlife Society Annual Meeting. York, NE. Feb 2019. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Spatial Requirements of Plains Bison (Bison bison) in the American West. The Wildlife Society 25th Annual Conference. Cleveland, OH. Oct 2018. Oral presentation.\n Bickford N, Ritson R, Ranglack DH. Wildlife Behavior Changes During a Solar Eclipse. The Wildlife Society 25th Annual Conference. Cleveland, OH. Oct 2018. Poster.\n Ritson R, Bickford N, Smith L, Bickford S, Bice MR, Ranglack DH. Evaluating the role of CSR and SLO in Ecotourism. Plains Safaris: A conference on tourism and conservation in the Great Plains. Kearney, NE. April 2018. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Does Wildlife Behavior Change in Response to a Solar Eclipse? The Nebraska Academy of Sciences Annual Meeting. Lincoln, NE. April 2018. Oral presentation.\n Ritson R, Bickford N, Ranglack DH. Spatial Requirements of Plains Bison (Bison bison) in the American West. Central Mountains and Plains Section of the Wildlife Society Annual Meeting. Kearney, NE. March 2018. Poster."
  },
  {
    "objectID": "about.html#fa-network-wired-professional-development",
    "href": "about.html#fa-network-wired-professional-development",
    "title": "Curriculum Vitae",
    "section": " Professional Development",
    "text": "Professional Development\n Animal movement analyses: A to Z, with lots of R. June 2018. British Ecological Society, Movement Ecology Special Interest Group. Vancouver, BC. Speakers: Marie Auger-Methe, Luca Borger, Garrett Street. Workshop"
  },
  {
    "objectID": "about.html#fa-people-group-professional-service",
    "href": "about.html#fa-people-group-professional-service",
    "title": "Curriculum Vitae",
    "section": " Professional Service",
    "text": "Professional Service\n\nIdaho Chapter of The Wildlife Society\n Co-chair, Sponsorship Committee\n Membership Committee\n Annual Meeting Volunteer\n\n\nNorthwest Section of The Wildlife Society\n Bylaws and Operations Manual Committee\n\n\nInternational Journal of Ecology\n Reviewer"
  },
  {
    "objectID": "about.html#fa-medal-honors-and-awards",
    "href": "about.html#fa-medal-honors-and-awards",
    "title": "Curriculum Vitae",
    "section": " Honors and Awards",
    "text": "Honors and Awards\n Most Outstanding Thesis Award, University of Nebraska-Kearney (2020)\n Shikar-Safari Club Scholarship (2014)\n Four Year Conservation Scholarship, Safari Club International Foundation (2014)\n Eagle Scout, Boy Scouts of America (2009)"
  },
  {
    "objectID": "seasonalranges.html#seasonal-range-analysis-dashboard",
    "href": "seasonalranges.html#seasonal-range-analysis-dashboard",
    "title": "Ungulate Seasonal Ranges",
    "section": "Seasonal Range Analysis Dashboard",
    "text": "Seasonal Range Analysis Dashboard\n\n\nAverage Winter Range Map\n\n\n\nAnnual Winter Ranges"
  },
  {
    "objectID": "seasonalranges.html#vegetation-classification-covariates",
    "href": "seasonalranges.html#vegetation-classification-covariates",
    "title": "Ungulate Seasonal Ranges",
    "section": "Vegetation Classification Covariates",
    "text": "Vegetation Classification Covariates\n\nPython Function\n\n# --------------------------------------------------------\n# Calculate Hurley Vegetation Focal Statistics\n# Author: Robert Ritson, Associate Research Scientist (UW)\n# Last Updated: 5/10/2022\n# Description: Calculate square meters of Hurley\n#   vegetation classes (binary rasters derrived from LANDFIRE)\n#   given a mean daily movement distance (from an ungulate population),\n#   clipped by a population DAU boundary\n# --------------------------------------------------------\n#Import modules\nimport arcpy\nfrom arcpy.sa import *\nimport datetime\nimport csv\nimport os\narcpy.CheckOutExtension(\"Spatial\")\n#Define function\ndef hveg_focal(path_to_dau, mdm_ci95, path_to_hveg, dau_hveg_folder, scratch = \"C:\\\\Users\\\\rritson\\\\Documents\\\\ArcGIS\\\\scratch\\\\\"):\n    try:\n        print 'begin script on '+datetime.datetime.now().date().isoformat()+' at '+datetime.datetime.now().time().isoformat()[0:8]\n\n        # Set path to folders and workspace\n        dauws = path_to_dau\n        rastws = path_to_hveg\n        outws = dau_hveg_folder\n        neighborhood = arcpy.sa.NbrCircle(mdm_ci95,\"MAP\")\n        arcpy.env.overwriteOuptput = False\n        arcpy.env.workspace = scratch\n\n        # Buffer Selected DAU by provided mean daily movement\n        print 'buffering DAU shape by mean daily movement input (meters)'\n        arcpy.Buffer_analysis(dauws,scratch+'\\\\DAU_Buffer.shp', mdm_ci95,\"FULL\",\"ROUND\",\"NONE\",\"\",\"PLANAR\")\n        \n        # List Hurley Vegetation Rasters\n        arcpy.env.workspace = rastws\n        try:\n            print 'listing Hveg rasters'\n            hveg_list = [hveg for hveg in arcpy.ListRasters()]\n        except:  print arcpy.GetMessages(2)\n\n        # Clip Hurley Vegetation Raster to buffered DAU and calculate focal statistics\n        arcpy.env.workspace = scratch\n        for hveg in hveg_list:\n            print 'loading raster '+hveg\n            arcpy.MakeRasterLayer_management(rastws+'/'+hveg,'temp_rast.tif',\"\",scratch+'/DAU_Buffer.shp',\"\") #load raster and clip to buffered DAU extent\n\n            print 'calculating focal statistics'\n            arcpy.CheckOutExtension(\"Spatial\")\n            fstat = FocalStatistics('temp_rast.tif',  neighborhood, \"SUM\", \"DATA\") #Focal sum of binaries by mean daily movement distance\n            \n            print 'converting to square meters'\n            outrast = fstat * (30^2) #multiply focal sum by cell dimensions (convert to square meters)\n            outrast.save(outws+hveg) #save output\n\n            print hveg+' raster saved to '+outws+' at '+datetime.datetime.now().time().isoformat()[0:8]\n\n        print 'Finished: Completed Hurley vegetation density rasters for '+dauws+' located in '+outws\n        print 'script completed on '+datetime.datetime.now().date().isoformat()+' at '+datetime.datetime.now().time().isoformat()[0:8]\n\n    except:  print arcpy.GetMessages(2)\narcpy.CheckInExtension(\"Spatial\")\n# # # # # END OF FUNCTION # # # # # # #\n\n\n\nR code\n\n## Hurley Vegetation Density Raster Calculations ##\n### Loop through remaining DAUs (~10min per DAU) ###\n#Load package\nrequire(dplyr)\n\n#devtools::install_github(\"rstudio/reticulate\")\n#Sys.setenv(RETICULATE_PYTHON = \"C:\\\\Python27\\\\ArcGIS10.8\\\\\\\\pythonw.exe\")\nSys.setenv(RETICULATE_PYTHON = 'C:/Users/rritson/AppData/Local/Programs/ArcGIS/Pro/bin/Python/envs/arcgispro-py3/python.exe')\nrequire(reticulate)\n\n\n#DAU List\ndau_list <- sf::st_read('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/DAU_BBox_10kbuff.shp') %>%\n  as.data.frame(.) %>%\n  dplyr::select(NAME) %>%\n  #dplyr::filter(NAME == \"Island Park\")\n  dplyr::filter(NAME %in% c(\"Bannock\",\"Caribou\",\"Mountain Valley\",\"Portneuf\",\"Weiser-McCall\"))\n  #dplyr::filter(!(NAME %in% c(\"Bitterroot\",\"Panhandle\",\"Lower Salmon\",\"Snake River\",\"Smokey-Boise\",\"Island Park\")))\n\n#DAU shape (all)\ndau_shp <- sf::st_read('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/DAU_BBox_10kbuff.shp') %>%\n  #dplyr::select(-GlobalID,-Shape_Leng,-Shape_Area) %>% \n  sfheaders::sf_remove_holes(.)\n\n#Movement Data\ndat <- readRDS(\"C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/Winter_RSF/MD_Winter_Locs_1pd.rds\") %>% as.data.frame(.)\n\n# Check R Session Info\nif(sessionInfo()$R.version$arch != \"i386\"){\n  print(\"STOP: Must run R in 32-bit Architecture to source 'arcpy'\")\n  }\nif(paste0(sessionInfo()$R.version$major,\".\",sessionInfo()$R.version$minor) > \"4.0.4\"){\n  print(\"STOP: Must run R in version prior or equal to 4.0.4 to source 'arcpy'\") \n  # reticulate does not want to work with R version 4.1.0...\n  }\n\n# Initiate Python before beginning loop\n#reticulate::use_python(\"C:\\\\Python27\\\\ArcGIS10.8\\\\\\\\pythonw.exe\", required = T)\nreticulate::use_python('C:/Users/rritson/AppData/Local/Programs/ArcGIS/Pro/bin/Python/envs/arcgispro-py3/python.exe', required = T)\nreticulate::py_config()\nreticulate::source_python(\"C:/Users/rritson/Documents/Python Scripts/hveg_focal_func.py\")\n#reticulate::source_python(\"C:/Users/rritson/Documents/Python Scripts/hveg_focal_func_sing.py\") #for dealing with a single raster (must change file paths below if so)\n\n# Loop through DAUs\nfor (i in 1:nrow(dau_list)){\n  \n  # Select DAU\n  print(paste(\"Beginning DAU:\",dau_list[i,],\"(\",nrow(dau_list)-i,\"remaining)...\"))\n  dau_sel <- dau_list[i,] \n  \n  # Create folder for outputs\n  #print(\"Creating output folder...\")\n  #dir.create(\"F:/Seasonal_range_covars/mdmci95_2buff\") \n  #dir.create(paste0(\"F:/Seasonal_range_covars/mdmci95_2buff/\",dau_sel)) \n  \n  # Write DAU shapefile\n  #print(\"Writing shapefile...\")\n  #dau <- dau_shp %>% dplyr::filter(NAME == dau_sel)\n  #sf::write_sf(dau,paste0('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/SeasonalRanges/',dau_sel,\".shp\"),append=F)\n  \n  # Get Mean Daily Movements for DAU\n  print(\"Accessing mean daily movement (95% CI, in meters)...\")\n  mdm_ci95 <- dat %>% dplyr::filter(DAU == dau_sel) %>% dplyr::select(MDM_CI95_avg) %>% dplyr::slice(1)\n  mdm_ci95 <- mdm_ci95[[1]]\n  mdm_ci95_2 <- mdm_ci95 / 2\n  \n  # Calculate Hurley vegetation density raster for DAU: Mean Daily Movement\n  print(\"Reticulating HVeg Density Raster Calculation (Mean Daily Movement)...\")\n  hveg_focal(path_to_dau = paste0('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/SeasonalRanges/',dau_sel,\".shp\"),\n             mdm_ci95 = mdm_ci95, #mean daily movement\n             path_to_hveg = \"F:\\\\Seasonal_range_covars\\\\hveg\",\n             dau_hveg_folder = paste0(\"F:/Seasonal_range_covars/mdmci95_buff/\",dau_sel,\"/\"), #CHANGE THIS!!! (to match output folder)\n             scratch = \"C:/Users/rritson/Documents/ArcGIS/scratch\")\n  \n  #Delete temp files\n  lapply(list.files(\"C:/Users/rritson/Documents/ArcGIS/scratch\",full.names = T),file.remove)\n  gc()\n  \n  # Calculate Hurley vegetation density raster for DAU: One-half Mean Daily Movement\n  print(\"Reticulating HVeg Density Raster Calculation (One-Half Mean Daily Movement)...\")\n  hveg_focal(path_to_dau = paste0('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/SeasonalRanges/',dau_sel,\".shp\"),\n             mdm_ci95 = mdm_ci95_2, #one-half mean daily movement\n             path_to_hveg = \"F:\\\\Seasonal_range_covars\\\\hveg\",\n             dau_hveg_folder = paste0(\"F:/Seasonal_range_covars/mdmci95_2buff/\",dau_sel,\"/\"), #CHANGE THIS!!! (to match output folder)\n             scratch = \"C:/Users/rritson/Documents/ArcGIS/scratch\")\n  \n  #Delete temp files\n  lapply(list.files(\"C:/Users/rritson/Documents/ArcGIS/scratch\",full.names = T),file.remove)\n  gc()\n}"
  },
  {
    "objectID": "fsvmproj.html#fsvm-r-package",
    "href": "fsvmproj.html#fsvm-r-package",
    "title": "Fine Scale Vegetation Model",
    "section": "fsvm R package",
    "text": "fsvm R package\n\n\n\nIn order to assist in IDFG’s Fine Scale Vegetation Model, I wrote an R package to streamline the workflow and ensure reproducability. Among the package’s functions are helpers for uploading and formatting new survey data, rectify taxonomic names to ensure standardization, as well as functions for training machine learning models and producing prediction maps.\n\n\n\n \n\nVignettes\n     \n\n\nPredictions"
  },
  {
    "objectID": "fsvmproj.html#field-lpi-generation",
    "href": "fsvmproj.html#field-lpi-generation",
    "title": "Fine Scale Vegetation Model",
    "section": "Field LPI Generation",
    "text": "Field LPI Generation\nCovarites for this model are stored in ~44 million polygons which were created using eCognition. In order to more effectively sample these irregularly shaped polygons, I wrote code which randomly selects one of the eCognition polygons (i.e. ‘quadpolygons’), then attempts to fit a 100 meter line within it so the standard line point intercept (LPI) survey protocol effectively samples it. The code works by first randomly generating a starting location within the polygon, randomly selecting a direction, then draws a 50 meter survey line. If that line intersects the border of the polygon, then the process is repeated until a 100 meter line is drawn which does not intersect the polygon or after 100 failed attempts.\nThis process can then be repeated with additional randomly selected polygons until the desired number of survey options is achieved. This gives field personnel fixed options when conducting field vegetation surveys and ensures the surveys they conduct effectively sample the polygon instead of straddling multiple polygons. This also saves the analyst time by automating the generation of possible surveys which meet the desired criteria.\n\nR Functions\n\nbuff_sample <- function(poly,buff,r=10){\n  p <- sf::st_cast(poly,\"MULTILINESTRING\")\n  n <- 0\n  repeat{\n    n <- n + 1\n    rand_start <- sf::st_sample(poly,1)\n    d <- as.numeric(sf::st_distance(rand_start,p))\n    if(d >= buff | n == r){\n      break\n    }\n  }\n  if(n == r & d < buff){\n    return(NA)\n    }else{\n      return(rand_start)\n  }\n}\n\nst_fitLPI <- function(poly, r=200, buff=5, len=50){\n  poly <- sf::st_transform(poly,crs = \"WGS84\")\n  p <- sf::st_cast(poly,\"MULTILINESTRING\")\n  permute_dirs  <- sample(1:360) \n  rs <- buff_sample(poly,buff,r) \n  if(is.na(rs)){\n    return(NULL)\n  }else{rs <- sf::st_transform(rs,crs = \"WGS84\")}\n  for(j in 1:length(permute_dirs)){\n    dp <- geosphere::destPoint(rs[[1]][], b = permute_dirs[j], d = len) %>%\n      sf::st_point(.) %>% sf::st_sfc(.) %>% sf::`st_crs<-`(\"WGS84\")\n    lpi <- sf::st_cast(c(rs[[1]],dp[[1]]),\"LINESTRING\")\n    int <- sf::st_intersects(lpi,p, sparse = F)\n    if(isFALSE(int)){break}\n  }\n  if(isTRUE(int)){\n    return(NULL)\n  }\n  df <- data.frame(QPID = poly$QuadPolyID,\n                   Shape = sf::st_geometry(lpi)) %>%\n    sf::st_sf(.) %>% sf::`st_crs<-`(\"WGS84\")\n  return(df)\n}\n\n\n\nR Code\n\nrequire(dplyr)\nusgs24k <- sf::st_read(\"C:/Users/rritson/Documents/GitHub/USGS24k/USGS24k.shp\")\nr1quads <- sf::st_read(\"C:/Users/rritson/Documents/GitHub/Extents/IDFG Regions.shp\") %>% \n  dplyr::filter(ID == \"1\") %>%\n  sf::st_intersects(.,usgs24k) %>% as.data.frame(.) %>%\n  dplyr::mutate(Quad = usgs24k$UID[col.id]) %>%\n  dplyr::select(-row.id,-col.id)\nquads <- dir(\"A:/Fine scale vegetation analysis/dbases_4modeling/24kpolys\",pattern=\".rds\",full.names = T)\nflist <- quads[which(basename(quads) %in% paste0(\"q\",r1quads$Quad,\".rds\"))]\nwater <- sf::st_read(\"C:/Users/rritson/Documents/GitHub/extents/ID_Lakes.shp\")\nfgrid <- readRDS(\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/Faragut_QuadPoly_Selections.rds\")\n\n## Loop through list\nout <- sf::st_sfc() \nsf::st_crs(out) <- sf::st_crs(usgs24k)\nfor(i in 1:length(flist)){\n  print(paste(i,\"of\",length(flist)))\n  \n  # Read 24k quad w/ in R1 grid\n  temp <- readRDS(flist[i]) %>% dplyr::mutate(QuadPolyID = paste0(quad,\"_\",id))\n  wint <- sf::st_intersection(temp,water)\n  temp <- temp[which(!(temp$id %in% wint$id)),] #Filter out open water quad polygons\n  temp <- temp[which(!(temp$QuadPolyID %in% fgrid$QuadPolyID)),]\n  \n  # Randomly select 50 quadpolys from each Faragut quad\n  int <- temp %>%\n    dplyr::filter(QuadPolyID %in% QuadPolyID[sample(1:nrow(.),50)]) %>% \n    dplyr::select(QuadPolyID,Shape)\n  \n  # Collect output\n  out <- rbind(out,int)\n}\nnrow(out) == length(unique(out$QuadPolyID))\nsaveRDS(out,\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Selections.rds\")\n\n# Draw LPIs a priori\nrgrid <- readRDS(\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Selections.rds\")\nsource(\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/fitLPI_inpoly_function2.R\")\nrequire(dplyr)\n\n##Try Drawing One 50m line\n#reps <- 50 #number of repeats\nlen <- 50 #LPI line length (in meters)\nbuff <- 5 #Buffer distance from polygon edge\nout <- sf::st_sfc() \nsf::st_crs(out) <- sf::st_crs(\"WGS84\")\nfor (i in 301:600) {\n  print(paste(\"Beginning\",i,\"of\",nrow(rgrid)))\n  pb = txtProgressBar(min = 0, max = 360, initial = 0) \n  poly <- rgrid[i,] %>% sf::st_transform(.,crs = \"WGS84\")\n  p <- sf::st_cast(poly,\"MULTILINESTRING\")\n  permute_dirs  <- sample(1:360) \n  rs <- buff_sample(poly,buff,r=200) \n  if(is.na(rs)){next}else{rs <- sf::st_transform(rs,crs = \"WGS84\")}\n  for(j in 1:length(permute_dirs)){\n    setTxtProgressBar(pb,360)\n    dp <- geosphere::destPoint(rs[[1]][], b = permute_dirs[j], d = len) %>%\n      sf::st_point(.) %>% sf::st_sfc(.) %>% sf::`st_crs<-`(\"WGS84\")\n    lpi <- sf::st_cast(c(rs[[1]],dp[[1]]),\"LINESTRING\")\n    int <- sf::st_intersects(lpi,p, sparse = F)\n    if(isFALSE(int) | j == length(permute_dirs)){\n      break\n    }\n  }\n  close(pb)\n  if(isTRUE(int) & j == length(permute_dirs)){\n    print(\"Failed.\")\n    next\n  }\n  print(\"Success!\")\n  df <- data.frame(QPID = poly$QuadPolyID,\n                   Shape = sf::st_geometry(lpi)) %>%\n    sf::st_sf(.) %>% sf::`st_crs<-`(\"WGS84\")\n  out <- rbind(out,df)\n  gc()\n}\nsaveRDS(out,\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Lines_1.rds\")\nsf::st_write(out,\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Lines.shp\")"
  },
  {
    "objectID": "fsvmproj.html#fa-computer-code-fsvm-r-package",
    "href": "fsvmproj.html#fa-computer-code-fsvm-r-package",
    "title": "Fine Scale Vegetation Model",
    "section": " fsvm R package",
    "text": "fsvm R package\n\n\n\nIn order to assist in IDFG’s Fine Scale Vegetation Model, I wrote an R package to streamline the workflow and ensure reproducability. Among the package’s functions are helpers for uploading and formatting new survey data, rectify taxonomic names to ensure standardization, as well as functions for training machine learning models and producing prediction maps.\n\n\n\n \n\n Vignettes\nI wrote several vignettes demonstrating the functions and tools included in the fsvm package in order to document the processes as well as assist others in using the package.      \n\n\n Predictions\n\n\n\nAssociating the fsvm predictions with the eCognition polygons is technically challenging compared to traditional rasters"
  },
  {
    "objectID": "fsvmproj.html#fa-leaf-field-lpi-generation",
    "href": "fsvmproj.html#fa-leaf-field-lpi-generation",
    "title": "Fine Scale Vegetation Model",
    "section": " Field LPI Generation",
    "text": "Field LPI Generation\nIn order to more effectively sample the irregularly shaped eCognition polygons for new vegetation surveys, I wrote code which randomly selects one of polygons, then attempts to fit a 50 meter line within it so the standard line point intercept (LPI) survey protocol effectively samples it. The code works by first randomly generating a starting location within the polygon, randomly selecting a direction, then draws a 50 meter survey line. If that line intersects the border of the polygon, then the process is repeated until a 50 meter line is drawn which does not intersect the polygon or after 100 failed attempts.\nThis process can then be repeated with additional randomly selected polygons until the desired number of survey options is achieved. This gives field personnel fixed options when conducting field vegetation surveys and ensures the surveys they conduct effectively sample the polygon instead of straddling multiple polygons. This also saves the analyst time by automating the generation of possible surveys which meet the desired criteria.\n\n R Functions\n\nbuff_sample <- function(poly,buff,r=10){\n  p <- sf::st_cast(poly,\"MULTILINESTRING\")\n  n <- 0\n  repeat{\n    n <- n + 1\n    rand_start <- sf::st_sample(poly,1)\n    d <- as.numeric(sf::st_distance(rand_start,p))\n    if(d >= buff | n == r){\n      break\n    }\n  }\n  if(n == r & d < buff){\n    return(NA)\n    }else{\n      return(rand_start)\n  }\n}\n\nst_fitLPI <- function(poly, r=200, buff=5, len=50){\n  poly <- sf::st_transform(poly,crs = \"WGS84\")\n  p <- sf::st_cast(poly,\"MULTILINESTRING\")\n  permute_dirs  <- sample(1:360) \n  rs <- buff_sample(poly,buff,r) \n  if(is.na(rs)){\n    return(NULL)\n  }else{rs <- sf::st_transform(rs,crs = \"WGS84\")}\n  for(j in 1:length(permute_dirs)){\n    dp <- geosphere::destPoint(rs[[1]][], b = permute_dirs[j], d = len) %>%\n      sf::st_point(.) %>% sf::st_sfc(.) %>% sf::`st_crs<-`(\"WGS84\")\n    lpi <- sf::st_cast(c(rs[[1]],dp[[1]]),\"LINESTRING\")\n    int <- sf::st_intersects(lpi,p, sparse = F)\n    if(isFALSE(int)){break}\n  }\n  if(isTRUE(int)){\n    return(NULL)\n  }\n  df <- data.frame(QPID = poly$QuadPolyID,\n                   Shape = sf::st_geometry(lpi)) %>%\n    sf::st_sf(.) %>% sf::`st_crs<-`(\"WGS84\")\n  return(df)\n}\n\n\n\n R Code\n\nrequire(dplyr)\nusgs24k <- sf::st_read(\"C:/Users/rritson/Documents/GitHub/USGS24k/USGS24k.shp\")\nr1quads <- sf::st_read(\"C:/Users/rritson/Documents/GitHub/Extents/IDFG Regions.shp\") %>% \n  dplyr::filter(ID == \"1\") %>%\n  sf::st_intersects(.,usgs24k) %>% as.data.frame(.) %>%\n  dplyr::mutate(Quad = usgs24k$UID[col.id]) %>%\n  dplyr::select(-row.id,-col.id)\nquads <- dir(\"A:/Fine scale vegetation analysis/dbases_4modeling/24kpolys\",pattern=\".rds\",full.names = T)\nflist <- quads[which(basename(quads) %in% paste0(\"q\",r1quads$Quad,\".rds\"))]\nwater <- sf::st_read(\"C:/Users/rritson/Documents/GitHub/extents/ID_Lakes.shp\")\nfgrid <- readRDS(\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/Faragut_QuadPoly_Selections.rds\")\n\n## Loop through list\nout <- sf::st_sfc() \nsf::st_crs(out) <- sf::st_crs(usgs24k)\nfor(i in 1:length(flist)){\n  print(paste(i,\"of\",length(flist)))\n  \n  # Read 24k quad w/ in R1 grid\n  temp <- readRDS(flist[i]) %>% dplyr::mutate(QuadPolyID = paste0(quad,\"_\",id))\n  wint <- sf::st_intersection(temp,water)\n  temp <- temp[which(!(temp$id %in% wint$id)),] #Filter out open water quad polygons\n  temp <- temp[which(!(temp$QuadPolyID %in% fgrid$QuadPolyID)),]\n  \n  # Randomly select 50 quadpolys from each Faragut quad\n  int <- temp %>%\n    dplyr::filter(QuadPolyID %in% QuadPolyID[sample(1:nrow(.),50)]) %>% \n    dplyr::select(QuadPolyID,Shape)\n  \n  # Collect output\n  out <- rbind(out,int)\n}\nnrow(out) == length(unique(out$QuadPolyID))\nsaveRDS(out,\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Selections.rds\")\n\n# Draw LPIs a priori\nrgrid <- readRDS(\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Selections.rds\")\nsource(\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/fitLPI_inpoly_function2.R\")\nrequire(dplyr)\n\n##Try Drawing One 50m line\n#reps <- 50 #number of repeats\nlen <- 50 #LPI line length (in meters)\nbuff <- 5 #Buffer distance from polygon edge\nout <- sf::st_sfc() \nsf::st_crs(out) <- sf::st_crs(\"WGS84\")\nfor (i in 301:600) {\n  print(paste(\"Beginning\",i,\"of\",nrow(rgrid)))\n  pb = txtProgressBar(min = 0, max = 360, initial = 0) \n  poly <- rgrid[i,] %>% sf::st_transform(.,crs = \"WGS84\")\n  p <- sf::st_cast(poly,\"MULTILINESTRING\")\n  permute_dirs  <- sample(1:360) \n  rs <- buff_sample(poly,buff,r=200) \n  if(is.na(rs)){next}else{rs <- sf::st_transform(rs,crs = \"WGS84\")}\n  for(j in 1:length(permute_dirs)){\n    setTxtProgressBar(pb,360)\n    dp <- geosphere::destPoint(rs[[1]][], b = permute_dirs[j], d = len) %>%\n      sf::st_point(.) %>% sf::st_sfc(.) %>% sf::`st_crs<-`(\"WGS84\")\n    lpi <- sf::st_cast(c(rs[[1]],dp[[1]]),\"LINESTRING\")\n    int <- sf::st_intersects(lpi,p, sparse = F)\n    if(isFALSE(int) | j == length(permute_dirs)){\n      break\n    }\n  }\n  close(pb)\n  if(isTRUE(int) & j == length(permute_dirs)){\n    print(\"Failed.\")\n    next\n  }\n  print(\"Success!\")\n  df <- data.frame(QPID = poly$QuadPolyID,\n                   Shape = sf::st_geometry(lpi)) %>%\n    sf::st_sf(.) %>% sf::`st_crs<-`(\"WGS84\")\n  out <- rbind(out,df)\n  gc()\n}\nsaveRDS(out,\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Lines_1.rds\")\nsf::st_write(out,\"C:/Users/rritson/Documents/FineScaleVegModel/Field_LPI/R1_QuadPoly_Lines.shp\")"
  },
  {
    "objectID": "seasonalranges.html#fa-layer-group-vegetation-classification-covariates",
    "href": "seasonalranges.html#fa-layer-group-vegetation-classification-covariates",
    "title": "Ungulate Seasonal Ranges",
    "section": " Vegetation Classification Covariates",
    "text": "Vegetation Classification Covariates\nA major component of the seasonal range models is IDFG’s vegetation classification covariates which are derived from LANDFIRE. The models explicitly require each vegetation class to be transformed to a focal value based on the average daily movement distance of individuals in the DAU. To streamline this covariate transformation, I wrote a Python function using ESRI’s arcpy and Spatial Analyst tools, which are called by an R script I wrote to iterate the process over each collection of DAU covariates.\n\n Python Function\n\n# --------------------------------------------------------\n# Calculate Hurley Vegetation Focal Statistics\n# Author: Robert Ritson, Associate Research Scientist (UW)\n# Last Updated: 5/10/2022\n# Description: Calculate square meters of Hurley\n#   vegetation classes (binary rasters derrived from LANDFIRE)\n#   given a mean daily movement distance (from an ungulate population),\n#   clipped by a population DAU boundary\n# --------------------------------------------------------\n#Import modules\nimport arcpy\nfrom arcpy.sa import *\nimport datetime\nimport csv\nimport os\narcpy.CheckOutExtension(\"Spatial\")\n#Define function\ndef hveg_focal(path_to_dau, mdm_ci95, path_to_hveg, dau_hveg_folder, scratch = \"C:\\\\Users\\\\rritson\\\\Documents\\\\ArcGIS\\\\scratch\\\\\"):\n    try:\n        print 'begin script on '+datetime.datetime.now().date().isoformat()+' at '+datetime.datetime.now().time().isoformat()[0:8]\n\n        # Set path to folders and workspace\n        dauws = path_to_dau\n        rastws = path_to_hveg\n        outws = dau_hveg_folder\n        neighborhood = arcpy.sa.NbrCircle(mdm_ci95,\"MAP\")\n        arcpy.env.overwriteOuptput = False\n        arcpy.env.workspace = scratch\n\n        # Buffer Selected DAU by provided mean daily movement\n        print 'buffering DAU shape by mean daily movement input (meters)'\n        arcpy.Buffer_analysis(dauws,scratch+'\\\\DAU_Buffer.shp', mdm_ci95,\"FULL\",\"ROUND\",\"NONE\",\"\",\"PLANAR\")\n        \n        # List Hurley Vegetation Rasters\n        arcpy.env.workspace = rastws\n        try:\n            print 'listing Hveg rasters'\n            hveg_list = [hveg for hveg in arcpy.ListRasters()]\n        except:  print arcpy.GetMessages(2)\n\n        # Clip Hurley Vegetation Raster to buffered DAU and calculate focal statistics\n        arcpy.env.workspace = scratch\n        for hveg in hveg_list:\n            print 'loading raster '+hveg\n            arcpy.MakeRasterLayer_management(rastws+'/'+hveg,'temp_rast.tif',\"\",scratch+'/DAU_Buffer.shp',\"\") #load raster and clip to buffered DAU extent\n\n            print 'calculating focal statistics'\n            arcpy.CheckOutExtension(\"Spatial\")\n            fstat = FocalStatistics('temp_rast.tif',  neighborhood, \"SUM\", \"DATA\") #Focal sum of binaries by mean daily movement distance\n            \n            print 'converting to square meters'\n            outrast = fstat * (30^2) #multiply focal sum by cell dimensions (convert to square meters)\n            outrast.save(outws+hveg) #save output\n\n            print hveg+' raster saved to '+outws+' at '+datetime.datetime.now().time().isoformat()[0:8]\n\n        print 'Finished: Completed Hurley vegetation density rasters for '+dauws+' located in '+outws\n        print 'script completed on '+datetime.datetime.now().date().isoformat()+' at '+datetime.datetime.now().time().isoformat()[0:8]\n\n    except:  print arcpy.GetMessages(2)\narcpy.CheckInExtension(\"Spatial\")\n# # # # # END OF FUNCTION # # # # # # #\n\n\n\n R code\n\n## Hurley Vegetation Density Raster Calculations ##\n### Loop through remaining DAUs (~10min per DAU) ###\n#Load package\nrequire(dplyr)\n\n#devtools::install_github(\"rstudio/reticulate\")\n#Sys.setenv(RETICULATE_PYTHON = \"C:\\\\Python27\\\\ArcGIS10.8\\\\\\\\pythonw.exe\")\nSys.setenv(RETICULATE_PYTHON = 'C:/Users/rritson/AppData/Local/Programs/ArcGIS/Pro/bin/Python/envs/arcgispro-py3/python.exe')\nrequire(reticulate)\n\n\n#DAU List\ndau_list <- sf::st_read('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/DAU_BBox_10kbuff.shp') %>%\n  as.data.frame(.) %>%\n  dplyr::select(NAME) %>%\n  #dplyr::filter(NAME == \"Island Park\")\n  dplyr::filter(NAME %in% c(\"Bannock\",\"Caribou\",\"Mountain Valley\",\"Portneuf\",\"Weiser-McCall\"))\n  #dplyr::filter(!(NAME %in% c(\"Bitterroot\",\"Panhandle\",\"Lower Salmon\",\"Snake River\",\"Smokey-Boise\",\"Island Park\")))\n\n#DAU shape (all)\ndau_shp <- sf::st_read('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/DAU_BBox_10kbuff.shp') %>%\n  #dplyr::select(-GlobalID,-Shape_Leng,-Shape_Area) %>% \n  sfheaders::sf_remove_holes(.)\n\n#Movement Data\ndat <- readRDS(\"C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/Winter_RSF/MD_Winter_Locs_1pd.rds\") %>% as.data.frame(.)\n\n# Check R Session Info\nif(sessionInfo()$R.version$arch != \"i386\"){\n  print(\"STOP: Must run R in 32-bit Architecture to source 'arcpy'\")\n  }\nif(paste0(sessionInfo()$R.version$major,\".\",sessionInfo()$R.version$minor) > \"4.0.4\"){\n  print(\"STOP: Must run R in version prior or equal to 4.0.4 to source 'arcpy'\") \n  # reticulate does not want to work with R version 4.1.0...\n  }\n\n# Initiate Python before beginning loop\n#reticulate::use_python(\"C:\\\\Python27\\\\ArcGIS10.8\\\\\\\\pythonw.exe\", required = T)\nreticulate::use_python('C:/Users/rritson/AppData/Local/Programs/ArcGIS/Pro/bin/Python/envs/arcgispro-py3/python.exe', required = T)\nreticulate::py_config()\nreticulate::source_python(\"C:/Users/rritson/Documents/Python Scripts/hveg_focal_func.py\")\n#reticulate::source_python(\"C:/Users/rritson/Documents/Python Scripts/hveg_focal_func_sing.py\") #for dealing with a single raster (must change file paths below if so)\n\n# Loop through DAUs\nfor (i in 1:nrow(dau_list)){\n  \n  # Select DAU\n  print(paste(\"Beginning DAU:\",dau_list[i,],\"(\",nrow(dau_list)-i,\"remaining)...\"))\n  dau_sel <- dau_list[i,] \n  \n  # Create folder for outputs\n  #print(\"Creating output folder...\")\n  #dir.create(\"F:/Seasonal_range_covars/mdmci95_2buff\") \n  #dir.create(paste0(\"F:/Seasonal_range_covars/mdmci95_2buff/\",dau_sel)) \n  \n  # Write DAU shapefile\n  #print(\"Writing shapefile...\")\n  #dau <- dau_shp %>% dplyr::filter(NAME == dau_sel)\n  #sf::write_sf(dau,paste0('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/SeasonalRanges/',dau_sel,\".shp\"),append=F)\n  \n  # Get Mean Daily Movements for DAU\n  print(\"Accessing mean daily movement (95% CI, in meters)...\")\n  mdm_ci95 <- dat %>% dplyr::filter(DAU == dau_sel) %>% dplyr::select(MDM_CI95_avg) %>% dplyr::slice(1)\n  mdm_ci95 <- mdm_ci95[[1]]\n  mdm_ci95_2 <- mdm_ci95 / 2\n  \n  # Calculate Hurley vegetation density raster for DAU: Mean Daily Movement\n  print(\"Reticulating HVeg Density Raster Calculation (Mean Daily Movement)...\")\n  hveg_focal(path_to_dau = paste0('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/SeasonalRanges/',dau_sel,\".shp\"),\n             mdm_ci95 = mdm_ci95, #mean daily movement\n             path_to_hveg = \"F:\\\\Seasonal_range_covars\\\\hveg\",\n             dau_hveg_folder = paste0(\"F:/Seasonal_range_covars/mdmci95_buff/\",dau_sel,\"/\"), #CHANGE THIS!!! (to match output folder)\n             scratch = \"C:/Users/rritson/Documents/ArcGIS/scratch\")\n  \n  #Delete temp files\n  lapply(list.files(\"C:/Users/rritson/Documents/ArcGIS/scratch\",full.names = T),file.remove)\n  gc()\n  \n  # Calculate Hurley vegetation density raster for DAU: One-half Mean Daily Movement\n  print(\"Reticulating HVeg Density Raster Calculation (One-Half Mean Daily Movement)...\")\n  hveg_focal(path_to_dau = paste0('C:/Users/rritson/Documents/Projects/MuleDeer_SeasonalRanges/SeasonalRanges/',dau_sel,\".shp\"),\n             mdm_ci95 = mdm_ci95_2, #one-half mean daily movement\n             path_to_hveg = \"F:\\\\Seasonal_range_covars\\\\hveg\",\n             dau_hveg_folder = paste0(\"F:/Seasonal_range_covars/mdmci95_2buff/\",dau_sel,\"/\"), #CHANGE THIS!!! (to match output folder)\n             scratch = \"C:/Users/rritson/Documents/ArcGIS/scratch\")\n  \n  #Delete temp files\n  lapply(list.files(\"C:/Users/rritson/Documents/ArcGIS/scratch\",full.names = T),file.remove)\n  gc()\n}"
  },
  {
    "objectID": "seasonalranges.html#fa-chart-line-seasonal-range-analysis-dashboard",
    "href": "seasonalranges.html#fa-chart-line-seasonal-range-analysis-dashboard",
    "title": "Ungulate Seasonal Ranges",
    "section": " Seasonal Range Analysis Dashboard",
    "text": "Seasonal Range Analysis Dashboard\n\n\n Average Winter Range Map\n\n\n\n Annual Winter Ranges"
  },
  {
    "objectID": "bisonproj.html#fa-binoculars-space-use-patterns",
    "href": "bisonproj.html#fa-binoculars-space-use-patterns",
    "title": "Bison",
    "section": " Space Use Patterns",
    "text": "Space Use Patterns\nIn this portion of my research, I assessed bison home ranges using autocorrelated kernel density estimates as well as foraging patch size using first-passage time analysis. These were calculated at an annual scale as well as the seasonally (growing and non-growing). These were fitted into generalized linear models to assess how space use differed between herds and across seasons\n\n Home Range: Autocorrelated Kernel Density Estimates\nExample code from home range analysis\n\n#akde code snippet\n\n\n\n Forage Patch: First-passage Time Analysis\nExample code from fpt analysis\n\n\n\nGLM outputs?\nMaps?"
  },
  {
    "objectID": "bisonproj.html#fa-puzzle-piece-habitat-selection",
    "href": "bisonproj.html#fa-puzzle-piece-habitat-selection",
    "title": "Bison",
    "section": " Habitat Selection",
    "text": "Habitat Selection\nThis portion of my research utilized resource selection functions to compare patterns of habitat use between bison herds.\nResource Selection Function example code\n\n#code and plot examples...\n\nRSF outputs?\nMaps?"
  }
]